Slide 1: Welcoming and Internship Title
Script:
"Good morning, everyone. I am Yahia Bourraoui, and I am delighted to present my end-of-study internship project titled 'Sleep Stages Detection Using Deep Learning: An Unsupervised Approach.' I would like to thank our jury president, Professor Btihal El Ghali from ESI, and my supervisors, Professor Christophe Bernard from INS and Professor Manar Abourezq from ESI, for their invaluable guidance throughout this research journey. Thank you also to all the attendees for taking the time to be here today. This work represents the culmination of months of research at the intersection of neuroscience, machine learning, and sleep medicine, and I'm excited to share our findings with you."

Slide 2: Overview/Table of Content
Script:
"Here is the structure of my presentation, organized to give you a comprehensive view of this research project:
1. Introduction - providing context about the host organization and research environment
2. Background - exploring the fundamentals of sleep architecture and epilepsy
3. Problem Statement - defining the research questions and challenges
4. Methodology - explaining our CRISP-DM approach
5. Data Understanding and Processing - detailing our multi-modal physiological datasets
6. Data Preparation and Feature Engineering - highlighting our physics-informed feature extraction
7. Modeling and Evaluation - presenting our four distinct machine learning approaches
8. Conclusion - synthesizing findings and discussing implications

Let's begin with an introduction to the research environment where this work was conducted."

Slide 3: Introduction
Script:
"This research was conducted at the Institut de Neurosciences des Systèmes, or INS, a flagship multidisciplinary research institute strategically positioned at the intersection of computational neuroscience, clinical medicine, and theoretical physics. INS was established through a collaborative partnership between INSERM and Aix-Marseille University and operates from the La Timone Campus in Marseille.

What makes INS unique is its integrative approach that combines experimental methodologies, advanced theoretical frameworks, and cutting-edge clinical applications. The institute hosts state-of-the-art facilities including MEG imaging, TMS-EEG systems, specialized electrophysiology laboratories, and a dedicated epilepsy patient unit.

I was primarily working with the PhysioNet team, which specializes in investigating the relationship between brain network dynamics and physiological functions, with a particular focus on epilepsy. INS represents one of the largest neuroscience communities in France and stands among the most prominent in Europe, with over 150 researchers and clinicians working across multiple research teams. Their work on epilepsy has generated groundbreaking insights into the mechanisms of neural synchronization and novel therapeutic approaches."

Slide 4: Project Overview
Script:
"This slide illustrates the comprehensive pipeline we developed for automated sleep analysis. Our approach begins with raw data acquisition from both rodent and human EEG recordings, followed by rigorous preprocessing to remove artifacts and noise. The cleaned signals then undergo feature extraction using Dynamic Mode Decomposition techniques, which capture the complex spatiotemporal dynamics while maintaining biological interpretability.

The heart of our methodology lies in the application of four distinct machine learning approaches: sliding window clustering for unsupervised pattern discovery, Hidden Markov Models for temporal state modeling, Bidirectional LSTM networks for sequence-based learning, and Time Series Transformers for capturing long-range dependencies.

The expected outcomes, as shown on the right side of the diagram, include the identification of novel sleep microstates, detection of micro-arousals that may serve as precursors to epileptic events, and the development of interpretable models that can be deployed in clinical environments. This pipeline represents an end-to-end solution that bridges computational techniques with real-world clinical applications."

Slide 5-6: Background/Context – Sleep Architecture and Epilepsy
Script:
"Sleep architecture refers to the cyclical progression through various sleep stages during a typical night. In humans, sleep follows a characteristic architecture composed of Non-Rapid Eye Movement (NREM) and Rapid Eye Movement (REM) stages, each serving distinct physiological functions.

NREM sleep encompasses three progressive stages: Stage 1 is characterized by the transition from alpha to theta wave dominance; Stage 2 is marked by sleep spindles and K-complexes reflecting thalamo-cortical circuit activity; and Stage 3, or deep sleep, is dominated by high-amplitude delta waves generated by synchronized cortical neuronal populations.

REM sleep presents what scientists call a paradoxical state - brain activity resembles wakefulness, yet the body experiences profound muscle atonia and vivid dreaming. This stage emerges through complex interactions between brainstem cholinergic neurons which orchestrate EEG desynchronization, rapid eye movements, and muscle paralysis.

Epilepsy is a neurological disorder characterized by recurrent seizures resulting from abnormal, excessive, or hypersynchronous neuronal activity. The relationship between sleep and epilepsy is bidirectional - sleep can trigger seizures in certain epilepsy syndromes, while epileptic activity can significantly disrupt sleep architecture. This complex interrelationship makes sleep analysis particularly valuable in epilepsy research and clinical care."

Slide 7: Importance of Sleep Scoring for Epilepsy
Script:
"Accurate sleep scoring is critical for understanding epilepsy, as certain sleep stages can modulate seizure threshold and excitability. Particularly, the transition from wakefulness to NREM sleep and from NREM to REM sleep represents periods of potential vulnerability for seizure occurrence.

Micro-arousals - brief interruptions in sleep continuity typically lasting 3-15 seconds - are especially significant in epilepsy research. These events may not result in conscious awakening but can significantly impact sleep quality and potentially act as precursors to epileptic events. They're characterized by sudden increases in EEG frequency, often accompanied by autonomic nervous system activation.

Machine learning plays a transformative role in this field by enabling the detection of complex, nonlinear patterns that traditional visual scoring often misses. Our unsupervised approaches can identify subtle micro-arousal patterns without being constrained by conventional scoring criteria, potentially revealing novel biomarkers of epileptogenesis. This represents a paradigm shift from reliance on expert visual interpretation to data-driven pattern discovery that may lead to earlier and more precise epilepsy diagnosis and treatment optimization."

Slide 8-9: Limitations of Existing Work
Script:
"Despite significant advances in sleep analysis, traditional methods face several critical limitations that our research aims to address:

First, there's an inherent bias in standardized staging frameworks like the AASM manual. These frameworks reflect consensus agreements rather than biological ground truth and may oversimplify the rich diversity of sleep patterns. Many physiologists believe additional sleep substates exist beyond the conventional stages, but these remain difficult to characterize using traditional approaches.

Second, conventional methods treat sleep stages as discrete, well-defined states rather than acknowledging the continuous, dynamic nature of brain activity during sleep. This oversimplification fails to capture the nonlinear transitions and overlapping characteristics of sleep stages, particularly during pathological conditions like epilepsy.

Third, generalization remains a significant challenge. Models trained on specific populations often perform poorly when applied to different demographic groups, species, or recording conditions. This is especially problematic when analyzing both rodent and human data as we do in this research.

Our approach directly addresses these limitations through unsupervised learning methods that don't impose preconceived notions of sleep architecture and can adapt to the unique characteristics of individual subjects and recording conditions."

Slide 10: Research Problem
Script:
"Our research problem focuses on exploring the underlying structure and transitions within sleep data without relying on labeled datasets or conventional sleep stage definitions. This unsupervised approach allows us to let the data speak for itself, potentially revealing patterns that traditional methods might overlook.

Specifically, we aim to identify novel patterns such as micro-arousals or transitional states that exist between conventionally defined sleep stages. These subtle events may provide crucial insights into sleep dynamics and their relationship to epileptic activity.

By employing physics-informed feature extraction through Dynamic Mode Decomposition combined with advanced machine learning techniques, we seek to develop models that maintain biological interpretability while capturing the complex, nonlinear dynamics of neural activity during sleep. The ultimate goal is to advance our understanding of sleep architecture in both normal and pathological conditions, particularly in the context of epilepsy."

Slide 11: Review of Existing Literature
Script:
"This table summarizes key methodological approaches that directly inform our research. The literature review spans several complementary domains:

First, foundational approaches to time series analysis, including the work of Aggarwal on real-time data stream clustering over sliding windows and Gama's survey on concept drift adaptation. These provide crucial theoretical frameworks for handling the temporal complexity inherent in sleep analysis.

Second, machine learning models and neural architectures specifically designed for sleep classification, such as Supratak's DeepSleepNet and Phan's SeqSleepNet, which demonstrate the potential of deep learning for automated sleep staging.

Third, advanced time series modeling approaches like Banville's self-supervised learning framework, which addresses the fundamental challenge of limited annotated datasets in neuroscience research.

Finally, physics-informed methods like Dynamic Mode Decomposition, which provide interpretable feature extraction techniques that capture the underlying dynamics of neural signals while maintaining biological relevance.

Each of these approaches contributes essential capabilities to our comprehensive analytical framework while addressing specific limitations of alternative methods."

Slide 12-13: CRISP-DM Methodology
Script:
"Our research methodology follows the Cross-Industry Standard Process for Data Mining (CRISP-DM), providing a structured yet flexible framework for this complex interdisciplinary project.

We began with business understanding, defining clear objectives around sleep stage detection and micro-arousal identification, and conducting a comprehensive literature review to identify methodological gaps and opportunities.

The data understanding phase involved extensive exploratory analysis of both human and rat EEG datasets, characterizing temporal dependencies, frequency domain features, and signal quality assessment.

Data preparation encompassed preprocessing pipelines for noise reduction, artifact removal, and standardization, followed by feature engineering using both conventional spectral analysis and innovative physics-informed methods like Dynamic Mode Decomposition.

The modeling phase implemented four complementary approaches: sliding window clustering, Hidden Markov Models, Bidirectional LSTM networks, and Time Series Transformers, each offering unique advantages for different aspects of sleep analysis.

Evaluation focused on biological interpretability and pattern discovery rather than conventional accuracy metrics, given the unsupervised nature of our approach. The entire process was iterative, with insights from each phase informing refinements to earlier stages."

Slide 14-15: Data Understanding and Preparation
Script:
"Our research utilized two primary data sources: human polysomnographic recordings from the Sleep-EDF database and continuous rat EEG recordings from the INS epilepsy models. The human dataset contains overnight recordings from multiple subjects, each including EEG from Fpz-Cz and Pz-Oz electrode placements, horizontal EOG, and submental EMG channels sampled at 100Hz. The rat dataset comprises continuous 24-hour recordings at 512Hz from freely moving animals, allowing for analysis of circadian patterns and micro-arousals in rodent models.

Preprocessing involved several critical steps: filtering to remove line noise and drift (0.5-80Hz bandpass); artifact detection and removal using Z-score and wavelet-based approaches; segmentation into overlapping time windows (3-second windows with 50% overlap for micro-arousals and 30-second epochs for conventional sleep stages); and normalization to account for amplitude variations across recordings and subjects.

This rigorous preparation was essential for ensuring that subsequent analyses would capture genuine physiological patterns rather than technical artifacts or irrelevant signal components. The multi-species approach also enabled comparative analyses that could distinguish universal sleep dynamics from species-specific characteristics."

Slide 16: Exploratory Data Analysis - Time Domain Analysis
Script:
"Our time domain analysis revealed distinct amplitude patterns and oscillatory characteristics across electrode placements. This slide shows EEG signals from the Pz-Oz electrode placement, which captures activity primarily from the parietal and occipital regions of the brain.

Notice the characteristic waveforms, including sleep spindles, K-complexes, and slow waves. The Pz-Oz placement shows smoother patterns with pronounced alpha activity compared to frontal-central recordings. These regional differences reflect the functional specialization of different brain areas during sleep.

The temporal structure of these signals exhibits non-stationarity and complex transitions between different oscillatory patterns. This reinforces the need for advanced time series methods capable of capturing these dynamic changes rather than treating each segment in isolation. These time domain characteristics provided essential context for our subsequent feature extraction and modeling approaches."

Slide 17: Exploratory Data Analysis - Frequency Spectrum Analysis
Script:
"Frequency spectrum analysis revealed clear spectral signatures associated with different sleep stages. This slide shows the power spectral density of EEG signals from the Pz-Oz electrode placement across frequency bands.

Notice the pronounced delta activity (0.5-4Hz) during deep sleep, the characteristic sigma band (12-16Hz) peaks during Stage 2 associated with sleep spindles, and the relative prominence of alpha (8-13Hz) during relaxed wakefulness and REM sleep.

These spectral differences form the foundation for conventional sleep staging approaches. However, our analysis revealed significant inter-individual variability and smooth transitions between spectral states rather than discrete boundaries. This observation further motivated our unsupervised approach, which could potentially identify novel spectral patterns beyond the conventional frequency band definitions.

The spectral characteristics informed our feature extraction strategy, particularly the frequency bands targeted for further analysis in our machine learning models."

Slide 18: Time Series Analysis
Script:
"Our comprehensive time series analysis provided crucial insights into the temporal structure of sleep signals. This slide shows autocorrelation and partial autocorrelation functions for 24-hour rat EEG recordings, revealing complex temporal dependencies spanning multiple time scales.

The autocorrelation function (top) exhibits oscillatory patterns with multiple periodic components, including ultradian rhythms corresponding to sleep cycles and circadian patterns across the 24-hour period. The partial autocorrelation function (bottom) shows significant correlations at multiple lags, indicating complex dependencies that cannot be captured by simple linear models.

These long-range dependencies and nonlinear characteristics confirmed that our analytical approach needed to incorporate methods capable of handling complex temporal structures. This directly informed our decision to implement advanced techniques like Dynamic Mode Decomposition for feature extraction and sequential models like LSTM networks and Transformers that can capture dependencies across extended time periods."

Slide 19-20: Data Cleaning and Preprocessing
Script:
"Data cleaning was a critical step in ensuring the quality and reliability of our analyses. We implemented a multi-stage approach to outlier detection, combining statistical thresholds based on Z-scores with more sophisticated wavelet-based methods capable of identifying transient artifacts while preserving physiologically relevant events like spindles and K-complexes.

For the preprocessing pipeline, we applied a Butterworth bandpass filter (0.5-80Hz) to remove both slow drifts and high-frequency noise while preserving the spectral content relevant to sleep architecture. The lower cutoff frequency effectively removed DC components typically associated with electrode polarization, while the upper cutoff accommodated higher-frequency components associated with REM sleep and micro-arousals.

Segmentation utilized overlapping time windows to maintain temporal continuity, with 3-second windows for micro-arousal detection and 30-second windows for conventional sleep stage analysis. The 50% overlap between consecutive windows enabled smooth transitions and helped capture events occurring at segment boundaries.

Normalization using robust scaling techniques addressed amplitude variations across subjects and recording sessions, ensuring that subsequent analyses would focus on physiologically meaningful patterns rather than technical differences in recording conditions."

Slide 22: Data Preparation Recap
Script:
"This table summarizes our comprehensive data preparation process, highlighting the rationale and implementation details for each step.

Signal filtering employed a Butterworth bandpass design to preserve phase relationships while effectively removing noise. Our frequency range (0.5-80Hz) was specifically selected to retain all physiologically relevant oscillatory components while eliminating technical artifacts.

Segmentation utilized a dual-window approach, with shorter 3-second windows capturing rapid transient events like micro-arousals and longer 30-second windows aligning with conventional sleep staging practices. This multi-scale approach enabled analyses across different temporal resolutions.

Normalization combined channel-wise Z-score standardization with subject-level scaling to address both within-recording variability and between-subject differences. This robust approach ensured that subsequent clustering would identify genuine physiological patterns rather than artifacts of recording conditions.

Each of these preprocessing steps was carefully validated through visual inspection and quantitative quality metrics to ensure optimal signal quality while preserving the biological information critical for our analyses."

Slide 23: Feature Engineering Recap
Script:
"Our feature engineering strategy combined conventional spectral analysis with innovative physics-informed approaches to capture the multifaceted nature of sleep dynamics.

Dynamic Mode Decomposition (DMD) provided a powerful framework for extracting spatiotemporal features while maintaining physical interpretability. This technique decomposes complex systems into coherent modes with associated frequencies and growth rates, effectively capturing the underlying dynamics of neural signals. By extracting DMD modes and their corresponding temporal evolution, we obtained features that reflect the system's dynamic behavior rather than static statistical properties.

Spectral power features were calculated across conventional frequency bands (delta, theta, alpha, beta, gamma) as well as more specific bands associated with sleep phenomena, such as sigma band activity linked to sleep spindles. We computed both absolute and relative power metrics to capture both the magnitude and proportional distribution of spectral content.

Non-linear features, including sample entropy and Hurst exponent, quantified the complexity and long-range dependencies in the signals. These measures provided complementary information to conventional spectral analysis, capturing subtle patterns in signal structure that power spectra might miss.

Together, these features enabled a comprehensive representation of the multidimensional nature of sleep signals, providing our models with rich information for pattern discovery."

Slide 24: Modeling and Evaluation
Script:
"Our modeling strategy employed four complementary approaches, each offering unique advantages for analyzing sleep dynamics. This systematic comparison allowed us to identify the most effective techniques for different aspects of sleep analysis while providing a comprehensive view of sleep architecture.

We began with sliding window clustering to establish baseline patterns in an unsupervised manner. This was followed by Hidden Markov Models to capture state transitions and temporal dependencies. We then implemented more sophisticated deep learning approaches, including Bidirectional LSTM networks and Time Series Transformers, to capture complex sequential patterns.

Evaluation focused on biological interpretability rather than conventional accuracy metrics, given our unsupervised approach. We employed cluster analysis, frequency band characterization, temporal stability metrics, and comparison with known physiological patterns to assess model performance. This multifaceted evaluation strategy ensured that our findings were not only statistically robust but also biologically meaningful."

Slide 25: Clustering over Sliding Windows Recap
Script:
"Our sliding window clustering approach implemented an unsupervised framework for discovering patterns in sleep EEG without imposing predefined stage definitions. This table summarizes the implementation details and key findings.

We employed a combination of spectral and DMD-based features, with window sizes optimized for micro-arousal detection (3 seconds) and conventional sleep staging (30 seconds). Multiple clustering algorithms were systematically compared, including KMeans, HDBSCAN, and Agglomerative Clustering, to identify the most effective approach for different aspects of sleep analysis.

Dimensionality reduction using PCA and t-SNE facilitated visualization of cluster separability, while biological interpretation was ensured through spectral power analysis of the identified clusters. Temporal dynamics were assessed through transition probability analysis and continuous duration statistics.

Key findings included the identification of distinct micro-states within conventional sleep stages and the detection of transitional states characterized by unique spectral signatures. These results challenge the conventional view of sleep as comprising discrete, well-defined stages and suggest a more nuanced continuum of brain states."

Slide 26: Clustering Results using KMeans
Script:
"This slide visualizes the clustering results obtained using KMeans with optimal parameters determined through silhouette analysis. The PCA projection shows clear separation between identified clusters, particularly between deep sleep states (characterized by high delta power) and wake/REM states (characterized by higher frequency components).

The t-SNE visualization, which better preserves local structure, reveals more subtle substructures within the major clusters, suggesting the presence of transitional states and micro-states that aren't captured by conventional sleep staging approaches.

Color coding indicates the different clusters, with the distribution reflecting the proportional time spent in each state. The separation quality and biological interpretability of these clusters validated our feature extraction approach and confirmed that unsupervised methods can effectively identify meaningful patterns in sleep EEG data."

Slide 27: Clustering Results using Agglomerative Clustering
Script:
"Agglomerative Clustering, with its hierarchical approach, provided complementary insights to the KMeans results. This method identified more distinct boundaries between clusters while preserving hierarchical relationships, as shown in the dendrogram (not pictured).

The PCA projection demonstrates how agglomerative clustering captured major sleep states while also identifying potential substates within them. The hierarchical nature of this algorithm aligns well with the biological understanding of sleep as a nested hierarchy of states rather than strictly separate categories.

The t-SNE visualization highlights the fine-grained structure of the data, with clusters that potentially correspond to micro-states or transitional periods between major sleep stages. This hierarchical perspective provides valuable insights into the organization of sleep architecture that complement the partition-based approach of KMeans."

Slide 28: Clustering Results using HDBSCAN
Script:
"HDBSCAN, a density-based clustering algorithm, offered unique advantages for identifying natural groupings in our sleep data without imposing spherical cluster shapes. This approach was particularly effective at identifying outliers and handling the non-uniform density distribution characteristic of sleep EEG features.

The visualization shows how HDBSCAN identified core sleep states while also highlighting transitional regions and potential micro-arousals as separate clusters. Unlike KMeans, which assigns every point to a cluster, HDBSCAN can leave points unclustered if they don't clearly belong to any high-density region. This property was especially valuable for detecting anomalous patterns that might represent micro-arousals or pathological events.

The cluster structure identified by HDBSCAN aligned well with known physiological states while revealing additional substructure that warrants further investigation. The noise points (shown in gray) often corresponded to transitional periods between stable sleep stages, providing insights into the dynamic nature of sleep state transitions."

Slide 29: HMM Model Recap
Script:
"Our Hidden Markov Model implementation focused on capturing the temporal dynamics and state transitions in sleep EEG. This table summarizes the model configuration and key findings.

We employed a combination of spectral and DMD-based features, with state number optimization using the Bayesian Information Criterion. The model architecture incorporated Gaussian emission probabilities and a first-order Markovian assumption to balance complexity with interpretability.

Time-dependent transition matrices were estimated to capture the evolution of sleep dynamics throughout the recording period, enabling us to model the circadian influence on sleep architecture. State sequence decoding using the Viterbi algorithm provided the most likely sequence of hidden states given the observed features.

Key findings included the identification of probabilistic transition patterns that align with known sleep physiology, such as the progressive deepening of sleep through NREM stages and the cycling between NREM and REM sleep. The model also revealed asymmetric transition probabilities that wouldn't be captured by simple clustering approaches, highlighting the value of explicitly modeling temporal dependencies."

Slide 30: Clustering Results - Distribution of Clusters
Script:
"This slide illustrates the distribution of clusters identified by our models across different subjects and recording conditions. The proportional representation of each cluster provides insights into sleep architecture and individual variability.

The pie chart shows the relative distribution of major sleep states, with percentages that align reasonably well with expected physiological norms for healthy adults (approximately 5% Stage 1, 50% Stage 2, 20% deep sleep, and 25% REM sleep). However, our unsupervised approach identified additional states that don't fit neatly into conventional categories, particularly transitional states and potential micro-arousal patterns.

The bar chart depicts cluster distribution across different subjects, revealing individual variability while maintaining consistent core sleep states. This balance between commonality and individual differences supports the biological relevance of our cluster definitions and demonstrates the potential for personalized sleep analysis using our unsupervised approach."

Slide 31: Spectral Power Distribution Across Frequency Bands
Script:
"This visualization shows the spectral power distribution across conventional frequency bands for each cluster identified by our models. This analysis was crucial for interpreting the biological significance of the unsupervised clusters.

Notice the distinct spectral signatures: clusters dominated by delta activity (0.5-4Hz) likely correspond to deep sleep; clusters with prominent sigma activity (12-16Hz) align with Stage 2 sleep and spindle events; clusters with balanced alpha and beta power may represent REM sleep or transitional states.

Beyond these conventional associations, we observed clusters with unique spectral combinations that don't fit neatly into traditional sleep stages. For instance, Cluster 3 shows a distinctive profile with elevated theta and alpha power that may represent a transitional state between light sleep and REM sleep.

These spectral characteristics provided essential validation of our clustering results while also revealing novel patterns that warrant further investigation for their potential clinical significance."

Slide 32: BiLSTM Recap
Script:
"Our Bidirectional Long Short-Term Memory (BiLSTM) network implementation leveraged the power of recurrent neural networks to capture complex temporal dependencies in sleep EEG. This table summarizes the model architecture and training approach.

The network comprised embedding layers for feature representation, bidirectional LSTM layers for sequential processing, and fully connected layers for feature integration. This architecture processed information in both forward and backward directions, enabling the model to capture both past and future context for each time point.

Training employed an unsupervised approach using contrastive learning, where the model learned to distinguish between temporally adjacent segments and randomly sampled segments. This self-supervised pretraining strategy leveraged the sequential nature of sleep data without requiring labeled examples.

Key findings included superior performance in capturing long-range dependencies compared to traditional methods and the emergence of physiologically meaningful representations in the network's hidden states. The bidirectional approach proved particularly valuable for identifying micro-arousals, which often exhibit characteristic patterns both before and after the event."

Slide 33: Clustering Results - Distribution of BiLSTM Clusters
Script:
"This slide shows the distribution of clusters derived from the BiLSTM hidden representations, offering insights into the patterns automatically discovered by the network.

The distribution exhibits a balance between major sleep states while capturing more nuanced transitional states than conventional approaches. The cluster proportions generally align with expected physiological distributions, with approximately 20-25% of time spent in REM-like states and the remainder distributed across various NREM-like states.

Notably, the BiLSTM identified smaller clusters that appear to represent transitional states or micro-arousals, shown in the smaller segments of the pie chart. These fine-grained distinctions highlight the advantage of our approach over traditional methods that might overlook these subtle but potentially significant patterns.

The stability of these clusters across validation datasets supports their biological relevance rather than representing artifacts or overfitting to training data."

Slide 34: Frequency Band Analysis for the BiLSTM Clusters
Script:
"This frequency band analysis for the BiLSTM-derived clusters reveals the spectral characteristics that the network learned to differentiate, providing biological interpretation for the unsupervised representations.

Each cluster exhibits a distinct spectral signature across delta, theta, alpha, beta, and gamma bands. Clusters 1 and 4 show prominent delta activity characteristic of deep sleep, while Cluster 3 displays balanced power across multiple bands suggesting REM sleep or transition states.

Particularly interesting is Cluster 5, which shows elevated high-frequency activity that may correspond to micro-arousal events or brief awakenings. The BiLSTM successfully identified this distinct pattern without explicit guidance, demonstrating its ability to discover clinically relevant patterns through unsupervised learning.

These spectral profiles not only validate the biological relevance of the learned representations but also provide potential biomarkers for different sleep states that could inform clinical applications in sleep medicine and epilepsy research."

Slide 35: Continuous Duration Analysis for the BiLSTM Clusters
Script:
"Continuous duration analysis provided crucial insights into the temporal stability and transitions between the states identified by our BiLSTM model. This visualization shows the distribution of episode durations for each cluster, revealing characteristic temporal patterns.

Deep sleep-like clusters (1 and 4) show longer continuous durations, reflecting the stability of these states once established. In contrast, transitional or micro-arousal-like clusters (5 and 6) typically have shorter durations, consistent with their role as brief interruptions or transitions between more stable states.

The exponential decay in episode duration for certain clusters aligns with the known properties of sleep state transitions, where the probability of transitioning out of a state increases with time spent in that state. This temporal structure provides additional validation of the biological relevance of our unsupervised clusters.

Furthermore, the analysis revealed cyclic patterns in state transitions that correspond to the ultradian rhythm of the sleep cycle, with approximately 90-minute periodicity in humans and 12-15 minute cycles in rats, further supporting the physiological significance of our model's representations."

Slide 36: TST Recap
Script:
"Our Time Series Transformer (TST) model leveraged the power of attention mechanisms to capture long-range dependencies in sleep EEG without the constraints of recurrent architectures. This table summarizes the implementation details and key findings.

The model architecture combined multi-head self-attention mechanisms with position-aware encodings to process sequential data while maintaining awareness of temporal position and context. This approach allowed the model to attend to relevant patterns across long sequences regardless of their distance from the current time point.

Training employed a masked language modeling approach adapted for time series, where the model learned to predict masked segments based on surrounding context. This self-supervised strategy leveraged the sequential nature of sleep data while avoiding the need for labeled examples.

Key findings included superior performance in detecting long-range patterns compared to both traditional methods and recurrent networks. The attention visualizations revealed that the model automatically learned to focus on physiologically relevant events such as spindles, K-complexes, and state transitions, providing interpretable insights into its decision-making process."

Slide 37: Distribution of Clusters
Script:
"This visualization shows the cluster distribution identified by the Time Series Transformer model. The proportional representation provides insights into the sleep architecture captured by the attention-based approach.

The distribution shows clear differentiation between major sleep states while capturing transitional states and micro-arousals as distinct clusters. The proportions generally align with expected physiological distributions from conventional sleep staging, with approximately 5% Stage 1, 45-50% Stage 2, 20-25% deep sleep, and 20-25% REM sleep.

Notably, the transformer model identified smaller clusters that appear to represent micro-arousals or brief awakenings, shown in the smaller segments of the chart. The model's attention mechanism proved particularly effective at capturing these transient events by focusing on their distinctive temporal and spectral characteristics.

The consistency of these distributions across different subjects supports the biological relevance of the identified clusters rather than representing artifacts or idiosyncratic patterns."

Slide 38: Hypnogram Comparison for the Time Series Transformer Model
Script:
"This slide presents a hypnogram comparison between segments classified as awake versus asleep by the Time Series Transformer model. The hypnogram visualization shows the sequence of identified sleep states over time, providing insights into sleep architecture and dynamics.

In the awake segments (top), notice the predominance of high-frequency states with brief excursions into transitional states. The pattern shows higher variability and more frequent state transitions, characteristic of conscious wakefulness and attention shifts.

In contrast, the asleep segments (bottom) display the characteristic cycling between different sleep stages, with longer periods in sustained states and more structured transitions. The cyclic pattern of progressively deeper sleep followed by REM periods is clearly visible, matching the expected ultradian rhythm of sleep cycles.

This comparison demonstrates the model's ability to capture physiologically meaningful sleep dynamics without explicit supervision. The clear differentiation between awake and sleep patterns provides strong validation of our unsupervised approach and supports the biological relevance of the identified states."

Slide 40: Conclusion
Script:
"In conclusion, our research has made several significant contributions to the field of automated sleep analysis and its application to epilepsy research.

We successfully developed and validated four complementary unsupervised approaches for sleep stage detection and micro-arousal identification. The integration of physics-informed feature extraction through Dynamic Mode Decomposition with advanced machine learning techniques provided a powerful framework for pattern discovery while maintaining biological interpretability.

Key findings include the identification of novel sleep microstates beyond conventional staging, the detection of transitional states with unique spectral signatures, and the superior performance of sequence-based models, particularly Time Series Transformers, in capturing long-range temporal dependencies essential for understanding sleep dynamics.

The clinical implications extend to precision medicine through automated, objective analysis tools for complex physiological signals. Our approach shows particular promise for detecting subtle micro-arousal patterns that may serve as biomarkers or precursors for epileptic events, potentially enabling earlier intervention and more personalized treatment strategies.

This work establishes new benchmarks for automated physiological signal interpretation and provides a foundation for future investigations into neurological health through computational sleep analysis. Thank you for your attention, and I welcome any questions."

******************************************
******************************************
******************************************

# Sleep Stages Detection Using Deep Learning: An Unsupervised Approach
## Shortened Presentation Script (15-20 minutes)

### Slide 1: Welcoming and Internship Title
**Script:**
"Good morning, everyone. I am Yahia Bourraoui, presenting my end-of-study internship project titled 'Sleep Stages Detection Using Deep Learning: An Unsupervised Approach.' I thank Professor Btihal El Ghali from ESI, Professor Christophe Bernard from INS, and Professor Manar Abourezq from ESI for their guidance. This work represents months of research at the intersection of neuroscience, machine learning, and sleep medicine."

### Slide 2: Overview/Table of Content
**Script:**
"Here's my presentation structure:
1. Introduction to the research environment
2. Background on sleep architecture and epilepsy
3. Problem statement and research questions
4. CRISP-DM methodology
5. Data understanding and processing
6. Feature engineering approach
7. Four modeling approaches and evaluation
8. Conclusion and implications

Let's begin with the research environment."

### Slide 3: Introduction
**Script:**
"This research was conducted at the Institut de Neurosciences des Systèmes (INS), a multidisciplinary institute combining computational neuroscience, clinical medicine, and theoretical physics. INS operates from La Timone Campus in Marseille through a partnership between INSERM and Aix-Marseille University.

INS features state-of-the-art facilities including MEG imaging, TMS-EEG systems, and specialized epilepsy units. I worked with the PhysioNet team, investigating brain network dynamics and epilepsy. INS represents one of Europe's largest neuroscience communities with over 150 researchers."

### Slide 4: Project Overview
**Script:**
"Our pipeline begins with raw EEG data from both rodent and human recordings, followed by preprocessing to remove artifacts. The cleaned signals undergo feature extraction using Dynamic Mode Decomposition, capturing complex spatiotemporal dynamics.

We applied four machine learning approaches: sliding window clustering, Hidden Markov Models, Bidirectional LSTMs, and Time Series Transformers. Expected outcomes include novel sleep microstate identification, micro-arousal detection as precursors to epileptic events, and interpretable models for clinical deployment."

### Slide 5-6: Background/Context – Sleep Architecture and Epilepsy
**Script:**
"Sleep architecture comprises cyclical progression through NREM and REM stages. NREM includes Stage 1 (alpha to theta transition), Stage 2 (sleep spindles and K-complexes), and Stage 3 (high-amplitude delta waves). REM sleep presents paradoxical brain activity with muscle atonia and vivid dreaming.

Epilepsy involves recurrent seizures from abnormal neuronal activity. Sleep and epilepsy have a bidirectional relationship - sleep can trigger seizures while epileptic activity disrupts sleep architecture, making sleep analysis valuable for epilepsy research and clinical care."

### Slide 7: Importance of Sleep Scoring for Epilepsy
**Script:**
"Accurate sleep scoring is critical for epilepsy understanding, as certain sleep stages modulate seizure threshold. Micro-arousals - brief 3-15 second sleep interruptions - are especially significant as potential precursors to epileptic events.

Machine learning enables detection of complex, nonlinear patterns that visual scoring misses. Our unsupervised approaches identify subtle micro-arousal patterns without conventional scoring constraints, potentially revealing novel epileptogenesis biomarkers."

### Slide 8-9: Limitations of Existing Work
**Script:**
"Traditional methods face critical limitations: inherent bias in standardized frameworks like AASM, treating sleep stages as discrete rather than continuous dynamic states, and poor generalization across populations and species.

Our unsupervised approach addresses these limitations by not imposing preconceived sleep architecture notions and adapting to individual subject characteristics and recording conditions."

### Slide 10: Research Problem
**Script:**
"Our research explores underlying sleep structure without labeled datasets or conventional stage definitions. We aim to identify novel patterns like micro-arousals and transitional states between conventional sleep stages.

Using physics-informed feature extraction through Dynamic Mode Decomposition with advanced machine learning, we develop biologically interpretable models capturing complex neural dynamics during sleep."

### Slide 11: Review of Existing Literature
**Script:**
"Our literature review spans time series analysis foundations, machine learning models for sleep classification like DeepSleepNet, self-supervised learning frameworks addressing limited annotated datasets, and physics-informed methods like Dynamic Mode Decomposition providing interpretable feature extraction while maintaining biological relevance."

### Slide 12-13: CRISP-DM Methodology
**Script:**
"We followed CRISP-DM methodology: business understanding defining objectives around sleep detection, data understanding through exploratory analysis of human and rat EEG datasets, data preparation including preprocessing and feature engineering using Dynamic Mode Decomposition, modeling with four complementary approaches, and evaluation focusing on biological interpretability rather than conventional accuracy metrics."

### Slide 14-15: Data Understanding and Preparation
**Script:**
"We used human polysomnographic recordings from Sleep-EDF database and continuous rat EEG recordings from INS epilepsy models. Human data includes overnight recordings with EEG, EOG, and EMG channels at 100Hz. Rat data comprises 24-hour recordings at 512Hz.

Preprocessing involved bandpass filtering (0.5-80Hz), artifact removal using Z-score and wavelet methods, segmentation into overlapping windows (3-second for micro-arousals, 30-second for conventional stages), and normalization for amplitude variations."

### Slide 16: Exploratory Data Analysis - Time Domain Analysis
**Script:**
"Time domain analysis revealed distinct amplitude patterns across electrode placements. The Pz-Oz placement shows characteristic waveforms including sleep spindles, K-complexes, and slow waves with smoother patterns and pronounced alpha activity.

These signals exhibit non-stationarity and complex transitions between oscillatory patterns, reinforcing the need for advanced time series methods capable of capturing dynamic changes."

### Slide 17: Exploratory Data Analysis - Frequency Spectrum Analysis
**Script:**
"Frequency analysis revealed clear spectral signatures: pronounced delta activity (0.5-4Hz) during deep sleep, sigma band peaks (12-16Hz) during Stage 2 sleep spindles, and alpha prominence (8-13Hz) during wake and REM sleep.

We observed significant inter-individual variability and smooth transitions rather than discrete boundaries, motivating our unsupervised approach to identify novel spectral patterns."

### Slide 18: Time Series Analysis
**Script:**
"Time series analysis revealed complex temporal dependencies spanning multiple scales. Autocorrelation functions show oscillatory patterns with ultradian and circadian components. Partial autocorrelation indicates complex dependencies requiring advanced techniques like Dynamic Mode Decomposition and sequential models like LSTMs and Transformers."

### Slide 19-20: Data Cleaning and Preprocessing
**Script:**
"Data cleaning combined statistical Z-score thresholds with wavelet-based methods to identify artifacts while preserving physiological events. Preprocessing applied Butterworth bandpass filtering (0.5-80Hz), overlapping segmentation with 50% overlap, and robust normalization addressing amplitude variations across subjects and sessions."

### Slide 22: Data Preparation Recap
**Script:**
"Our preparation process: Butterworth bandpass filtering preserving phase relationships, dual-window segmentation (3-second for micro-arousals, 30-second for conventional staging), and combined Z-score and subject-level normalization ensuring identification of genuine physiological patterns rather than recording artifacts."

### Slide 23: Feature Engineering Recap
**Script:**
"Feature engineering combined conventional spectral analysis with physics-informed Dynamic Mode Decomposition. DMD extracted spatiotemporal features while maintaining interpretability, capturing system dynamics rather than static properties. We computed spectral power across frequency bands and non-linear features like sample entropy and Hurst exponent for comprehensive signal representation."

### Slide 24: Modeling and Evaluation
**Script:**
"We employed four complementary approaches: sliding window clustering for baseline patterns, Hidden Markov Models for state transitions, Bidirectional LSTMs for sequential learning, and Time Series Transformers for long-range dependencies. Evaluation focused on biological interpretability through cluster analysis, spectral characterization, and physiological pattern comparison."

### Slide 25: Clustering over Sliding Windows Recap
**Script:**
"Sliding window clustering discovered patterns without predefined stage definitions. We compared KMeans, HDBSCAN, and Agglomerative Clustering with optimized window sizes. Key findings included distinct micro-states within conventional stages and transitional states with unique spectral signatures, challenging discrete sleep stage views."

### Slide 26: Clustering Results using KMeans
**Script:**
"KMeans results show clear separation between deep sleep states (high delta power) and wake/REM states (higher frequency components). The t-SNE visualization reveals subtle substructures suggesting transitional states and micro-states not captured by conventional approaches."

### Slide 27: Clustering Results using Agglomerative Clustering
**Script:**
"Agglomerative clustering provided hierarchical insights with distinct boundaries while preserving relationships. This approach captured major sleep states and potential substates, aligning with biological understanding of sleep as nested hierarchy rather than separate categories."

### Slide 28: Clustering Results using HDBSCAN
**Script:**
"HDBSCAN identified natural groupings without imposing spherical shapes, effectively detecting outliers and handling non-uniform density. It identified core sleep states while highlighting transitional regions and potential micro-arousals, with noise points often corresponding to transitional periods."

### Slide 29: HMM Model Recap
**Script:**
"Hidden Markov Models captured temporal dynamics using spectral and DMD features with Gaussian emissions and first-order Markovian assumptions. Key findings included probabilistic transition patterns aligning with sleep physiology and asymmetric transition probabilities highlighting temporal dependency value."

### Slide 30: Clustering Results - Distribution of Clusters
**Script:**
"Cluster distributions align with physiological norms while identifying additional transitional states and micro-arousal patterns. Individual variability exists while maintaining consistent core sleep states, supporting biological relevance and potential for personalized sleep analysis."

### Slide 31: Spectral Power Distribution Across Frequency Bands
**Script:**
"Spectral analysis reveals distinct signatures: delta-dominated clusters correspond to deep sleep, sigma-prominent clusters align with Stage 2 sleep, and balanced alpha-beta clusters represent REM or transitional states. Novel clusters with unique spectral combinations warrant further clinical investigation."

### Slide 32: BiLSTM Recap
**Script:**
"Bidirectional LSTM networks captured complex temporal dependencies using contrastive learning for self-supervised training. Key findings included superior long-range dependency capture and physiologically meaningful hidden state representations, particularly valuable for micro-arousal identification."

### Slide 33: Clustering Results - Distribution of BiLSTM Clusters
**Script:**
"BiLSTM cluster distribution balances major sleep states while capturing nuanced transitional states. Smaller clusters represent micro-arousals or transitions, highlighting advantages over traditional methods. Cluster stability across validation datasets supports biological relevance."

### Slide 34: Frequency Band Analysis for the BiLSTM Clusters
**Script:**
"BiLSTM clusters show distinct spectral signatures: Clusters 1 and 4 display deep sleep delta activity, Cluster 3 shows REM-like balanced power, and Cluster 5 exhibits elevated high-frequency activity potentially corresponding to micro-arousals, demonstrating unsupervised clinical pattern discovery."

### Slide 35: Continuous Duration Analysis for the BiLSTM Clusters
**Script:**
"Duration analysis reveals temporal stability patterns: deep sleep clusters show longer durations reflecting stability, while transitional clusters have shorter durations. Exponential decay patterns align with sleep state transition properties, and cyclic patterns correspond to ultradian rhythms."

### Slide 36: TST Recap
**Script:**
"Time Series Transformers leveraged attention mechanisms for long-range dependencies without recurrent constraints. Using masked language modeling for self-supervised training, key findings included superior long-range pattern detection and attention visualizations revealing focus on physiologically relevant events."

### Slide 37: Distribution of Clusters
**Script:**
"Transformer cluster distribution differentiates major sleep states while capturing transitional states and micro-arousals. Proportions align with physiological distributions, and smaller clusters represent micro-arousals identified through attention mechanisms, with consistency across subjects supporting biological relevance."

### Slide 38: Hypnogram Comparison for the Time Series Transformer Model
**Script:**
"Hypnogram comparison shows clear differentiation: awake segments display high-frequency states with frequent transitions, while asleep segments show characteristic cycling between sleep stages with structured transitions and ultradian rhythm patterns, validating our unsupervised approach."

### Slide 40: Conclusion
**Script:**
"We successfully developed four complementary unsupervised approaches for sleep analysis. Key contributions include novel sleep microstate identification, transitional state detection, and superior performance of sequence-based models, particularly Time Series Transformers.

Clinical implications extend to precision medicine through automated analysis tools and micro-arousal biomarker detection for epilepsy intervention. This work establishes new benchmarks for physiological signal interpretation and provides foundations for future neurological health investigations through computational sleep analysis. Thank you for your attention."