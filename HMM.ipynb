{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f993ebf",
   "metadata": {},
   "source": [
    "# EEG Signal Processing Pipeline with GPU Acceleration\n",
    "This notebook demonstrates a pipeline to process EEG signals from EDF files. The pipeline includes interpolation, standardization, detrending, and applying a Hidden Markov Model (HMM) for stage classification or clustering with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b576362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:30:36.962521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow sees the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Is GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from scipy.signal import detrend\n",
    "from hmmlearn import hmm\n",
    "# Import GPU libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# Check if GPU is available\n",
    "print(f\"TensorFlow sees the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "print(f\"Is GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ba66b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth set to True\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU memory management\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print('Memory growth set to True')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b71ec1",
   "metadata": {},
   "source": [
    "## Step 1: Read EDF File\n",
    "Load the EEG signal from an EDF file with a sampling frequency of 512 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e3de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/yahia/notebooks/by captain borat/raw/EEG_0_per_hour_2024-03-20 17_12_18.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 44153855  =      0.000 ... 86237.998 secs...\n"
     ]
    }
   ],
   "source": [
    "# Load EDF file\n",
    "def load_edf(file_path):\n",
    "    # Use mne.io.read_raw_edf to read EDF files\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    # Get data as numpy array, selecting the first channel for simplicity\n",
    "    # Modify this based on which channels you want to analyze\n",
    "    data = raw.get_data()[0]\n",
    "    return data\n",
    "\n",
    "file_path = 'by captain borat/raw/EEG_0_per_hour_2024-03-20 17_12_18.edf'\n",
    "eeg_signal = load_edf(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a46d85",
   "metadata": {},
   "source": [
    "## Step 2: Interpolate Signal\n",
    "Interpolate locally with a threshold of 3x the standard deviation using a sliding window of 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "148f5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate signal\n",
    "def interpolate_signal(signal, window_size, threshold_factor):\n",
    "    interpolated_signal = signal.copy()\n",
    "    std_dev = np.std(signal)\n",
    "    threshold = threshold_factor * std_dev\n",
    "    for i in range(0, len(signal), window_size):\n",
    "        window = signal[i:i+window_size]\n",
    "        outliers = np.abs(window - np.mean(window)) > threshold\n",
    "        interpolated_signal[i:i+window_size][outliers] = np.mean(window)\n",
    "    return interpolated_signal\n",
    "\n",
    "window_size = 512 * 10  # 10 seconds\n",
    "threshold_factor = 3\n",
    "eeg_signal_interpolated = interpolate_signal(eeg_signal, window_size, threshold_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2c305",
   "metadata": {},
   "source": [
    "## Step 3: Standardize Signal\n",
    "Standardize the signal to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13c2c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize signal\n",
    "def standardize_signal(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "eeg_signal_standardized = standardize_signal(eeg_signal_interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3b876",
   "metadata": {},
   "source": [
    "## Step 4: Remove Linear Trends\n",
    "Remove linear trends from the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11208073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove linear trends\n",
    "eeg_signal_detrended = detrend(eeg_signal_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1d6a9",
   "metadata": {},
   "source": [
    "## Step 5: Apply Hidden Markov Model (HMM) with GPU Acceleration\n",
    "Use a GPU-accelerated implementation of HMM to classify or cluster different stages from the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c57b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMM on: [LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:30:44.166239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 15:30:44.379233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10446 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# GPU-accelerated HMM implementation using TensorFlow for matrix operations\n",
    "class TFHMM:\n",
    "    def __init__(self, n_components=5, n_iter=100):\n",
    "        self.n_components = n_components\n",
    "        self.n_iter = n_iter\n",
    "        self.means_ = None\n",
    "        self.covars_ = None\n",
    "        self.transmat_ = None\n",
    "        self.startprob_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Convert data to TensorFlow tensor\n",
    "        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        n_samples, n_features = X_tf.shape\n",
    "\n",
    "        # Initialize parameters randomly\n",
    "        self.means_ = tf.Variable(tf.random.normal([self.n_components, n_features]))\n",
    "        self.covars_ = tf.Variable(tf.ones([self.n_components, n_features]))\n",
    "        self.transmat_ = tf.Variable(tf.random.uniform([self.n_components, self.n_components]))\n",
    "        self.startprob_ = tf.Variable(tf.random.uniform([self.n_components]))\n",
    "\n",
    "        # Normalize transition and start probabilities\n",
    "        self.transmat_.assign(tf.nn.softmax(self.transmat_, axis=1))\n",
    "        self.startprob_.assign(tf.nn.softmax(self.startprob_))\n",
    "\n",
    "        # Simple EM algorithm implementation\n",
    "        for i in range(self.n_iter):\n",
    "            # E-step: compute responsibilities (using log-likelihood for stability)\n",
    "            log_resp = self._compute_log_likelihood(X_tf) + tf.math.log(self.startprob_[:, tf.newaxis])\n",
    "            # Normalize responsibilities\n",
    "            log_resp = log_resp - tf.reduce_logsumexp(log_resp, axis=0)[tf.newaxis, :]\n",
    "            resp = tf.exp(log_resp)\n",
    "            \n",
    "            # M-step: update parameters\n",
    "            # Update means\n",
    "            numer = tf.matmul(resp, X_tf)\n",
    "            denom = tf.reduce_sum(resp, axis=1)[:, tf.newaxis]\n",
    "            self.means_.assign(numer / denom)\n",
    "            \n",
    "            # Update covariances\n",
    "            centered = X_tf[tf.newaxis, :, :] - self.means_[:, tf.newaxis, :]\n",
    "            squared = centered ** 2\n",
    "            self.covars_.assign(tf.reduce_sum(resp[:, :, tf.newaxis] * squared, axis=1) / denom)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert data to TensorFlow tensor\n",
    "        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        # Use Viterbi algorithm for decoding\n",
    "        log_likelihood = self._compute_log_likelihood(X_tf)\n",
    "        return tf.argmax(log_likelihood, axis=0).numpy()\n",
    "    \n",
    "    def _compute_log_likelihood(self, X):\n",
    "        # Calculate log-likelihood for each state and sample\n",
    "        X_expanded = X[tf.newaxis, :, :]  # Shape: [1, n_samples, n_features]\n",
    "        means_expanded = self.means_[:, tf.newaxis, :]  # Shape: [n_components, 1, n_features]\n",
    "        covars_expanded = self.covars_[:, tf.newaxis, :]  # Shape: [n_components, 1, n_features]\n",
    "        \n",
    "        # Calculate log-likelihood using Gaussian distribution\n",
    "        diff = X_expanded - means_expanded  # Shape: [n_components, n_samples, n_features]\n",
    "        log_likelihood = -0.5 * tf.reduce_sum(diff**2 / covars_expanded, axis=2)\n",
    "        log_likelihood = log_likelihood - 0.5 * tf.reduce_sum(tf.math.log(2 * np.pi * covars_expanded), axis=2)\n",
    "        return log_likelihood\n",
    "\n",
    "def apply_gpu_hmm(signal, n_states):\n",
    "    # Reshape the signal for HMM\n",
    "    signal_reshaped = signal.reshape(-1, 1)\n",
    "    # Apply GPU-accelerated HMM\n",
    "    model = TFHMM(n_components=n_states, n_iter=100)\n",
    "    model.fit(signal_reshaped)\n",
    "    hidden_states = model.predict(signal_reshaped)\n",
    "    return hidden_states\n",
    "\n",
    "# Define the number of states\n",
    "n_states = 5\n",
    "\n",
    "# Apply GPU accelerated HMM\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n",
    "    print(f\"Running HMM on: {tf.config.list_logical_devices()}\")\n",
    "    hidden_states = apply_gpu_hmm(eeg_signal_detrended, n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb07538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy is available for GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "# Alternative GPU-accelerated HMM using the hmmlearn library with CuPy if available\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(\"CuPy is available for GPU acceleration\")\n",
    "    # Use CuPy for GPU acceleration\n",
    "    def apply_hmm_cupy(signal, n_states):\n",
    "        # Move data to GPU\n",
    "        signal_gpu = cp.array(signal.reshape(-1, 1))\n",
    "        # Initialize and fit the model\n",
    "        model = hmm.GaussianHMM(n_components=n_states, covariance_type='diag', n_iter=100)\n",
    "        model.fit(cp.asnumpy(signal_gpu))  # Convert back to numpy for hmmlearn\n",
    "        # Predict states\n",
    "        hidden_states = model.predict(cp.asnumpy(signal_gpu))\n",
    "        return hidden_states\n",
    "    \n",
    "    # Apply CuPy accelerated HMM\n",
    "    hidden_states_cupy = apply_hmm_cupy(eeg_signal_detrended, n_states)\n",
    "    print(\"HMM computation completed using CuPy\")\n",
    "except ImportError:\n",
    "    print(\"CuPy is not available, using TensorFlow implementation only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f26191",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results\n",
    "Visualize the classified or clustered stages from the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(eeg_signal_detrended, label='Detrended Signal')\n",
    "plt.plot(hidden_states, label='Hidden States (GPU)', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('EEG Signal and Hidden States (GPU-accelerated HMM)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beefb06",
   "metadata": {},
   "source": [
    "## Performance Analysis: CPU vs GPU\n",
    "Compare the performance of CPU and GPU implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison between CPU and GPU implementations\n",
    "import time\n",
    "\n",
    "# CPU implementation\n",
    "def apply_hmm_cpu(signal, n_states):\n",
    "    model = hmm.GaussianHMM(n_components=n_states, covariance_type='diag', n_iter=100)\n",
    "    signal_reshaped = signal.reshape(-1, 1)\n",
    "    model.fit(signal_reshaped)\n",
    "    hidden_states = model.predict(signal_reshaped)\n",
    "    return hidden_states\n",
    "\n",
    "# Time the CPU implementation\n",
    "start_time = time.time()\n",
    "hidden_states_cpu = apply_hmm_cpu(eeg_signal_detrended, n_states)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU Implementation Time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# Time the GPU implementation\n",
    "start_time = time.time()\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n",
    "    hidden_states_gpu = apply_gpu_hmm(eeg_signal_detrended, n_states)\n",
    "gpu_time = time.time() - start_time\n",
    "print(f\"GPU Implementation Time: {gpu_time:.4f} seconds\")\n",
    "\n",
    "# Calculate speedup\n",
    "if gpu_time > 0:\n",
    "    print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "\n",
    "# Compare results\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(eeg_signal_detrended[:1000], label='Signal (first 1000 points)', alpha=0.7)\n",
    "plt.plot(hidden_states_cpu[:1000], label='CPU HMM', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('CPU Implementation')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(eeg_signal_detrended[:1000], label='Signal (first 1000 points)', alpha=0.7)\n",
    "plt.plot(hidden_states_gpu[:1000], label='GPU HMM', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('GPU Implementation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
