{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54969651",
   "metadata": {},
   "source": [
    "# Advanced Time Series Transformer + Clustering Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of detected sleep stage clusters using time series transformer embeddings followed by K-means clustering. We analyze cluster distributions, temporal dynamics, and frequency domain characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb31967",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustering results\n",
    "def load_clustering_results():\n",
    "    \"\"\"Load both 3s and 30s clustering results\"\"\"\n",
    "    \n",
    "    # Load 3-second window results\n",
    "    results_3s = {}\n",
    "    results_3s['csv'] = pd.read_csv('results/predicted_labels_3s_tst_20_files_20250530_131707.csv')\n",
    "    results_3s['npy'] = np.load('results/predicted_labels_3s_tst_20_files_20250530_131707.npy')\n",
    "    \n",
    "    with open('results/predicted_labels_3s_tst_20_files_20250530_131707_metadata.txt', 'r') as f:\n",
    "        results_3s['metadata'] = f.read()\n",
    "    \n",
    "    # Load 30-second window results\n",
    "    results_30s = {}\n",
    "    results_30s['csv'] = pd.read_csv('results/predicted_labels_30s_tst_3_files_20250523_181027.csv')\n",
    "    results_30s['npy'] = np.load('results/predicted_labels_30s_tst_3_files_20250523_181027.npy')\n",
    "    \n",
    "    with open('results/predicted_labels_30s_tst_3_files_20250523_181027_metadata.txt', 'r') as f:\n",
    "        results_30s['metadata'] = f.read()\n",
    "    \n",
    "    return results_3s, results_30s\n",
    "\n",
    "# Load original EEG data\n",
    "def load_eeg_data():\n",
    "    \"\"\"Load the original EEG signal for comparison\"\"\"\n",
    "    try:\n",
    "        # Load the EDF file\n",
    "        raw = mne.io.read_raw_edf('by captain borat/raw/SC4001E0-PSG.edf', preload=True)\n",
    "        \n",
    "        # Get EEG channels (assuming first channel is EEG)\n",
    "        eeg_data = raw.get_data()[0]  # First channel\n",
    "        fs = raw.info['sfreq']\n",
    "        \n",
    "        return eeg_data, fs, raw\n",
    "    except Exception as e:\n",
    "        print(f'Error loading EEG data: {e}')\n",
    "        return None, None, None\n",
    "\n",
    "# Load all data\n",
    "results_3s, results_30s = load_clustering_results()\n",
    "eeg_data, fs, raw_eeg = load_eeg_data()\n",
    "\n",
    "print(f'3s results shape: {results_3s[\"csv\"].shape}')\n",
    "print(f'30s results shape: {results_30s[\"csv\"].shape}')\n",
    "if eeg_data is not None:\n",
    "    print(f'EEG data shape: {eeg_data.shape}, Sampling rate: {fs} Hz')\n",
    "else:\n",
    "    print('EEG data not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00344711",
   "metadata": {},
   "source": [
    "## 2. Cluster Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b616eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the actual window durations to verify the issue\n",
    "print(\"=== Window Duration Analysis ===\")\n",
    "\n",
    "# Check 3s results\n",
    "df_3s = results_3s['csv']\n",
    "window_duration_3s = df_3s['end_time_sec'].iloc[0] - df_3s['start_time_sec'].iloc[0]\n",
    "print(f\"\\n3-second dataset:\")\n",
    "print(f\"  First few windows:\")\n",
    "for i in range(5):\n",
    "    start = df_3s['start_time_sec'].iloc[i]\n",
    "    end = df_3s['end_time_sec'].iloc[i]\n",
    "    duration = end - start\n",
    "    print(f\"    Window {i}: {start:.1f}s - {end:.1f}s (duration: {duration:.1f}s)\")\n",
    "print(f\"  Expected window duration: 3s, Actual: {window_duration_3s:.1f}s\")\n",
    "\n",
    "# Check 30s results  \n",
    "df_30s = results_30s['csv']\n",
    "window_duration_30s = df_30s['end_time_sec'].iloc[0] - df_30s['start_time_sec'].iloc[0]\n",
    "print(f\"\\n30-second dataset:\")\n",
    "print(f\"  First few windows:\")\n",
    "for i in range(5):\n",
    "    start = df_30s['start_time_sec'].iloc[i]\n",
    "    end = df_30s['end_time_sec'].iloc[i]\n",
    "    duration = end - start\n",
    "    print(f\"    Window {i}: {start:.1f}s - {end:.1f}s (duration: {duration:.1f}s)\")\n",
    "print(f\"  Expected window duration: 30s, Actual: {window_duration_30s:.1f}s\")\n",
    "\n",
    "# Check if there's a labeling issue\n",
    "print(f\"\\nTotal windows comparison:\")\n",
    "print(f\"  3s dataset: {len(df_3s)} windows\")\n",
    "print(f\"  30s dataset: {len(df_30s)} windows\")\n",
    "print(f\"  Expected ratio (3s:30s): ~10:1, Actual ratio: {len(df_3s)/len(df_30s):.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cluster_distribution(results, title_suffix):\n",
    "    \"\"\"Analyze and visualize cluster distributions\"\"\"\n",
    "    df = results['csv']\n",
    "    \n",
    "    # Basic statistics\n",
    "    cluster_counts = df['cluster_label'].value_counts().sort_index()\n",
    "    cluster_percentages = (cluster_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    print(f'\\n=== Cluster Distribution Analysis ({title_suffix}) ===')\n",
    "    print(f'Total windows: {len(df)}')\n",
    "    print(f'Total duration: {df[\"end_time_sec\"].max()/3600:.2f} hours')\n",
    "    print('\\nCluster distribution:')\n",
    "    for cluster in sorted(cluster_counts.index):\n",
    "        count = cluster_counts[cluster]\n",
    "        pct = cluster_percentages[cluster]\n",
    "        duration_min = count * (df['end_time_sec'][0] - df['start_time_sec'][0]) / 60\n",
    "        print(f'  Cluster {cluster}: {count:4d} windows ({pct:5.1f}%) - {duration_min:.1f} min')\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Cluster Distribution Analysis - {title_suffix}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Bar plot of counts\n",
    "    axes[0,0].bar(cluster_counts.index, cluster_counts.values, alpha=0.7)\n",
    "    axes[0,0].set_title('Cluster Counts')\n",
    "    axes[0,0].set_xlabel('Cluster Label')\n",
    "    axes[0,0].set_ylabel('Number of Windows')\n",
    "    for i, v in enumerate(cluster_counts.values):\n",
    "        axes[0,0].text(cluster_counts.index[i], v, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[0,1].pie(cluster_counts.values, labels=[f'Cluster {i}' for i in cluster_counts.index], \n",
    "                  autopct='%1.1f%%', startangle=90)\n",
    "    axes[0,1].set_title('Cluster Proportions')\n",
    "    \n",
    "    # Timeline visualization (first 2 hours)\n",
    "    df_subset = df[df['end_time_sec'] <= 7200].copy()  # First 2 hours\n",
    "    time_points = df_subset['start_time_sec'] / 60  # Convert to minutes\n",
    "    colors = plt.cm.Set1(df_subset['cluster_label'])\n",
    "    \n",
    "    axes[1,0].scatter(time_points, df_subset['cluster_label'], c=colors, alpha=0.6, s=20)\n",
    "    axes[1,0].set_title('Cluster Timeline (First 2 Hours)')\n",
    "    axes[1,0].set_xlabel('Time (minutes)')\n",
    "    axes[1,0].set_ylabel('Cluster Label')\n",
    "    axes[1,0].set_yticks(sorted(df['cluster_label'].unique()))\n",
    "    \n",
    "    # Cluster transitions\n",
    "    transitions = []\n",
    "    for i in range(1, len(df)):\n",
    "        if df.iloc[i]['cluster_label'] != df.iloc[i-1]['cluster_label']:\n",
    "            transitions.append((df.iloc[i-1]['cluster_label'], df.iloc[i]['cluster_label']))\n",
    "    \n",
    "    if transitions:\n",
    "        transition_df = pd.DataFrame(transitions, columns=['from_cluster', 'to_cluster'])\n",
    "        transition_matrix = pd.crosstab(transition_df['from_cluster'], transition_df['to_cluster'])\n",
    "        \n",
    "        sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Cluster Transition Matrix')\n",
    "        axes[1,1].set_xlabel('To Cluster')\n",
    "        axes[1,1].set_ylabel('From Cluster')\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'No transitions found', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "        axes[1,1].set_title('Cluster Transition Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cluster_counts, cluster_percentages\n",
    "\n",
    "# Analyze both datasets\n",
    "cluster_counts_3s, cluster_pct_3s = analyze_cluster_distribution(results_3s, '3-second windows')\n",
    "cluster_counts_30s, cluster_pct_30s = analyze_cluster_distribution(results_30s, '30-second windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d02c58",
   "metadata": {},
   "source": [
    "## 3. Continuous Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6449706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_continuous_durations(results, title_suffix):\n",
    "    \"\"\"Analyze continuous durations of each cluster\"\"\"\n",
    "    df = results['csv'].copy()\n",
    "    window_duration = df['end_time_sec'].iloc[0] - df['start_time_sec'].iloc[0]\n",
    "    \n",
    "    # Find continuous segments\n",
    "    segments = []\n",
    "    current_cluster = df['cluster_label'].iloc[0]\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        if df['cluster_label'].iloc[i] != current_cluster:\n",
    "            # End of current segment\n",
    "            duration = (i - start_idx) * window_duration\n",
    "            segments.append({\n",
    "                'cluster': current_cluster,\n",
    "                'start_time': df['start_time_sec'].iloc[start_idx],\n",
    "                'end_time': df['end_time_sec'].iloc[i-1],\n",
    "                'duration_sec': duration,\n",
    "                'duration_min': duration / 60,\n",
    "                'num_windows': i - start_idx\n",
    "            })\n",
    "            \n",
    "            # Start new segment\n",
    "            current_cluster = df['cluster_label'].iloc[i]\n",
    "            start_idx = i\n",
    "    \n",
    "    # Add final segment\n",
    "    duration = (len(df) - start_idx) * window_duration\n",
    "    segments.append({\n",
    "        'cluster': current_cluster,\n",
    "        'start_time': df['start_time_sec'].iloc[start_idx],\n",
    "        'end_time': df['end_time_sec'].iloc[-1],\n",
    "        'duration_sec': duration,\n",
    "        'duration_min': duration / 60,\n",
    "        'num_windows': len(df) - start_idx\n",
    "    })\n",
    "    \n",
    "    segments_df = pd.DataFrame(segments)\n",
    "    \n",
    "    print(f'\\n=== Continuous Duration Analysis ({title_suffix}) ===')\n",
    "    print(f'Total continuous segments: {len(segments_df)}')\n",
    "    \n",
    "    # Statistics by cluster\n",
    "    duration_stats = segments_df.groupby('cluster')['duration_min'].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "    ]).round(2)\n",
    "    \n",
    "    print('\\nDuration statistics by cluster (minutes):')\n",
    "    print(duration_stats)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Continuous Duration Analysis - {title_suffix}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Box plot of durations by cluster\n",
    "    cluster_labels = sorted(segments_df['cluster'].unique())\n",
    "    duration_data = [segments_df[segments_df['cluster'] == c]['duration_min'].values for c in cluster_labels]\n",
    "    \n",
    "    axes[0,0].boxplot(duration_data, labels=[f'Cluster {c}' for c in cluster_labels])\n",
    "    axes[0,0].set_title('Duration Distribution by Cluster')\n",
    "    axes[0,0].set_ylabel('Duration (minutes)')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Histogram of all durations\n",
    "    axes[0,1].hist(segments_df['duration_min'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_title('Overall Duration Distribution')\n",
    "    axes[0,1].set_xlabel('Duration (minutes)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Mean duration by cluster\n",
    "    mean_durations = segments_df.groupby('cluster')['duration_min'].mean()\n",
    "    axes[1,0].bar(mean_durations.index, mean_durations.values, alpha=0.7)\n",
    "    axes[1,0].set_title('Mean Duration by Cluster')\n",
    "    axes[1,0].set_xlabel('Cluster Label')\n",
    "    axes[1,0].set_ylabel('Mean Duration (minutes)')\n",
    "    for i, v in enumerate(mean_durations.values):\n",
    "        axes[1,0].text(mean_durations.index[i], v, f'{v:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Timeline of segments (first 4 hours)\n",
    "    segments_subset = segments_df[segments_df['start_time'] <= 14400].copy()  # First 4 hours\n",
    "    \n",
    "    for i, row in segments_subset.iterrows():\n",
    "        start_min = row['start_time'] / 60\n",
    "        end_min = row['end_time'] / 60\n",
    "        cluster = row['cluster']\n",
    "        axes[1,1].barh(cluster, end_min - start_min, left=start_min, \n",
    "                      alpha=0.7, label=f'Cluster {cluster}' if i == 0 else '')\n",
    "    \n",
    "    axes[1,1].set_title('Segment Timeline (First 4 Hours)')\n",
    "    axes[1,1].set_xlabel('Time (minutes)')\n",
    "    axes[1,1].set_ylabel('Cluster Label')\n",
    "    axes[1,1].set_yticks(sorted(segments_df['cluster'].unique()))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return segments_df, duration_stats\n",
    "\n",
    "# Analyze continuous durations\n",
    "segments_3s, duration_stats_3s = analyze_continuous_durations(results_3s, '3-second windows')\n",
    "segments_30s, duration_stats_30s = analyze_continuous_durations(results_30s, '30-second windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c62cf",
   "metadata": {},
   "source": [
    "## 4. Frequency Domain Analysis with Multitaper Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69208504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multitaper_spectrogram(eeg_data, fs, window_length=30, overlap=0.5):\n",
    "    \"\"\"Create multitaper spectrogram of EEG data\"\"\"\n",
    "    if eeg_data is None:\n",
    "        print('No EEG data available for spectrogram analysis')\n",
    "        return None, None, None\n",
    "    \n",
    "    # Parameters for spectrogram\n",
    "    nperseg = int(window_length * fs)\n",
    "    noverlap = int(nperseg * overlap)\n",
    "    \n",
    "    # Compute spectrogram (removed invalid 'method' parameter)\n",
    "    frequencies, times, Sxx = signal.spectrogram(\n",
    "        eeg_data, fs,\n",
    "        window='hann',\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap\n",
    "    )\n",
    "    \n",
    "    return frequencies, times, Sxx\n",
    "\n",
    "# Alternative function using scipy's built-in multitaper method\n",
    "def create_multitaper_psd(eeg_data, fs, window_length=30):\n",
    "    \"\"\"Create multitaper power spectral density\"\"\"\n",
    "    if eeg_data is None:\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # Use multitaper method for PSD estimation\n",
    "        from scipy import signal\n",
    "        nperseg = int(window_length * fs)\n",
    "        \n",
    "        # Calculate PSD using multitaper method\n",
    "        frequencies, psd = signal.welch(\n",
    "            eeg_data, fs,\n",
    "            window='hann',\n",
    "            nperseg=nperseg,\n",
    "            method='multitaper'\n",
    "        )\n",
    "        \n",
    "        return frequencies, psd\n",
    "    except Exception as e:\n",
    "        print(f'Multitaper PSD calculation failed: {e}')\n",
    "        # Fallback to regular welch method\n",
    "        frequencies, psd = signal.welch(\n",
    "            eeg_data, fs,\n",
    "            window='hann',\n",
    "            nperseg=nperseg\n",
    "        )\n",
    "        return frequencies, psd\n",
    "\n",
    "def analyze_frequency_bands(frequencies, Sxx, cluster_labels, times):\n",
    "    \"\"\"Analyze power in different frequency bands for each cluster\"\"\"\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'Delta (0.5-4 Hz)': (0.5, 4),\n",
    "        'Theta (4-8 Hz)': (4, 8),\n",
    "        'Alpha (8-13 Hz)': (8, 13),\n",
    "        'Beta (13-30 Hz)': (13, 30),\n",
    "        'Gamma (30-50 Hz)': (30, 50)\n",
    "    }\n",
    "    \n",
    "    # Calculate power in each band\n",
    "    band_powers = {}\n",
    "    \n",
    "    for band_name, (low_freq, high_freq) in bands.items():\n",
    "        # Find frequency indices\n",
    "        freq_mask = (frequencies >= low_freq) & (frequencies <= high_freq)\n",
    "        \n",
    "        if np.any(freq_mask):\n",
    "            # Calculate mean power in this band across time\n",
    "            band_power = np.mean(Sxx[freq_mask, :], axis=0)\n",
    "            band_powers[band_name] = band_power\n",
    "        else:\n",
    "            band_powers[band_name] = np.zeros(len(times))\n",
    "    \n",
    "    return band_powers\n",
    "\n",
    "def plot_frequency_analysis(eeg_data, fs, results, title_suffix):\n",
    "    \"\"\"Comprehensive frequency domain analysis\"\"\"\n",
    "    \n",
    "    if eeg_data is None:\n",
    "        print(f'Cannot perform frequency analysis for {title_suffix} - no EEG data')\n",
    "        return\n",
    "    \n",
    "    # Truncate EEG data to match clustering results duration\n",
    "    df = results['csv']\n",
    "    max_time = df['end_time_sec'].max()\n",
    "    eeg_truncated = eeg_data[:int(max_time * fs)]\n",
    "    \n",
    "    print(f'\\n=== Frequency Domain Analysis ({title_suffix}) ===')\n",
    "    print(f'EEG duration: {len(eeg_truncated)/fs/3600:.2f} hours')\n",
    "    print(f'Clustering duration: {max_time/3600:.2f} hours')\n",
    "    \n",
    "    # Create spectrogram (fixed function call)\n",
    "    frequencies, times, Sxx = create_multitaper_spectrogram(eeg_truncated, fs)\n",
    "    \n",
    "    if frequencies is None:\n",
    "        return\n",
    "    \n",
    "    # Convert power to dB\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "    \n",
    "    # Create cluster labels aligned with spectrogram times\n",
    "    cluster_times = []\n",
    "    cluster_labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        start_time = row['start_time_sec']\n",
    "        end_time = row['end_time_sec']\n",
    "        cluster = row['cluster_label']\n",
    "        \n",
    "        # Find corresponding time indices in spectrogram\n",
    "        time_mask = (times >= start_time) & (times < end_time)\n",
    "        cluster_times.extend(times[time_mask])\n",
    "        cluster_labels.extend([cluster] * np.sum(time_mask))\n",
    "    \n",
    "    # Analyze frequency bands\n",
    "    band_powers = analyze_frequency_bands(frequencies, Sxx, cluster_labels, times)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Full spectrogram\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    im1 = ax1.pcolormesh(times/60, frequencies, Sxx_db, shading='gouraud', cmap='viridis')\n",
    "    ax1.set_ylabel('Frequency (Hz)')\n",
    "    ax1.set_title(f'Spectrogram - {title_suffix}')\n",
    "    ax1.set_ylim([0, 50])\n",
    "    plt.colorbar(im1, ax=ax1, label='Power (dB)')\n",
    "    \n",
    "    # 2. Cluster overlay on spectrogram (first 2 hours)\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    time_subset = times <= 7200  # First 2 hours\n",
    "    im2 = ax2.pcolormesh(times[time_subset]/60, frequencies, Sxx_db[:, time_subset], \n",
    "                        shading='gouraud', cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # Overlay cluster information\n",
    "    df_subset = df[df['end_time_sec'] <= 7200]\n",
    "    for _, row in df_subset.iterrows():\n",
    "        start_min = row['start_time_sec'] / 60\n",
    "        end_min = row['end_time_sec'] / 60\n",
    "        cluster = int(row['cluster_label'])  # Ensure integer\n",
    "        color_idx = cluster % 10  # Use modulo to stay within colormap range\n",
    "        ax2.axvspan(start_min, end_min, ymin=0.95, ymax=1.0, \n",
    "                   color=plt.cm.Set1(color_idx), alpha=0.8)\n",
    "    \n",
    "    ax2.set_ylabel('Frequency (Hz)')\n",
    "    ax2.set_xlabel('Time (minutes)')\n",
    "    ax2.set_title('Spectrogram with Cluster Overlay (First 2 Hours)')\n",
    "    ax2.set_ylim([0, 50])\n",
    "    plt.colorbar(im2, ax=ax2, label='Power (dB)')\n",
    "    \n",
    "    # 3-6. Frequency band analysis by cluster\n",
    "    band_names = list(band_powers.keys())[:4]  # Show first 4 bands\n",
    "    \n",
    "    for i, band_name in enumerate(band_names):\n",
    "        ax = fig.add_subplot(gs[2 + i//2, i%2])\n",
    "        \n",
    "        # Calculate mean power per cluster\n",
    "        cluster_band_power = {}\n",
    "        for cluster in sorted(df['cluster_label'].unique()):\n",
    "            cluster_mask = np.array(cluster_labels) == cluster\n",
    "            if np.any(cluster_mask):\n",
    "                cluster_times_subset = np.array(cluster_times)[cluster_mask]\n",
    "                time_indices = [np.argmin(np.abs(times - t)) for t in cluster_times_subset]\n",
    "                # Ensure indices are integers and within bounds\n",
    "                time_indices = [int(idx) for idx in time_indices if 0 <= int(idx) < len(band_powers[band_name])]\n",
    "                if time_indices:\n",
    "                    power_values = band_powers[band_name][time_indices]\n",
    "                    cluster_band_power[cluster] = np.mean(power_values)\n",
    "                else:\n",
    "                    cluster_band_power[cluster] = 0\n",
    "            else:\n",
    "                cluster_band_power[cluster] = 0\n",
    "        \n",
    "        clusters = list(cluster_band_power.keys())\n",
    "        powers = list(cluster_band_power.values())\n",
    "        \n",
    "        # Use safe color indexing\n",
    "        colors_safe = [plt.cm.Set1(int(c) % 10) for c in clusters]\n",
    "        bars = ax.bar(clusters, powers, alpha=0.7, color=colors_safe)\n",
    "        ax.set_title(f'{band_name} Power by Cluster')\n",
    "        ax.set_xlabel('Cluster Label')\n",
    "        ax.set_ylabel('Mean Power')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, power in zip(bars, powers):\n",
    "            if power > 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                       f'{power:.2e}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 7. Power spectral density by cluster\n",
    "    ax7 = fig.add_subplot(gs[3, 2])\n",
    "    \n",
    "    for cluster in sorted(df['cluster_label'].unique()):\n",
    "        cluster_mask = np.array(cluster_labels) == cluster\n",
    "        if np.any(cluster_mask):\n",
    "            cluster_times_subset = np.array(cluster_times)[cluster_mask]\n",
    "            # Fix: Convert time indices to integers and add bounds checking\n",
    "            time_indices = []\n",
    "            for t in cluster_times_subset:\n",
    "                idx = np.argmin(np.abs(times - t))\n",
    "                # Ensure index is integer and within bounds\n",
    "                idx = int(idx)\n",
    "                if 0 <= idx < Sxx.shape[1]:\n",
    "                    time_indices.append(idx)\n",
    "            \n",
    "            if time_indices:  # Only proceed if we have valid indices\n",
    "                mean_psd = np.mean(Sxx[:, time_indices], axis=1)\n",
    "                ax7.semilogy(frequencies, mean_psd, label=f'Cluster {cluster}', alpha=0.8)\n",
    "    \n",
    "    ax7.set_xlabel('Frequency (Hz)')\n",
    "    ax7.set_ylabel('Power Spectral Density')\n",
    "    ax7.set_title('Mean PSD by Cluster')\n",
    "    ax7.set_xlim([0, 50])\n",
    "    ax7.legend()\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Comprehensive Frequency Analysis - {title_suffix}', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return frequencies, times, Sxx_db, band_powers\n",
    "\n",
    "# Perform frequency analysis\n",
    "if eeg_data is not None:\n",
    "    freq_results_3s = plot_frequency_analysis(eeg_data, fs, results_3s, '3-second windows')\n",
    "    freq_results_30s = plot_frequency_analysis(eeg_data, fs, results_30s, '30-second windows')\n",
    "else:\n",
    "    print('EEG data not available - skipping frequency analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0181b2",
   "metadata": {},
   "source": [
    "## 5. Interactive Hypnogram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_hypnogram(results_3s, results_30s):\n",
    "    \"\"\"Create interactive hypnogram comparison\"\"\"\n",
    "    \n",
    "    # Prepare data for 3s results\n",
    "    df_3s = results_3s['csv'].copy()\n",
    "    df_3s['time_hours'] = df_3s['start_time_sec'] / 3600\n",
    "    df_3s['window_type'] = '3-second'\n",
    "    \n",
    "    # Prepare data for 30s results\n",
    "    df_30s = results_30s['csv'].copy()\n",
    "    df_30s['time_hours'] = df_30s['start_time_sec'] / 3600\n",
    "    df_30s['window_type'] = '30-second'\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('3-Second Window Clustering', '30-Second Window Clustering'),\n",
    "        vertical_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # Color mapping for clusters\n",
    "    colors = px.colors.qualitative.Set1\n",
    "    \n",
    "    # Plot 3s results\n",
    "    for cluster in sorted(df_3s['cluster_label'].unique()):\n",
    "        cluster_data = df_3s[df_3s['cluster_label'] == cluster]\n",
    "        # Fix: Ensure cluster index is integer for color selection\n",
    "        color_idx = int(cluster) % len(colors)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cluster_data['time_hours'],\n",
    "                y=cluster_data['cluster_label'],\n",
    "                mode='markers',\n",
    "                marker=dict(color=colors[color_idx], size=4),\n",
    "                name=f'3s Cluster {cluster}',\n",
    "                legendgroup=f'3s_{cluster}',\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Plot 30s results (limit to same time range as 3s)\n",
    "    max_time_3s = df_3s['time_hours'].max()\n",
    "    df_30s_subset = df_30s[df_30s['time_hours'] <= max_time_3s]\n",
    "    \n",
    "    for cluster in sorted(df_30s_subset['cluster_label'].unique()):\n",
    "        cluster_data = df_30s_subset[df_30s_subset['cluster_label'] == cluster]\n",
    "        # Fix: Ensure cluster index is integer for color selection\n",
    "        color_idx = int(cluster) % len(colors)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cluster_data['time_hours'],\n",
    "                y=cluster_data['cluster_label'],\n",
    "                mode='markers',\n",
    "                marker=dict(color=colors[color_idx], size=8, symbol='square'),\n",
    "                name=f'30s Cluster {cluster}',\n",
    "                legendgroup=f'30s_{cluster}',\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Interactive Hypnogram Comparison: Time Series Transformer + Clustering Results',\n",
    "        height=800,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text='Time (hours)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Cluster Label', dtick=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create interactive hypnogram\n",
    "interactive_fig = create_interactive_hypnogram(results_3s, results_30s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_synchronized_plot(eeg_data, fs, results, title_suffix, start_time_hours, duration_hours):\n",
    "    \"\"\"Create interactive synchronized plot with EEG, spectrogram, and hypnogram with synchronized selection/zooming\"\"\"\n",
    "    \n",
    "    if eeg_data is None:\n",
    "        print('No EEG data available for synchronized plot')\n",
    "        return None\n",
    "    \n",
    "    # Convert time parameters to seconds\n",
    "    start_time_sec = start_time_hours * 3600\n",
    "    duration_sec = duration_hours * 3600\n",
    "    end_time_sec = start_time_sec + duration_sec\n",
    "    \n",
    "    # Extract EEG segment\n",
    "    start_idx = int(start_time_sec * fs)\n",
    "    end_idx = int(end_time_sec * fs)\n",
    "    eeg_segment = eeg_data[start_idx:end_idx]\n",
    "    \n",
    "    # Create time array for EEG\n",
    "    eeg_time = np.linspace(start_time_hours, start_time_hours + duration_hours, len(eeg_segment))\n",
    "    \n",
    "    # Extract clustering results for this time segment\n",
    "    df = results['csv'].copy()\n",
    "    df_segment = df[(df['start_time_sec'] >= start_time_sec) & (df['end_time_sec'] <= end_time_sec)].copy()\n",
    "    df_segment['time_hours'] = df_segment['start_time_sec'] / 3600\n",
    "    \n",
    "    # Create spectrogram for the segment\n",
    "    window_length = 10  # seconds for spectrogram\n",
    "    nperseg = int(window_length * fs)\n",
    "    noverlap = int(nperseg * 0.75)\n",
    "    \n",
    "    frequencies, times_spec, Sxx = signal.spectrogram(\n",
    "        eeg_segment, fs,\n",
    "        window='hann',\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap\n",
    "    )\n",
    "    \n",
    "    # Convert spectrogram time to hours (relative to start)\n",
    "    times_spec_hours = start_time_hours + times_spec / 3600\n",
    "    \n",
    "    # Convert power to dB\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "    \n",
    "    # Create subplot figure with synchronized axes\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        row_heights=[0.3, 0.4, 0.3],\n",
    "        subplot_titles=(\n",
    "            f'EEG Signal - {title_suffix}',\n",
    "            f'Multitaper Spectrogram - {title_suffix}',\n",
    "            f'Hypnogram - {title_suffix}'\n",
    "        ),\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    # 1. EEG Signal Plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=eeg_time,\n",
    "            y=eeg_segment,\n",
    "            mode='lines',\n",
    "            name='EEG Signal',\n",
    "            line=dict(color='blue', width=0.5),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Spectrogram Plot\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=times_spec_hours,\n",
    "            y=frequencies,\n",
    "            z=Sxx_db,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(\n",
    "                title='Power (dB)',\n",
    "                x=1.02,\n",
    "                y=0.5,\n",
    "                len=0.4\n",
    "            ),\n",
    "            hovertemplate='Time: %{x:.2f} hrs<br>Frequency: %{y:.1f} Hz<br>Power: %{z:.1f} dB<extra></extra>',\n",
    "            showscale=True\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 3. Hypnogram with cluster transitions\n",
    "    colors = px.colors.qualitative.Set1\n",
    "    \n",
    "    # Create step plot for hypnogram\n",
    "    for cluster in sorted(df_segment['cluster_label'].unique()):\n",
    "        cluster_data = df_segment[df_segment['cluster_label'] == cluster]\n",
    "        \n",
    "        # Create step-like visualization\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        \n",
    "        for _, row in cluster_data.iterrows():\n",
    "            start_hour = row['start_time_sec'] / 3600\n",
    "            end_hour = row['end_time_sec'] / 3600\n",
    "            cluster_val = row['cluster_label']\n",
    "            \n",
    "            # Add points for step function\n",
    "            x_vals.extend([start_hour, end_hour, end_hour])\n",
    "            y_vals.extend([cluster_val, cluster_val, None])  # None creates a break\n",
    "        \n",
    "        color_idx = int(cluster) % len(colors)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_vals,\n",
    "                y=y_vals,\n",
    "                mode='lines',\n",
    "                line=dict(color=colors[color_idx], width=3),\n",
    "                name=f'Cluster {cluster}',\n",
    "                hovertemplate='Time: %{x:.2f} hrs<br>Cluster: %{y}<extra></extra>',\n",
    "                connectgaps=False\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # Add cluster blocks for better visualization\n",
    "    for _, row in df_segment.iterrows():\n",
    "        start_hour = row['start_time_sec'] / 3600\n",
    "        end_hour = row['end_time_sec'] / 3600\n",
    "        cluster = int(row['cluster_label'])\n",
    "        color_idx = cluster % len(colors)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[start_hour, end_hour, end_hour, start_hour, start_hour],\n",
    "                y=[cluster-0.4, cluster-0.4, cluster+0.4, cluster+0.4, cluster-0.4],\n",
    "                fill='toself',\n",
    "                fillcolor=colors[color_idx],\n",
    "                opacity=0.3,\n",
    "                line=dict(width=0),\n",
    "                showlegend=False,\n",
    "                hoverinfo='skip'\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # Update layout for synchronized zooming and panning\n",
    "    fig.update_layout(\n",
    "        title=f'Synchronized EEG Analysis - {title_suffix}<br>Time Range: {start_time_hours:.1f} - {start_time_hours + duration_hours:.1f} hours',\n",
    "        height=1000,\n",
    "        hovermode='x unified',\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Update x-axes\n",
    "    fig.update_xaxes(\n",
    "        title_text='Time (hours)',\n",
    "        row=3, col=1,\n",
    "        rangeslider=dict(visible=True, thickness=0.05),\n",
    "        type='linear'\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    fig.update_yaxes(title_text='Amplitude (µV)', row=1, col=1)\n",
    "    fig.update_yaxes(\n",
    "        title_text='Frequency (Hz)',\n",
    "        row=2, col=1,\n",
    "        range=[0, 50]  # Focus on relevant frequency range\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='Cluster Label',\n",
    "        row=3, col=1,\n",
    "        dtick=1,\n",
    "        range=[-0.5, max(df_segment['cluster_label']) + 0.5]\n",
    "    )\n",
    "    \n",
    "    # Add annotation with statistics\n",
    "    total_windows = len(df_segment)\n",
    "    cluster_counts = df_segment['cluster_label'].value_counts().sort_index()\n",
    "    stats_text = f\"Total windows: {total_windows}<br>\"\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        pct = (count / total_windows) * 100\n",
    "        stats_text += f\"Cluster {cluster}: {count} ({pct:.1f}%)<br>\"\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=stats_text,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.02, y=0.98,\n",
    "        showarrow=False,\n",
    "        align=\"left\",\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def interactive_segment_analyzer(eeg_data, fs, results_3s, results_30s, start_hours, duration_hours):\n",
    "    \"\"\"Interactive function to analyze different time segments\"\"\"\n",
    "    \n",
    "    print(\"=== Interactive Synchronized EEG/Spectrogram/Hypnogram Analyzer ===\")\n",
    "    print(\"\\nAvailable functions:\")\n",
    "    print(\"1. plot_3s_segment(start_hours, duration_hours) - Analyze 3-second results\")\n",
    "    print(\"2. plot_30s_segment(start_hours, duration_hours) - Analyze 30-second results\")\n",
    "    print(\"3. compare_segments(start_hours, duration_hours) - Compare both window sizes\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"  fig_3s = plot_3s_segment(0, 2)     # First 2 hours with 3s windows\")\n",
    "    print(\"  fig_30s = plot_30s_segment(4, 1)   # Hour 4-5 with 30s windows\")\n",
    "    print(\"  compare_segments(8, 4)             # Hours 8-12 comparison\")\n",
    "    \n",
    "    def plot_3s_segment(start_hours, duration_hours):\n",
    "        \"\"\"Plot synchronized analysis for 3-second windows\"\"\"\n",
    "        return create_interactive_synchronized_plot(\n",
    "            eeg_data, fs, results_3s, '3-second windows', start_hours, duration_hours\n",
    "        )\n",
    "    \n",
    "    def plot_30s_segment(start_hours, duration_hours):\n",
    "        \"\"\"Plot synchronized analysis for 30-second windows\"\"\"\n",
    "        return create_interactive_synchronized_plot(\n",
    "            eeg_data, fs, results_30s, '30-second windows', start_hours, duration_hours\n",
    "        )\n",
    "    \n",
    "    def compare_segments(start_hours, duration_hours):\n",
    "        \"\"\"Compare both window sizes side by side\"\"\"\n",
    "        fig_3s = plot_3s_segment(start_hours, duration_hours)\n",
    "        fig_30s = plot_30s_segment(start_hours, duration_hours)\n",
    "        \n",
    "        if fig_3s and fig_30s:\n",
    "            print(f\"\\nComparison for time range: {start_hours:.1f} - {start_hours + duration_hours:.1f} hours\")\n",
    "            fig_3s.show()\n",
    "            fig_30s.show()\n",
    "            \n",
    "            # Print comparison statistics\n",
    "            df_3s = results_3s['csv']\n",
    "            df_30s = results_30s['csv']\n",
    "            \n",
    "            start_sec = start_hours * 3600\n",
    "            end_sec = (start_hours + duration_hours) * 3600\n",
    "            \n",
    "            df_3s_seg = df_3s[(df_3s['start_time_sec'] >= start_sec) & (df_3s['end_time_sec'] <= end_sec)]\n",
    "            df_30s_seg = df_30s[(df_30s['start_time_sec'] >= start_sec) & (df_30s['end_time_sec'] <= end_sec)]\n",
    "            \n",
    "            print(f\"\\n3-second windows: {len(df_3s_seg)} windows\")\n",
    "            print(f\"30-second windows: {len(df_30s_seg)} windows\")\n",
    "            print(f\"Resolution ratio: {len(df_3s_seg) / max(len(df_30s_seg), 1):.1f}:1\")\n",
    "            \n",
    "            return fig_3s, fig_30s\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    # Return the functions for interactive use\n",
    "    return plot_3s_segment, plot_30s_segment, compare_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the interactive analyzer\n",
    "start_hours=12\n",
    "duration_hours=1\n",
    "\n",
    "eeg_data, fs, raw_eeg = load_eeg_data()\n",
    "if eeg_data is not None:\n",
    "    plot_3s_segment, plot_30s_segment, compare_segments = interactive_segment_analyzer(\n",
    "        eeg_data, fs, results_3s, results_30s, start_hours, duration_hours\n",
    "    )\n",
    "    \n",
    "    # Create default plots for the first 2 hours\n",
    "    print(\"\\nCreating default synchronized plots for the first 2 hours...\")\n",
    "    default_fig_3s = plot_3s_segment(start_hours, duration_hours)\n",
    "    default_fig_30s = plot_30s_segment(start_hours, duration_hours)\n",
    "    \n",
    "    if default_fig_3s:\n",
    "        default_fig_3s.show()\n",
    "    if default_fig_30s:\n",
    "        default_fig_30s.show()\n",
    "        \n",
    "else:\n",
    "    print(\"EEG data not available - cannot create synchronized plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb11b2",
   "metadata": {},
   "source": [
    "## 6. Advanced Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caff769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_cluster_statistics(results, title_suffix):\n",
    "    \"\"\"Perform advanced statistical analysis of clustering results\"\"\"\n",
    "    df = results['csv'].copy()\n",
    "    \n",
    "    print(f'\\n=== Advanced Statistical Analysis ({title_suffix}) ===')\n",
    "    \n",
    "    # 1. Temporal distribution analysis\n",
    "    df['hour'] = (df['start_time_sec'] / 3600).astype(int)\n",
    "    hourly_distribution = df.groupby(['hour', 'cluster_label']).size().unstack(fill_value=0)\n",
    "    \n",
    "    print('\\n1. Hourly Distribution of Clusters:')\n",
    "    print(hourly_distribution)\n",
    "    \n",
    "    # 2. Cluster stability analysis (consecutive same-cluster windows)\n",
    "    stability_scores = []\n",
    "    current_cluster = df['cluster_label'].iloc[0]\n",
    "    current_length = 1\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        if df['cluster_label'].iloc[i] == current_cluster:\n",
    "            current_length += 1\n",
    "        else:\n",
    "            stability_scores.append(current_length)\n",
    "            current_cluster = df['cluster_label'].iloc[i]\n",
    "            current_length = 1\n",
    "    stability_scores.append(current_length)\n",
    "    \n",
    "    print(f'\\n2. Cluster Stability Analysis:')\n",
    "    print(f'   Mean consecutive windows: {np.mean(stability_scores):.2f}')\n",
    "    print(f'   Median consecutive windows: {np.median(stability_scores):.2f}')\n",
    "    print(f'   Max consecutive windows: {np.max(stability_scores)}')\n",
    "    print(f'   Number of segments: {len(stability_scores)}')\n",
    "    \n",
    "    # 3. Circadian rhythm analysis (if data spans multiple hours)\n",
    "    if df['hour'].max() >= 4:  # At least 4 hours of data\n",
    "        print(f'\\n3. Circadian Pattern Analysis:')\n",
    "        for cluster in sorted(df['cluster_label'].unique()):\n",
    "            cluster_hours = df[df['cluster_label'] == cluster]['hour'].values\n",
    "            if len(cluster_hours) > 0:\n",
    "                # Fix: Handle the mode calculation properly\n",
    "                try:\n",
    "                    mode_result = stats.mode(cluster_hours, keepdims=False)\n",
    "                    if hasattr(mode_result, 'mode'):\n",
    "                        peak_hour = mode_result.mode\n",
    "                    else:\n",
    "                        peak_hour = mode_result[0]\n",
    "                    print(f'   Cluster {cluster}: Peak activity at hour {peak_hour}')\n",
    "                except Exception as e:\n",
    "                    # Fallback to manual mode calculation\n",
    "                    from collections import Counter\n",
    "                    hour_counts = Counter(cluster_hours)\n",
    "                    peak_hour = hour_counts.most_common(1)[0][0]\n",
    "                    print(f'   Cluster {cluster}: Peak activity at hour {peak_hour}')\n",
    "    \n",
    "    # 4. Transition analysis\n",
    "    transitions = []\n",
    "    for i in range(1, len(df)):\n",
    "        prev_cluster = df['cluster_label'].iloc[i-1]\n",
    "        curr_cluster = df['cluster_label'].iloc[i]\n",
    "        if prev_cluster != curr_cluster:\n",
    "            transitions.append((prev_cluster, curr_cluster))\n",
    "    \n",
    "    if transitions:\n",
    "        transition_counts = pd.Series(transitions).value_counts()\n",
    "        print(f'\\n4. Most Common Transitions:')\n",
    "        print(transition_counts.head(10))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Advanced Statistical Analysis - {title_suffix}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Hourly distribution heatmap\n",
    "    if not hourly_distribution.empty:\n",
    "        sns.heatmap(hourly_distribution.T, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Hourly Cluster Distribution')\n",
    "        axes[0,0].set_xlabel('Hour of Recording')\n",
    "        axes[0,0].set_ylabel('Cluster Label')\n",
    "    \n",
    "    # Stability distribution\n",
    "    axes[0,1].hist(stability_scores, bins=min(30, len(set(stability_scores))), alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution of Consecutive Window Lengths')\n",
    "    axes[0,1].set_xlabel('Consecutive Windows')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].axvline(np.mean(stability_scores), color='red', linestyle='--', label=f'Mean: {np.mean(stability_scores):.1f}')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # Cluster proportion over time (sliding window)\n",
    "    window_size = max(100, len(df) // 20)  # Adaptive window size\n",
    "    time_points = []\n",
    "    cluster_props = {c: [] for c in sorted(df['cluster_label'].unique())}\n",
    "    \n",
    "    for i in range(window_size, len(df), window_size//2):\n",
    "        window_data = df.iloc[i-window_size:i]\n",
    "        time_points.append(window_data['start_time_sec'].mean() / 3600)\n",
    "        \n",
    "        for cluster in cluster_props.keys():\n",
    "            prop = (window_data['cluster_label'] == cluster).mean()\n",
    "            cluster_props[cluster].append(prop)\n",
    "    \n",
    "    for cluster, props in cluster_props.items():\n",
    "        if len(props) > 0:\n",
    "            axes[1,0].plot(time_points, props, marker='o', label=f'Cluster {cluster}', alpha=0.7)\n",
    "    \n",
    "    axes[1,0].set_title('Cluster Proportions Over Time')\n",
    "    axes[1,0].set_xlabel('Time (hours)')\n",
    "    axes[1,0].set_ylabel('Proportion')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Autocorrelation of cluster sequence\n",
    "    cluster_sequence = df['cluster_label'].values\n",
    "    max_lag = min(100, len(cluster_sequence) // 4)\n",
    "    \n",
    "    autocorr = []\n",
    "    for lag in range(max_lag):\n",
    "        if lag == 0:\n",
    "            autocorr.append(1.0)\n",
    "        else:\n",
    "            # Fix: Ensure proper array indexing and handle edge cases\n",
    "            if lag < len(cluster_sequence):\n",
    "                corr_val = np.corrcoef(cluster_sequence[:-lag], cluster_sequence[lag:])[0,1]\n",
    "                # Handle NaN values\n",
    "                if np.isnan(corr_val):\n",
    "                    corr_val = 0.0\n",
    "                autocorr.append(corr_val)\n",
    "            else:\n",
    "                autocorr.append(0.0)\n",
    "    \n",
    "    axes[1,1].plot(range(len(autocorr)), autocorr, marker='o', markersize=3)\n",
    "    axes[1,1].set_title('Autocorrelation of Cluster Sequence')\n",
    "    axes[1,1].set_xlabel('Lag (windows)')\n",
    "    axes[1,1].set_ylabel('Autocorrelation')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    axes[1,1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    return {\n",
    "        'hourly_distribution': hourly_distribution,\n",
    "        'stability_scores': stability_scores,\n",
    "        'transitions': transitions,\n",
    "        'autocorr': autocorr\n",
    "    }\n",
    "\n",
    "# Perform advanced statistical analysis\n",
    "stats_3s = advanced_cluster_statistics(results_3s, '3-second windows')\n",
    "stats_30s = advanced_cluster_statistics(results_30s, '30-second windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56cc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
