{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa8e633",
   "metadata": {},
   "source": [
    "# BiLSTM Sleep Stage Clustering Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of BiLSTM-based sleep stage clustering results including:\n",
    "- Interactive hypnogram visualization\n",
    "- EEG signal segment analysis\n",
    "- Cluster distribution and duration analysis\n",
    "- Multitaper spectrogram analysis\n",
    "- Frequency band dominance analysis\n",
    "\n",
    "**Data Sources:**\n",
    "- Model results: `bilstm_30s_4clusters.pkl`\n",
    "- Metadata: `bilstm_30s_4clusters_metadata.json`\n",
    "- EEG signal: `EEG_0_per_hour_2024-03-20 17_12_18.edf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import mne\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as colors\n",
    "from scipy import signal\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.style.use('seaborn-v0_8')\n",
    "px.defaults.template = 'plotly_white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "with open('results/bilstm_30s_4clusters_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"Model Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Load BiLSTM results using CPU only\n",
    "with open('results/bilstm_30s_4clusters.pkl', 'rb') as f:\n",
    "    results = pickle.load(f, encoding='latin1')  # Ensure compatibility with CPU\n",
    "\n",
    "print(\"\\nLoaded results keys:\")\n",
    "for key in results.keys():\n",
    "    print(f\"- {key}: {type(results[key])}\")\n",
    "    if hasattr(results[key], 'shape'):\n",
    "        print(f\"  Shape: {results[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf97a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEG data\n",
    "try:\n",
    "\t# Try the original path\n",
    "\teeg_file = 'by captain borat/raw/EEG_0_per_hour_2024-03-20 17_12_18.edf'\n",
    "\traw = mne.io.read_raw_edf(eeg_file, preload=True, verbose=False)\n",
    "except FileNotFoundError:\n",
    "\t# If the file doesn't exist at the original path, look in the local directory\n",
    "\tprint(\"Original file not found. Attempting to find in current directory...\")\n",
    "\ttry:\n",
    "\t\teeg_file = 'EEG_0_per_hour_2024-03-20 17_12_18.edf'\n",
    "\t\traw = mne.io.read_raw_edf(eeg_file, preload=True, verbose=False)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(\"EDF file not found. Creating simulated data for demonstration...\")\n",
    "\t\t# Create simulated EEG data\n",
    "\t\tduration = 86400  # 24 hours in seconds\n",
    "\t\tfs = 512  # Sampling frequency from metadata\n",
    "\t\tn_samples = int(duration * fs)\n",
    "\t\ttime_vector = np.arange(n_samples) / fs\n",
    "\t\t\n",
    "\t\t# Generate some random EEG-like data\n",
    "\t\tnp.random.seed(42)\n",
    "\t\teeg_data = np.random.randn(n_samples) * 50  # Typical EEG amplitude\n",
    "\t\t\n",
    "\t\t# Add some oscillations to make it more EEG-like\n",
    "\t\tfor freq in [0.5, 3, 8, 12, 20]:  # Delta, theta, alpha, beta\n",
    "\t\t\teeg_data += np.sin(2 * np.pi * freq * time_vector) * (100 / (freq + 5))\n",
    "\t\t\t\n",
    "\t\t# Create fake raw object with channel info\n",
    "\t\tinfo = mne.create_info(['EEG'], sfreq=fs, ch_types=['eeg'])\n",
    "\t\traw = mne.io.RawArray(eeg_data.reshape(1, -1), info)\n",
    "\t\tprint(\"Created simulated EEG data for demonstration\")\n",
    "\n",
    "print(f\"EEG Data Info:\")\n",
    "print(f\"Sampling frequency: {raw.info['sfreq']} Hz\")\n",
    "print(f\"Number of channels: {len(raw.ch_names)}\")\n",
    "print(f\"Channel names: {raw.ch_names}\")\n",
    "print(f\"Duration: {raw.times[-1]:.2f} seconds ({raw.times[-1]/3600:.2f} hours)\")\n",
    "\n",
    "# Get EEG data (assuming first channel is EEG)\n",
    "eeg_data = raw.get_data()[0]  # First channel\n",
    "fs = raw.info['sfreq']\n",
    "time_vector = np.arange(len(eeg_data)) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clustering results - OPTIMIZED VERSION\n",
    "cluster_labels = None\n",
    "\n",
    "# Try common cluster label keys efficiently\n",
    "possible_keys = ['cluster_labels', 'labels', 'predictions', 'y_pred', 'clusters']\n",
    "\n",
    "print(\"Searching for cluster labels...\")\n",
    "for key in possible_keys:\n",
    "    if key in results:\n",
    "        cluster_labels = results[key]\n",
    "        print(f\"Found cluster labels in '{key}'\")\n",
    "        break\n",
    "\n",
    "# Check nested results if not found\n",
    "if cluster_labels is None and 'results' in results:\n",
    "    nested_results = results['results']\n",
    "    for key in possible_keys:\n",
    "        if key in nested_results:\n",
    "            cluster_labels = nested_results[key]\n",
    "            print(f\"Found cluster labels in 'results.{key}'\")\n",
    "            break\n",
    "\n",
    "# If still not found, show available keys and try first array-like object\n",
    "if cluster_labels is None:\n",
    "    print(\"Cluster labels not found in expected keys. Available keys:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"  {key}: {type(value)}\")\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"    Shape: {value.shape}\")\n",
    "            # Try to use first array-like object as cluster labels\n",
    "            if cluster_labels is None and len(value.shape) == 1:\n",
    "                cluster_labels = value\n",
    "                print(f\"    Using '{key}' as cluster labels (first 1D array found)\")\n",
    "\n",
    "if cluster_labels is None:\n",
    "    raise ValueError(\"Could not find cluster labels in the results. Please check the data structure.\")\n",
    "\n",
    "# Convert to numpy array for efficiency\n",
    "cluster_labels = np.array(cluster_labels)\n",
    "\n",
    "# Create time alignment for clusters\n",
    "window_size = metadata['window_size_seconds']\n",
    "overlap = metadata['overlap']\n",
    "step_size = window_size * (1 - overlap)\n",
    "\n",
    "# Calculate cluster timestamps efficiently\n",
    "n_clusters = len(cluster_labels)\n",
    "cluster_times = np.arange(n_clusters, dtype=np.float32) * step_size\n",
    "\n",
    "print(f\"âœ“ Successfully extracted clustering results:\")\n",
    "print(f\"  Number of cluster windows: {n_clusters:,}\")\n",
    "print(f\"  Window size: {window_size}s\")\n",
    "print(f\"  Step size: {step_size}s\")\n",
    "print(f\"  Total duration covered: {cluster_times[-1] + window_size:.2f}s ({(cluster_times[-1] + window_size)/3600:.2f}h)\")\n",
    "print(f\"  Unique clusters: {np.unique(cluster_labels)}\")\n",
    "print(f\"  Cluster distribution: {dict(zip(*np.unique(cluster_labels, return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad223ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive hypnogram - OPTIMIZED VERSION\n",
    "def create_hypnogram_optimized(cluster_labels, cluster_times, window_size, max_points=5000):\n",
    "    \"\"\"Create an interactive hypnogram using Plotly - optimized for large datasets\"\"\"\n",
    "    \n",
    "    # Define colors for different clusters\n",
    "    cluster_colors = {\n",
    "        0: '#1f77b4',  # Blue\n",
    "        1: '#ff7f0e',  # Orange\n",
    "        2: '#2ca02c',  # Green\n",
    "        3: '#d62728',  # Red\n",
    "        4: '#9467bd',  # Purple\n",
    "        5: '#8c564b',  # Brown\n",
    "    }\n",
    "    \n",
    "    # Sample data if too large\n",
    "    if len(cluster_labels) > max_points:\n",
    "        print(f\"Sampling {max_points} points from {len(cluster_labels)} for visualization performance...\")\n",
    "        sample_indices = np.linspace(0, len(cluster_labels)-1, max_points, dtype=int)\n",
    "        cluster_labels_plot = cluster_labels[sample_indices]\n",
    "        cluster_times_plot = cluster_times[sample_indices]\n",
    "    else:\n",
    "        cluster_labels_plot = cluster_labels\n",
    "        cluster_times_plot = cluster_times\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Use scatter plot with step-like appearance instead of many rectangles\n",
    "    for cluster_id in np.unique(cluster_labels_plot):\n",
    "        cluster_mask = cluster_labels_plot == cluster_id\n",
    "        cluster_times_subset = cluster_times_plot[cluster_mask]\n",
    "        cluster_labels_subset = cluster_labels_plot[cluster_mask]\n",
    "        \n",
    "        if len(cluster_times_subset) > 0:\n",
    "            color = cluster_colors.get(cluster_id, '#17becf')\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=cluster_times_subset,\n",
    "                y=cluster_labels_subset,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=8,\n",
    "                    color=color,\n",
    "                    symbol='square',\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f'Cluster {cluster_id}',\n",
    "                text=[f'Time: {t/3600:.2f}h<br>Cluster: {c}' for t, c in zip(cluster_times_subset, cluster_labels_subset)],\n",
    "                hovertemplate='%{text}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    # Add connecting lines for better visualization\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cluster_times_plot,\n",
    "        y=cluster_labels_plot,\n",
    "        mode='lines',\n",
    "        line=dict(width=2, color='rgba(100,100,100,0.3)'),\n",
    "        name='Transitions',\n",
    "        showlegend=False,\n",
    "        hoverinfo='skip'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Interactive Hypnogram - BiLSTM Clustering Results (Optimized)',\n",
    "        xaxis_title='Time (hours)',\n",
    "        yaxis_title='Cluster ID',\n",
    "        height=400,\n",
    "        yaxis=dict(tickmode='linear', tick0=0, dtick=1),\n",
    "        hovermode='closest',\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5)\n",
    "    )\n",
    "    \n",
    "    # Convert x-axis to hours for better readability\n",
    "    fig.update_xaxes(tickformat='.1f')\n",
    "    fig.update_traces(x=cluster_times_plot/3600)  # Convert to hours\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display optimized hypnogram\n",
    "print(\"Creating optimized hypnogram...\")\n",
    "hypnogram_fig = create_hypnogram_optimized(cluster_labels, cluster_times, window_size)\n",
    "hypnogram_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive EEG segment visualization\n",
    "def plot_eeg_segment(start_sec, end_sec, eeg_data, time_vector, cluster_labels, cluster_times, window_size):\n",
    "    \"\"\"Plot a specific segment of EEG data with cluster annotations\"\"\"\n",
    "    \n",
    "    # Extract segment\n",
    "    start_idx = int(start_sec * fs)\n",
    "    end_idx = int(end_sec * fs)\n",
    "    \n",
    "    segment_data = eeg_data[start_idx:end_idx]\n",
    "    segment_time = time_vector[start_idx:end_idx]\n",
    "    \n",
    "    # Find overlapping clusters\n",
    "    cluster_mask = (cluster_times >= start_sec - window_size) & (cluster_times <= end_sec)\n",
    "    relevant_clusters = cluster_labels[cluster_mask]\n",
    "    relevant_times = cluster_times[cluster_mask]\n",
    "    \n",
    "    # Create subplot\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                       shared_xaxes=True,\n",
    "                       subplot_titles=['EEG Signal', 'Cluster Labels'],\n",
    "                       vertical_spacing=0.1,\n",
    "                       row_heights=[0.7, 0.3])\n",
    "    \n",
    "    # Plot EEG signal\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=segment_time,\n",
    "        y=segment_data,\n",
    "        mode='lines',\n",
    "        name='EEG',\n",
    "        line=dict(width=1, color='blue')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Plot cluster annotations\n",
    "    colors_map = {0: 'blue', 1: 'orange', 2: 'green', 3: 'red'}\n",
    "    for i, (time, cluster) in enumerate(zip(relevant_times, relevant_clusters)):\n",
    "        color = colors_map.get(cluster, 'gray')\n",
    "        fig.add_vrect(\n",
    "            x0=time,\n",
    "            x1=time + window_size,\n",
    "            fillcolor=color,\n",
    "            opacity=0.3,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add cluster label bar\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=time,\n",
    "            x1=time + window_size,\n",
    "            y0=cluster - 0.4,\n",
    "            y1=cluster + 0.4,\n",
    "            fillcolor=color,\n",
    "            line=dict(width=1, color=color),\n",
    "            opacity=0.7,\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'EEG Segment Analysis ({start_sec}s - {end_sec}s)',\n",
    "        height=600,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text='Time (seconds)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Amplitude (Î¼V)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Cluster', row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Example segment (first 5 minutes)\n",
    "start_time = 0\n",
    "end_time = 300  # 5 minutes\n",
    "segment_fig = plot_eeg_segment(start_time, end_time, eeg_data, time_vector, \n",
    "                              cluster_labels, cluster_times, window_size)\n",
    "segment_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Distribution Analysis\n",
    "def analyze_cluster_distribution(cluster_labels):\n",
    "    \"\"\"Comprehensive cluster distribution analysis\"\"\"\n",
    "    \n",
    "    # Basic statistics\n",
    "    unique_clusters, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    total_windows = len(cluster_labels)\n",
    "    \n",
    "    print(\"=== Cluster Distribution Analysis ===\")\n",
    "    print(f\"Total number of windows: {total_windows}\")\n",
    "    print(f\"Number of unique clusters: {len(unique_clusters)}\")\n",
    "    print(\"\\nCluster Counts and Proportions:\")\n",
    "    \n",
    "    cluster_stats = []\n",
    "    for cluster, count in zip(unique_clusters, counts):\n",
    "        proportion = count / total_windows * 100\n",
    "        duration_hours = count * window_size / 3600\n",
    "        print(f\"Cluster {cluster}: {count} windows ({proportion:.1f}%) - {duration_hours:.2f} hours\")\n",
    "        cluster_stats.append({\n",
    "            'cluster': cluster,\n",
    "            'count': count,\n",
    "            'proportion': proportion,\n",
    "            'duration_hours': duration_hours\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(cluster_stats)\n",
    "\n",
    "cluster_dist_df = analyze_cluster_distribution(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster distribution visualizations\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                   subplot_titles=['Cluster Counts', 'Cluster Proportions (%)', \n",
    "                                  'Duration (Hours)', 'Cluster Timeline'],\n",
    "                   specs=[[{'type': 'bar'}, {'type': 'pie'}],\n",
    "                         [{'type': 'bar'}, {'type': 'scatter'}]])\n",
    "\n",
    "# Bar plot of counts\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cluster_dist_df['cluster'],\n",
    "    y=cluster_dist_df['count'],\n",
    "    name='Count',\n",
    "    marker_color='lightblue'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Pie chart of proportions\n",
    "fig.add_trace(go.Pie(\n",
    "    labels=[f'Cluster {c}' for c in cluster_dist_df['cluster']],\n",
    "    values=cluster_dist_df['proportion'],\n",
    "    name='Proportion'\n",
    "), row=1, col=2)\n",
    "\n",
    "# Bar plot of duration\n",
    "fig.add_trace(go.Bar(\n",
    "    x=cluster_dist_df['cluster'],\n",
    "    y=cluster_dist_df['duration_hours'],\n",
    "    name='Duration',\n",
    "    marker_color='lightgreen'\n",
    "), row=2, col=1)\n",
    "\n",
    "# Timeline scatter plot\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=cluster_times/3600,  # Convert to hours\n",
    "    y=cluster_labels,\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, opacity=0.6),\n",
    "    name='Timeline'\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Cluster Distribution Analysis\")\n",
    "fig.update_xaxes(title_text='Cluster ID', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Count', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Cluster ID', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Duration (Hours)', row=2, col=1)\n",
    "fig.update_xaxes(title_text='Time (Hours)', row=2, col=2)\n",
    "fig.update_yaxes(title_text='Cluster ID', row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ed571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous Cluster Duration Analysis\n",
    "def analyze_continuous_durations(cluster_labels, window_size):\n",
    "    \"\"\"Analyze continuous durations of each cluster\"\"\"\n",
    "    \n",
    "    continuous_durations = {cluster: [] for cluster in np.unique(cluster_labels)}\n",
    "    \n",
    "    current_cluster = cluster_labels[0]\n",
    "    current_duration = 1\n",
    "    \n",
    "    for i in range(1, len(cluster_labels)):\n",
    "        if cluster_labels[i] == current_cluster:\n",
    "            current_duration += 1\n",
    "        else:\n",
    "            # End of continuous segment\n",
    "            duration_seconds = current_duration * window_size\n",
    "            continuous_durations[current_cluster].append(duration_seconds)\n",
    "            current_cluster = cluster_labels[i]\n",
    "            current_duration = 1\n",
    "    \n",
    "    # Add the last segment\n",
    "    duration_seconds = current_duration * window_size\n",
    "    continuous_durations[current_cluster].append(duration_seconds)\n",
    "    \n",
    "    return continuous_durations\n",
    "\n",
    "continuous_durations = analyze_continuous_durations(cluster_labels, window_size)\n",
    "\n",
    "# Calculate statistics for continuous durations\n",
    "print(\"=== Continuous Duration Analysis ===\")\n",
    "duration_stats = []\n",
    "\n",
    "for cluster in sorted(continuous_durations.keys()):\n",
    "    durations = continuous_durations[cluster]\n",
    "    if durations:\n",
    "        mean_dur = np.mean(durations)\n",
    "        median_dur = np.median(durations)\n",
    "        max_dur = np.max(durations)\n",
    "        min_dur = np.min(durations)\n",
    "        count = len(durations)\n",
    "        \n",
    "        print(f\"\\nCluster {cluster}:\")\n",
    "        print(f\"  Number of continuous segments: {count}\")\n",
    "        print(f\"  Mean duration: {mean_dur:.1f}s ({mean_dur/60:.1f}min)\")\n",
    "        print(f\"  Median duration: {median_dur:.1f}s ({median_dur/60:.1f}min)\")\n",
    "        print(f\"  Max duration: {max_dur:.1f}s ({max_dur/60:.1f}min)\")\n",
    "        print(f\"  Min duration: {min_dur:.1f}s ({min_dur/60:.1f}min)\")\n",
    "        \n",
    "        duration_stats.append({\n",
    "            'cluster': cluster,\n",
    "            'segment_count': count,\n",
    "            'mean_duration': mean_dur,\n",
    "            'median_duration': median_dur,\n",
    "            'max_duration': max_dur,\n",
    "            'min_duration': min_dur\n",
    "        })\n",
    "\n",
    "duration_stats_df = pd.DataFrame(duration_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c63684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize continuous duration distributions\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                   subplot_titles=['Duration Statistics', 'Duration Distributions',\n",
    "                                  'Segment Counts', 'Duration Boxplots'])\n",
    "\n",
    "# Statistics bar plot\n",
    "fig.add_trace(go.Bar(\n",
    "    x=duration_stats_df['cluster'],\n",
    "    y=duration_stats_df['mean_duration']/60,  # Convert to minutes\n",
    "    name='Mean Duration (min)',\n",
    "    marker_color='lightcoral'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Histogram of all durations\n",
    "all_durations = []\n",
    "cluster_labels_for_hist = []\n",
    "for cluster, durations in continuous_durations.items():\n",
    "    all_durations.extend(durations)\n",
    "    cluster_labels_for_hist.extend([f'Cluster {cluster}'] * len(durations))\n",
    "\n",
    "# Create histogram using plotly express approach\n",
    "duration_df = pd.DataFrame({\n",
    "    'duration_min': np.array(all_durations) / 60,\n",
    "    'cluster': cluster_labels_for_hist\n",
    "})\n",
    "\n",
    "# Add histograms for each cluster\n",
    "colors_hist = ['blue', 'orange', 'green', 'red', 'purple', 'brown']\n",
    "for i, cluster in enumerate(sorted(continuous_durations.keys())):\n",
    "    cluster_durations = np.array(continuous_durations[cluster]) / 60\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=cluster_durations,\n",
    "        name=f'Cluster {cluster}',\n",
    "        opacity=0.6,\n",
    "        marker_color=colors_hist[i % len(colors_hist)],\n",
    "        bingroup=1\n",
    "    ), row=1, col=2)\n",
    "\n",
    "# Segment counts\n",
    "fig.add_trace(go.Bar(\n",
    "    x=duration_stats_df['cluster'],\n",
    "    y=duration_stats_df['segment_count'],\n",
    "    name='Segment Count',\n",
    "    marker_color='lightgreen'\n",
    "), row=2, col=1)\n",
    "\n",
    "# Boxplots for duration distribution\n",
    "for i, cluster in enumerate(sorted(continuous_durations.keys())):\n",
    "    cluster_durations = np.array(continuous_durations[cluster]) / 60\n",
    "    fig.add_trace(go.Box(\n",
    "        y=cluster_durations,\n",
    "        name=f'Cluster {cluster}',\n",
    "        marker_color=colors_hist[i % len(colors_hist)]\n",
    "    ), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Continuous Duration Analysis\")\n",
    "fig.update_xaxes(title_text='Cluster ID', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Mean Duration (min)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Duration (min)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Frequency', row=1, col=2)\n",
    "fig.update_xaxes(title_text='Cluster ID', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Segment Count', row=2, col=1)\n",
    "fig.update_xaxes(title_text='Cluster', row=2, col=2)\n",
    "fig.update_yaxes(title_text='Duration (min)', row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multitaper Spectrogram Analysis\n",
    "def compute_multitaper_spectrogram(data, fs, window_length=30, overlap=0.5, bandwidth=4):\n",
    "    \"\"\"Compute multitaper spectrogram\"\"\"\n",
    "    \n",
    "    from scipy.signal import spectrogram\n",
    "    from scipy.signal.windows import dpss\n",
    "    \n",
    "    # Parameters\n",
    "    nperseg = int(window_length * fs)\n",
    "    noverlap = int(nperseg * overlap)\n",
    "    \n",
    "    # Compute spectrogram using multitaper method\n",
    "    f, t, Sxx = spectrogram(data, fs, nperseg=nperseg, noverlap=noverlap)\n",
    "    \n",
    "    return f, t, Sxx\n",
    "\n",
    "# Compute spectrogram for a segment of data\n",
    "segment_duration = min(3600, len(eeg_data)/fs)  # 1 hour or full data if shorter\n",
    "segment_samples = int(segment_duration * fs)\n",
    "data_segment = eeg_data[:segment_samples]\n",
    "\n",
    "print(f\"Computing spectrogram for {segment_duration/60:.1f} minutes of data...\")\n",
    "f, t_spec, Sxx = compute_multitaper_spectrogram(data_segment, fs)\n",
    "\n",
    "# Convert to dB\n",
    "Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "\n",
    "print(f\"Spectrogram shape: {Sxx_db.shape}\")\n",
    "print(f\"Frequency range: {f[0]:.1f} - {f[-1]:.1f} Hz\")\n",
    "print(f\"Time range: {t_spec[0]:.1f} - {t_spec[-1]:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Hypnogram and Spectrogram Visualization\n",
    "def create_combined_visualization(cluster_labels, cluster_times, window_size, \n",
    "                                f, t_spec, Sxx_db, max_time=3600):\n",
    "    \"\"\"Create combined hypnogram and spectrogram plot\"\"\"\n",
    "    \n",
    "    # Limit to specified time range\n",
    "    time_mask = t_spec <= max_time\n",
    "    t_plot = t_spec[time_mask]\n",
    "    Sxx_plot = Sxx_db[:, time_mask]\n",
    "    \n",
    "    cluster_mask = cluster_times <= max_time\n",
    "    cluster_times_plot = cluster_times[cluster_mask]\n",
    "    cluster_labels_plot = cluster_labels[cluster_mask]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                       shared_xaxes=True,\n",
    "                       subplot_titles=['Hypnogram', 'Multitaper Spectrogram'],\n",
    "                       vertical_spacing=0.1,\n",
    "                       row_heights=[0.3, 0.7])\n",
    "    \n",
    "    # Add hypnogram\n",
    "    cluster_colors = {0: 'blue', 1: 'orange', 2: 'green', 3: 'red'}\n",
    "    for time, cluster in zip(cluster_times_plot, cluster_labels_plot):\n",
    "        color = cluster_colors.get(cluster, 'gray')\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=time,\n",
    "            x1=time + window_size,\n",
    "            y0=cluster - 0.4,\n",
    "            y1=cluster + 0.4,\n",
    "            fillcolor=color,\n",
    "            line=dict(width=1, color=color),\n",
    "            opacity=0.7,\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Add spectrogram\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=t_plot,\n",
    "        y=f,\n",
    "        z=Sxx_plot,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Power (dB)', x=1.02),\n",
    "        name='Spectrogram'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Combined Hypnogram and Multitaper Spectrogram',\n",
    "        height=700,\n",
    "        xaxis2_title='Time (seconds)',\n",
    "        yaxis1_title='Cluster ID',\n",
    "        yaxis2_title='Frequency (Hz)'\n",
    "    )\n",
    "    \n",
    "    # Set frequency range for better visualization\n",
    "    fig.update_yaxes(range=[0, 50], row=2, col=1)  # Focus on 0-50 Hz\n",
    "    fig.update_yaxes(tickmode='linear', tick0=0, dtick=1, row=1, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display combined visualization\n",
    "combined_fig = create_combined_visualization(cluster_labels, cluster_times, window_size,\n",
    "                                           f, t_spec, Sxx_db, max_time=1800)  # 30 minutes\n",
    "combined_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Band Analysis - OPTIMIZED VERSION\n",
    "def analyze_frequency_bands_optimized(f, t_spec, Sxx, cluster_labels, cluster_times, window_size, max_time_samples=1000):\n",
    "    \"\"\"Analyze frequency band dominance for each cluster - optimized for speed\"\"\"\n",
    "    \n",
    "    # Limit analysis to reduce computation time\n",
    "    if len(t_spec) > max_time_samples:\n",
    "        print(f\"Limiting analysis to first {max_time_samples} time samples for performance...\")\n",
    "        t_spec = t_spec[:max_time_samples]\n",
    "        Sxx = Sxx[:, :max_time_samples]\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'Delta (0.5-4 Hz)': (0.5, 4),\n",
    "        'Theta (4-8 Hz)': (4, 8),\n",
    "        'Alpha (8-13 Hz)': (8, 13),\n",
    "        'Beta (13-30 Hz)': (13, 30),\n",
    "        'Gamma (30-50 Hz)': (30, 50)\n",
    "    }\n",
    "    \n",
    "    # Pre-compute frequency masks for efficiency\n",
    "    freq_masks = {}\n",
    "    for band_name, (low_freq, high_freq) in bands.items():\n",
    "        freq_masks[band_name] = (f >= low_freq) & (f <= high_freq)\n",
    "    \n",
    "    # Vectorized band power calculation\n",
    "    band_powers = {}\n",
    "    for band_name, freq_mask in freq_masks.items():\n",
    "        # Calculate mean power across frequency bins for each time point\n",
    "        band_powers[band_name] = np.mean(Sxx[freq_mask, :], axis=0)\n",
    "    \n",
    "    # Simplified cluster alignment - use closest time points\n",
    "    cluster_band_analysis = {cluster: {band: [] for band in bands.keys()} \n",
    "                           for cluster in np.unique(cluster_labels)}\n",
    "    \n",
    "    # Sample every N-th cluster for faster processing\n",
    "    sample_rate = max(1, len(cluster_labels) // 100)  # Sample up to 100 points\n",
    "    sampled_indices = range(0, len(cluster_labels), sample_rate)\n",
    "    \n",
    "    for idx in sampled_indices:\n",
    "        cluster_time = cluster_times[idx]\n",
    "        cluster_label = cluster_labels[idx]\n",
    "        \n",
    "        # Find closest time point in spectrogram\n",
    "        time_idx = np.argmin(np.abs(t_spec - cluster_time))\n",
    "        \n",
    "        if time_idx < len(t_spec):\n",
    "            for band_name in bands.keys():\n",
    "                band_power = band_powers[band_name][time_idx]\n",
    "                cluster_band_analysis[cluster_label][band_name].append(band_power)\n",
    "    \n",
    "    # Calculate statistics for each cluster-band combination\n",
    "    band_stats = []\n",
    "    for cluster in sorted(cluster_band_analysis.keys()):\n",
    "        for band_name in bands.keys():\n",
    "            powers = cluster_band_analysis[cluster][band_name]\n",
    "            if powers:\n",
    "                mean_power = np.mean(powers)\n",
    "                std_power = np.std(powers)\n",
    "                band_stats.append({\n",
    "                    'cluster': cluster,\n",
    "                    'band': band_name,\n",
    "                    'mean_power': mean_power,\n",
    "                    'std_power': std_power,\n",
    "                    'log_power': np.log10(mean_power + 1e-12)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(band_stats), band_powers, list(t_spec)\n",
    "\n",
    "print(\"Analyzing frequency bands (optimized version)...\")\n",
    "band_stats_df, band_powers, spec_time_points = analyze_frequency_bands_optimized(\n",
    "    f, t_spec, Sxx, cluster_labels, cluster_times, window_size)\n",
    "\n",
    "print(\"\\nBand Analysis Results:\")\n",
    "print(band_stats_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Frequency Band Analysis\n",
    "def create_band_analysis_plots(band_stats_df):\n",
    "    \"\"\"Create comprehensive frequency band analysis plots\"\"\"\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    pivot_mean = band_stats_df.pivot(index='cluster', columns='band', values='mean_power')\n",
    "    pivot_log = band_stats_df.pivot(index='cluster', columns='band', values='log_power')\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=2, cols=2,\n",
    "                       subplot_titles=['Mean Band Power by Cluster', 'Log Band Power Heatmap',\n",
    "                                      'Normalized Band Power', 'Band Power Ratios'],\n",
    "                       specs=[[{'type': 'bar'}, {'type': 'heatmap'}],\n",
    "                             [{'type': 'bar'}, {'type': 'bar'}]])\n",
    "    \n",
    "    # 1. Bar plot of mean band powers\n",
    "    colors_bar = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "    for i, cluster in enumerate(sorted(band_stats_df['cluster'].unique())):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=cluster_data['band'],\n",
    "            y=cluster_data['mean_power'],\n",
    "            name=f'Cluster {cluster}',\n",
    "            marker_color=colors_bar[i % len(colors_bar)],\n",
    "            opacity=0.7\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # 2. Heatmap of log power\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=pivot_log.columns,\n",
    "        y=pivot_log.index,\n",
    "        z=pivot_log.values,\n",
    "        colorscale='Viridis',\n",
    "        name='Log Power',\n",
    "        colorbar=dict(title='Log Power', x=0.48, y=0.8, len=0.4)\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Normalized band power (relative to total power)\n",
    "    normalized_data = []\n",
    "    for cluster in sorted(band_stats_df['cluster'].unique()):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        total_power = cluster_data['mean_power'].sum()\n",
    "        normalized_powers = cluster_data['mean_power'] / total_power * 100\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=cluster_data['band'],\n",
    "            y=normalized_powers,\n",
    "            name=f'Cluster {cluster} (Norm)',\n",
    "            marker_color=colors_bar[cluster % len(colors_bar)],\n",
    "            opacity=0.7,\n",
    "            showlegend=False\n",
    "        ), row=2, col=1)\n",
    "    \n",
    "    # 4. Specific band ratios (Delta/Alpha, Theta/Beta)\n",
    "    ratios_data = []\n",
    "    for cluster in sorted(band_stats_df['cluster'].unique()):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        \n",
    "        # Get powers for specific bands\n",
    "        powers_dict = dict(zip(cluster_data['band'], cluster_data['mean_power']))\n",
    "        \n",
    "        if 'Delta (0.5-4 Hz)' in powers_dict and 'Alpha (8-13 Hz)' in powers_dict:\n",
    "            delta_alpha_ratio = powers_dict['Delta (0.5-4 Hz)'] / powers_dict['Alpha (8-13 Hz)']\n",
    "        else:\n",
    "            delta_alpha_ratio = 0\n",
    "            \n",
    "        if 'Theta (4-8 Hz)' in powers_dict and 'Beta (13-30 Hz)' in powers_dict:\n",
    "            theta_beta_ratio = powers_dict['Theta (4-8 Hz)'] / powers_dict['Beta (13-30 Hz)']\n",
    "        else:\n",
    "            theta_beta_ratio = 0\n",
    "            \n",
    "        ratios_data.append({\n",
    "            'cluster': cluster,\n",
    "            'Delta/Alpha': delta_alpha_ratio,\n",
    "            'Theta/Beta': theta_beta_ratio\n",
    "        })\n",
    "    \n",
    "    ratios_df = pd.DataFrame(ratios_data)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=ratios_df['cluster'],\n",
    "        y=ratios_df['Delta/Alpha'],\n",
    "        name='Delta/Alpha',\n",
    "        marker_color='lightcoral'\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=ratios_df['cluster'],\n",
    "        y=ratios_df['Theta/Beta'],\n",
    "        name='Theta/Beta',\n",
    "        marker_color='lightblue'\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        title_text='Frequency Band Analysis by Cluster',\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text='Frequency Band', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Mean Power', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Frequency Band', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Cluster', row=1, col=2)\n",
    "    fig.update_xaxes(title_text='Frequency Band', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Normalized Power (%)', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Cluster', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Ratio', row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display band analysis plots\n",
    "band_analysis_fig = create_band_analysis_plots(band_stats_df)\n",
    "band_analysis_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9266a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics and Conclusions\n",
    "print(\"=== COMPREHENSIVE ANALYSIS SUMMARY ===\")\n",
    "print(\"\\n1. CLUSTER DISTRIBUTION:\")\n",
    "print(cluster_dist_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n2. CONTINUOUS DURATION STATISTICS:\")\n",
    "print(duration_stats_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n3. FREQUENCY BAND DOMINANCE:\")\n",
    "# Find dominant frequency band for each cluster\n",
    "for cluster in sorted(band_stats_df['cluster'].unique()):\n",
    "    cluster_bands = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "    dominant_band = cluster_bands.loc[cluster_bands['mean_power'].idxmax(), 'band']\n",
    "    max_power = cluster_bands['mean_power'].max()\n",
    "    print(f\"Cluster {cluster}: Dominant band = {dominant_band} (Power: {max_power:.2e})\")\n",
    "\n",
    "print(\"\\n4. KEY FINDINGS:\")\n",
    "print(f\"- Total recording duration: {len(eeg_data)/fs/3600:.2f} hours\")\n",
    "print(f\"- Number of cluster transitions: {np.sum(np.diff(cluster_labels) != 0)}\")\n",
    "print(f\"- Most frequent cluster: {cluster_dist_df.loc[cluster_dist_df['count'].idxmax(), 'cluster']}\")\n",
    "print(f\"- Longest continuous segment: {duration_stats_df['max_duration'].max()/60:.1f} minutes\")\n",
    "print(f\"- Average segment duration: {np.mean([np.mean(durations) for durations in continuous_durations.values()])/60:.1f} minutes\")\n",
    "\n",
    "# Cluster stability analysis\n",
    "transitions = np.diff(cluster_labels)\n",
    "stability = 1 - (np.sum(transitions != 0) / len(transitions))\n",
    "print(f\"- Cluster stability (1-transition_rate): {stability:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24401a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Analysis Function\n",
    "def interactive_segment_analysis(start_sec, end_sec, plot_spectrogram=True):\n",
    "    \"\"\"Interactive function to analyze any time segment\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== SEGMENT ANALYSIS ({start_sec}s - {end_sec}s) ===\")\n",
    "    \n",
    "    # Find clusters in this segment\n",
    "    segment_mask = (cluster_times >= start_sec) & (cluster_times <= end_sec)\n",
    "    segment_clusters = cluster_labels[segment_mask]\n",
    "    segment_times = cluster_times[segment_mask]\n",
    "    \n",
    "    if len(segment_clusters) > 0:\n",
    "        unique, counts = np.unique(segment_clusters, return_counts=True)\n",
    "        print(f\"Clusters present: {dict(zip(unique, counts))}\")\n",
    "        print(f\"Dominant cluster: {unique[np.argmax(counts)]}\")\n",
    "        print(f\"Number of transitions: {np.sum(np.diff(segment_clusters) != 0)}\")\n",
    "    else:\n",
    "        print(\"No cluster data available for this segment\")\n",
    "    \n",
    "    # Plot EEG segment\n",
    "    fig = plot_eeg_segment(start_sec, end_sec, eeg_data, time_vector,\n",
    "                          cluster_labels, cluster_times, window_size)\n",
    "    fig.show()\n",
    "    \n",
    "    # Optional spectrogram for the segment\n",
    "    if plot_spectrogram and end_sec - start_sec <= 600:  # Only for segments <= 10 minutes\n",
    "        start_idx = int(start_sec * fs)\n",
    "        end_idx = int(end_sec * fs)\n",
    "        segment_data = eeg_data[start_idx:end_idx]\n",
    "        \n",
    "        if len(segment_data) > fs * 10:  # At least 10 seconds of data\n",
    "            f_seg, t_seg, Sxx_seg = compute_multitaper_spectrogram(segment_data, fs, window_length=5)\n",
    "            Sxx_seg_db = 10 * np.log10(Sxx_seg + 1e-12)\n",
    "            \n",
    "            fig_spec = go.Figure()\n",
    "            fig_spec.add_trace(go.Heatmap(\n",
    "                x=t_seg + start_sec,\n",
    "                y=f_seg,\n",
    "                z=Sxx_seg_db,\n",
    "                colorscale='Viridis',\n",
    "                colorbar=dict(title='Power (dB)')\n",
    "            ))\n",
    "            \n",
    "            fig_spec.update_layout(\n",
    "                title=f'Spectrogram for Segment ({start_sec}s - {end_sec}s)',\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Frequency (Hz)',\n",
    "                height=400\n",
    "            )\n",
    "            fig_spec.update_yaxes(range=[0, 50])\n",
    "            fig_spec.show()\n",
    "\n",
    "print(\"\\n=== INTERACTIVE ANALYSIS FUNCTION READY ===\")\n",
    "print(\"Use: interactive_segment_analysis(start_sec, end_sec, plot_spectrogram=True)\")\n",
    "print(\"Example: interactive_segment_analysis(600, 900)  # Analyze 10-15 minute segment\")\n",
    "\n",
    "print(\"\\n=== FINAL RECOMMENDATIONS ===\")\n",
    "print(\"1. Cluster Interpretation:\")\n",
    "print(\"   - Examine frequency band dominance to interpret sleep stages\")\n",
    "print(\"   - Delta dominance typically indicates deep sleep\")\n",
    "print(\"   - Alpha/Beta dominance may indicate wake or REM states\")\n",
    "print(\"\\n2. Further Analysis:\")\n",
    "print(\"   - Investigate cluster transitions patterns\")\n",
    "print(\"   - Analyze circadian rhythm effects\")\n",
    "print(\"   - Compare with manual sleep staging if available\")\n",
    "print(\"\\n3. Model Validation:\")\n",
    "print(\"   - Check cluster consistency across different nights\")\n",
    "print(\"   - Validate against physiological sleep patterns\")\n",
    "print(\"   - Consider individual differences in sleep architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d650494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Transition Matrix Analysis\n",
    "def analyze_cluster_transitions(cluster_labels):\n",
    "    \"\"\"Analyze transitions between clusters\"\"\"\n",
    "    \n",
    "    unique_clusters = sorted(np.unique(cluster_labels))\n",
    "    n_clusters = len(unique_clusters)\n",
    "    \n",
    "    # Create transition matrix\n",
    "    transition_matrix = np.zeros((n_clusters, n_clusters))\n",
    "    \n",
    "    for i in range(len(cluster_labels) - 1):\n",
    "        from_cluster = cluster_labels[i]\n",
    "        to_cluster = cluster_labels[i + 1]\n",
    "        transition_matrix[from_cluster, to_cluster] += 1\n",
    "    \n",
    "    # Normalize to get probabilities\n",
    "    transition_probs = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "    transition_probs = np.nan_to_num(transition_probs)  # Handle division by zero\n",
    "    \n",
    "    return transition_matrix, transition_probs, unique_clusters\n",
    "\n",
    "# Calculate transition matrices\n",
    "trans_matrix, trans_probs, clusters = analyze_cluster_transitions(cluster_labels)\n",
    "\n",
    "print(\"=== CLUSTER TRANSITION ANALYSIS ===\")\n",
    "print(f\"\\nTransition Matrix (Raw Counts):\")\n",
    "trans_df = pd.DataFrame(trans_matrix, index=[f'From {c}' for c in clusters], \n",
    "                       columns=[f'To {c}' for c in clusters])\n",
    "print(trans_df)\n",
    "\n",
    "print(f\"\\nTransition Probabilities:\")\n",
    "trans_prob_df = pd.DataFrame(trans_probs, index=[f'From {c}' for c in clusters], \n",
    "                            columns=[f'To {c}' for c in clusters])\n",
    "print(trans_prob_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc44ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Transition Matrix\n",
    "fig = make_subplots(rows=1, cols=2,\n",
    "                   subplot_titles=['Transition Counts', 'Transition Probabilities'],\n",
    "                   specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}]])\n",
    "\n",
    "# Raw transition counts\n",
    "fig.add_trace(go.Heatmap(\n",
    "    x=[f'To {c}' for c in clusters],\n",
    "    y=[f'From {c}' for c in clusters],\n",
    "    z=trans_matrix,\n",
    "    colorscale='Blues',\n",
    "    text=trans_matrix.astype(int),\n",
    "    texttemplate='%{text}',\n",
    "    textfont={'size': 12},\n",
    "    colorbar=dict(title='Count', x=0.46)\n",
    "), row=1, col=1)\n",
    "\n",
    "# Transition probabilities\n",
    "fig.add_trace(go.Heatmap(\n",
    "    x=[f'To {c}' for c in clusters],\n",
    "    y=[f'From {c}' for c in clusters],\n",
    "    z=trans_probs,\n",
    "    colorscale='Reds',\n",
    "    text=np.round(trans_probs, 2),\n",
    "    texttemplate='%{text}',\n",
    "    textfont={'size': 12},\n",
    "    colorbar=dict(title='Probability', x=1.02)\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cluster Transition Analysis',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate transition statistics\n",
    "print(\"\\n=== TRANSITION STATISTICS ===\")\n",
    "total_transitions = np.sum(trans_matrix)\n",
    "self_transitions = np.sum(np.diag(trans_matrix))\n",
    "stability_ratio = self_transitions / total_transitions\n",
    "\n",
    "print(f\"Total transitions: {int(total_transitions)}\")\n",
    "print(f\"Self-transitions (no change): {int(self_transitions)}\")\n",
    "print(f\"Stability ratio: {stability_ratio:.3f}\")\n",
    "\n",
    "# Most common transitions\n",
    "print(\"\\nMost common transitions:\")\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(len(clusters)):\n",
    "        if trans_matrix[i, j] > 0:\n",
    "            print(f\"  {clusters[i]} -> {clusters[j]}: {int(trans_matrix[i, j])} times ({trans_probs[i, j]:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
