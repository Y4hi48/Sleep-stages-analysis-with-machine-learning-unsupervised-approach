{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa8e633",
   "metadata": {},
   "source": [
    "# BiLSTM Sleep Stage Clustering - Results Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of BiLSTM-based sleep stage clustering results from the research project \"Sleep Stages Analysis with Machine Learning - Unsupervised Approach\" conducted at Institut de Neurosciences des Syst√®mes (INS).\n",
    "\n",
    "## Analysis Components:\n",
    "- **Data Loading & Validation**: Load model results and EEG signals with robust error handling\n",
    "- **Interactive Hypnogram Visualization**: Time-series visualization of detected sleep clusters\n",
    "- **Cluster Distribution Analysis**: Statistical analysis of sleep stage frequency and duration\n",
    "- **Frequency Band Analysis**: Spectral power analysis across traditional EEG frequency bands\n",
    "- **Transition Pattern Analysis**: Markov-like analysis of sleep stage transitions\n",
    "- **Micro-arousal Detection**: Identification of brief arousal events\n",
    "\n",
    "## Data Sources:\n",
    "- **Model Results**: `bilstm_30s_4clusters.pkl` - Pre-trained BiLSTM clustering results\n",
    "- **Metadata**: `bilstm_30s_4clusters_metadata.json` - Model configuration and parameters  \n",
    "- **EEG Data**: `EEG_0_per_hour_2024-03-20 17_12_18.edf` - Continuous EEG recordings\n",
    "\n",
    "## Research Context:\n",
    "This analysis supports the unsupervised machine learning approach for automated sleep stage classification, contributing to precision medicine applications in neurology and sleep disorders research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LIBRARY IMPORTS AND CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Core scientific computing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# EEG signal processing\n",
    "import mne\n",
    "\n",
    "# Interactive visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as colors\n",
    "\n",
    "# Signal processing and statistical analysis\n",
    "from scipy import signal\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress routine warnings for cleaner output\n",
    "\n",
    "# Set plotting parameters for consistent visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "px.defaults.template = 'plotly_white'\n",
    "\n",
    "print(\"‚úì All required libraries imported successfully\")\n",
    "print(\"‚úì Visualization settings configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DATA LOADING: MODEL RESULTS AND METADATA\n",
    "# ==============================================================================\n",
    "\n",
    "# Load model metadata containing training parameters and configuration\n",
    "try:\n",
    "    with open('results/bilstm_30s_4clusters_metadata.json', 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(\"üìä Model Metadata Loaded:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"{key:20}: {value}\")\n",
    "    \n",
    "    # Extract key parameters for later use\n",
    "    window_size = metadata.get('window_size_seconds', 30)  # Default 30s windows\n",
    "    overlap = metadata.get('overlap', 0.5)  # Default 50% overlap\n",
    "    \n",
    "    print(f\"\\n‚úì Key parameters extracted:\")\n",
    "    print(f\"  Window size: {window_size}s\")\n",
    "    print(f\"  Overlap: {overlap*100}%\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Metadata file not found. Using default parameters.\")\n",
    "    metadata = {'window_size_seconds': 30, 'overlap': 0.5}\n",
    "    window_size, overlap = 30, 0.5\n",
    "except json.JSONDecodeError:\n",
    "    print(\"‚ùå Error parsing metadata JSON. Using default parameters.\")\n",
    "    metadata = {'window_size_seconds': 30, 'overlap': 0.5}\n",
    "    window_size, overlap = 30, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f51831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BiLSTM clustering results with robust error handling\n",
    "try:\n",
    "    with open('results/bilstm_30s_4clusters.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    print(\"\\nüì¶ BiLSTM Results Loaded Successfully:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key:20}: {type(value).__name__}\")\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"{'':<20}  Shape: {value.shape}\")\n",
    "        elif hasattr(value, '__len__') and not isinstance(value, str):\n",
    "            print(f\"{'':<20}  Length: {len(value)}\")\n",
    "    \n",
    "    print(\"‚úì Results data structure validated\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Results file not found. Please ensure 'results/bilstm_30s_4clusters.pkl' exists.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading results: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf97a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EEG DATA LOADING WITH FALLBACK MECHANISMS\n",
    "# ==============================================================================\n",
    "\n",
    "def load_eeg_data():\n",
    "    \"\"\"\n",
    "    Load EEG data with multiple fallback mechanisms for robust data handling.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (raw_data, eeg_signal, sampling_frequency, time_vector)\n",
    "    \"\"\"\n",
    "    # Priority order for EEG file locations\n",
    "    eeg_paths = [\n",
    "        'by captain borat/raw/EEG_0_per_hour_2024-03-20 17_12_18.edf',\n",
    "        'raw data/EEG_0_per_hour_2024-03-20 17_12_18.edf',\n",
    "        'EEG_0_per_hour_2024-03-20 17_12_18.edf'\n",
    "    ]\n",
    "    \n",
    "    # Attempt to load actual EEG data\n",
    "    for eeg_file in eeg_paths:\n",
    "        try:\n",
    "            print(f\"üìÇ Attempting to load: {eeg_file}\")\n",
    "            raw = mne.io.read_raw_edf(eeg_file, preload=True, verbose=False)\n",
    "            print(f\"‚úì Successfully loaded EEG data from: {eeg_file}\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    else:\n",
    "        # Create simulated EEG data if no file is found\n",
    "        print(\"‚ö†Ô∏è  No EEG file found. Generating simulated EEG data for demonstration...\")\n",
    "        raw = create_simulated_eeg_data()\n",
    "        print(\"‚úì Simulated EEG data created\")\n",
    "    \n",
    "    # Extract signal properties\n",
    "    fs = raw.info['sfreq']\n",
    "    eeg_data = raw.get_data()[0]  # First channel\n",
    "    time_vector = np.arange(len(eeg_data)) / fs\n",
    "    \n",
    "    # Display data characteristics\n",
    "    print(f\"\\nüìä EEG Data Characteristics:\")\n",
    "    print(f\"  Sampling frequency: {fs} Hz\")\n",
    "    print(f\"  Channels: {len(raw.ch_names)} ({', '.join(raw.ch_names)})\")\n",
    "    print(f\"  Duration: {time_vector[-1]:.1f}s ({time_vector[-1]/3600:.2f}h)\")\n",
    "    print(f\"  Data points: {len(eeg_data):,}\")\n",
    "    print(f\"  Amplitude range: [{eeg_data.min():.1f}, {eeg_data.max():.1f}] ¬µV\")\n",
    "    \n",
    "    return raw, eeg_data, fs, time_vector\n",
    "\n",
    "def create_simulated_eeg_data():\n",
    "    \"\"\"Create realistic simulated EEG data for demonstration purposes.\"\"\"\n",
    "    # Simulate 24-hour recording\n",
    "    duration = 86400  # seconds\n",
    "    fs = 512  # Hz (from metadata)\n",
    "    n_samples = int(duration * fs)\n",
    "    time_vector = np.arange(n_samples) / fs\n",
    "    \n",
    "    # Generate multi-component EEG-like signal\n",
    "    np.random.seed(42)  # Reproducible simulation\n",
    "    \n",
    "    # Base noise\n",
    "    eeg_signal = np.random.randn(n_samples) * 10\n",
    "    \n",
    "    # Add physiologically relevant frequency components\n",
    "    frequency_components = {\n",
    "        'delta': (0.5, 2.0, 80),    # Deep sleep dominant\n",
    "        'theta': (4.0, 8.0, 40),    # Light sleep, REM\n",
    "        'alpha': (8.0, 13.0, 30),   # Relaxed wakefulness\n",
    "        'beta': (13.0, 30.0, 20),   # Active wakefulness\n",
    "    }\n",
    "    \n",
    "    for band, (f_low, f_high, amplitude) in frequency_components.items():\n",
    "        freq = np.random.uniform(f_low, f_high)\n",
    "        eeg_signal += amplitude * np.sin(2 * np.pi * freq * time_vector)\n",
    "    \n",
    "    # Add sleep-wake cycle modulation (circadian rhythm simulation)\n",
    "    circadian_modulation = np.sin(2 * np.pi * time_vector / 86400) * 20\n",
    "    eeg_signal += circadian_modulation\n",
    "    \n",
    "    # Create MNE Raw object\n",
    "    info = mne.create_info(['EEG'], sfreq=fs, ch_types=['eeg'])\n",
    "    raw = mne.io.RawArray(eeg_signal.reshape(1, -1), info)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "# Load EEG data using the robust loading function\n",
    "raw, eeg_data, fs, time_vector = load_eeg_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CLUSTER LABELS EXTRACTION AND VALIDATION\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_cluster_labels(results, verbose=True):\n",
    "    \"\"\"\n",
    "    Intelligently extract cluster labels from results with comprehensive search.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Loaded results dictionary\n",
    "        verbose (bool): Print detailed search information\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Extracted cluster labels\n",
    "    \"\"\"\n",
    "    cluster_labels = None\n",
    "    \n",
    "    # Define potential keys where cluster labels might be stored\n",
    "    potential_keys = [\n",
    "        'cluster_labels', 'labels', 'predictions', 'y_pred', \n",
    "        'clusters', 'clustering_labels', 'cluster_assignments'\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"üîç Searching for cluster labels...\")\n",
    "    \n",
    "    # Search in main results dictionary\n",
    "    for key in potential_keys:\n",
    "        if key in results and results[key] is not None:\n",
    "            cluster_labels = results[key]\n",
    "            if verbose:\n",
    "                print(f\"‚úì Found cluster labels in: '{key}'\")\n",
    "            break\n",
    "    \n",
    "    # Search in nested 'results' dictionary if not found\n",
    "    if cluster_labels is None and 'results' in results:\n",
    "        nested = results['results']\n",
    "        for key in potential_keys:\n",
    "            if key in nested and nested[key] is not None:\n",
    "                cluster_labels = nested[key]\n",
    "                if verbose:\n",
    "                    print(f\"‚úì Found cluster labels in: 'results.{key}'\")\n",
    "                break\n",
    "    \n",
    "    # Fallback: find first suitable array-like object\n",
    "    if cluster_labels is None:\n",
    "        if verbose:\n",
    "            print(\"‚ö†Ô∏è  Cluster labels not found in expected locations. Available keys:\")\n",
    "            for key, value in results.items():\n",
    "                print(f\"  {key:20}: {type(value).__name__}\")\n",
    "                if hasattr(value, 'shape'):\n",
    "                    print(f\"{'':<20}    Shape: {value.shape}\")\n",
    "        \n",
    "        # Try to use first 1D array as cluster labels\n",
    "        for key, value in results.items():\n",
    "            if hasattr(value, 'shape') and len(value.shape) == 1 and len(value) > 100:\n",
    "                cluster_labels = value\n",
    "                if verbose:\n",
    "                    print(f\"‚úì Using '{key}' as cluster labels (first suitable 1D array)\")\n",
    "                break\n",
    "    \n",
    "    if cluster_labels is None:\n",
    "        raise ValueError(\"‚ùå Could not locate cluster labels in results. Please verify data structure.\")\n",
    "    \n",
    "    return np.array(cluster_labels)\n",
    "\n",
    "def validate_cluster_labels(cluster_labels, verbose=True):\n",
    "    \"\"\"Validate and analyze cluster label properties.\"\"\"\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    label_counts = np.bincount(cluster_labels.astype(int))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nüìä Cluster Labels Validation:\")\n",
    "        print(f\"  Total windows: {len(cluster_labels):,}\")\n",
    "        print(f\"  Unique clusters: {len(unique_labels)} {list(unique_labels)}\")\n",
    "        print(f\"  Label distribution:\")\n",
    "        for i, count in enumerate(label_counts):\n",
    "            if count > 0:\n",
    "                percentage = count / len(cluster_labels) * 100\n",
    "                print(f\"    Cluster {i}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return unique_labels, label_counts\n",
    "\n",
    "# Extract and validate cluster labels\n",
    "cluster_labels = extract_cluster_labels(results)\n",
    "unique_clusters, cluster_counts = validate_cluster_labels(cluster_labels)\n",
    "\n",
    "# Calculate temporal alignment parameters\n",
    "step_size = window_size * (1 - overlap)  # Time step between consecutive windows\n",
    "n_windows = len(cluster_labels)\n",
    "cluster_times = np.arange(n_windows) * step_size\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Temporal Alignment:\")\n",
    "print(f\"  Window size: {window_size}s\")\n",
    "print(f\"  Step size: {step_size}s\") \n",
    "print(f\"  Total coverage: {cluster_times[-1] + window_size:.1f}s ({(cluster_times[-1] + window_size)/3600:.2f}h)\")\n",
    "print(f\"  Effective recording: {len(cluster_labels)} windows\")\n",
    "\n",
    "print(\"\\n‚úì Cluster extraction and validation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad223ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INTERACTIVE HYPNOGRAM VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_hypnogram(cluster_labels, cluster_times, window_size, max_points=5000):\n",
    "    \"\"\"\n",
    "    Create an interactive hypnogram showing sleep cluster evolution over time.\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels (array): Cluster assignments for each time window\n",
    "        cluster_times (array): Start times for each window\n",
    "        window_size (float): Duration of each window in seconds\n",
    "        max_points (int): Maximum number of points to plot for performance\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Interactive hypnogram plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define distinct colors for each cluster (sleep stage)\n",
    "    cluster_colors = {\n",
    "        0: '#1f77b4',  # Deep Blue - potentially deep sleep\n",
    "        1: '#ff7f0e',  # Orange - potentially light sleep  \n",
    "        2: '#2ca02c',  # Green - potentially REM sleep\n",
    "        3: '#d62728',  # Red - potentially wake/arousal\n",
    "        4: '#9467bd',  # Purple - additional cluster\n",
    "        5: '#8c564b',  # Brown - additional cluster\n",
    "    }\n",
    "    \n",
    "    # Downsample for visualization performance if dataset is large\n",
    "    if len(cluster_labels) > max_points:\n",
    "        print(f\"üìä Downsampling to {max_points:,} points from {len(cluster_labels):,} for optimal visualization...\")\n",
    "        sample_indices = np.linspace(0, len(cluster_labels)-1, max_points, dtype=int)\n",
    "        labels_plot = cluster_labels[sample_indices]\n",
    "        times_plot = cluster_times[sample_indices]\n",
    "    else:\n",
    "        labels_plot = cluster_labels\n",
    "        times_plot = cluster_times\n",
    "    \n",
    "    # Create interactive figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add scatter plot for each cluster with distinct styling\n",
    "    for cluster_id in np.unique(labels_plot):\n",
    "        cluster_mask = labels_plot == cluster_id\n",
    "        times_subset = times_plot[cluster_mask] / 3600  # Convert to hours\n",
    "        labels_subset = labels_plot[cluster_mask]\n",
    "        \n",
    "        if len(times_subset) > 0:\n",
    "            color = cluster_colors.get(cluster_id, '#17becf')\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=times_subset,\n",
    "                y=labels_subset,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=6,\n",
    "                    color=color,\n",
    "                    symbol='square',\n",
    "                    opacity=0.8,\n",
    "                    line=dict(width=1, color='white')\n",
    "                ),\n",
    "                name=f'Cluster {cluster_id}',\n",
    "                text=[f'Time: {t:.2f}h<br>Cluster: {c}<br>Duration: {window_size}s' \n",
    "                      for t, c in zip(times_subset, labels_subset)],\n",
    "                hovertemplate='%{text}<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    # Add trend line to show cluster progression\n",
    "    times_hours = times_plot / 3600\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=times_hours,\n",
    "        y=labels_plot,\n",
    "        mode='lines',\n",
    "        line=dict(width=1.5, color='rgba(100,100,100,0.4)'),\n",
    "        name='Sleep Progression',\n",
    "        showlegend=True,\n",
    "        hoverinfo='skip'\n",
    "    ))\n",
    "    \n",
    "    # Configure layout for optimal viewing\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Sleep Stage Hypnogram - BiLSTM Unsupervised Clustering',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        },\n",
    "        xaxis_title='Time (hours)',\n",
    "        yaxis_title='Sleep Cluster (Stage)',\n",
    "        height=500,\n",
    "        yaxis=dict(\n",
    "            tickmode='linear', \n",
    "            tick0=0, \n",
    "            dtick=1,\n",
    "            title_font_size=14\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_font_size=14,\n",
    "            tickformat='.1f'\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            orientation='h', \n",
    "            yanchor='bottom', \n",
    "            y=1.02, \n",
    "            xanchor='center', \n",
    "            x=0.5\n",
    "        ),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate and display the hypnogram\n",
    "print(\"üé® Generating interactive hypnogram...\")\n",
    "hypnogram_fig = create_hypnogram(cluster_labels, cluster_times, window_size)\n",
    "hypnogram_fig.show()\n",
    "print(\"‚úì Hypnogram visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EEG SEGMENT VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_eeg_segment(start_sec, end_sec, eeg_data, time_vector, \n",
    "                     cluster_labels, cluster_times, window_size):\n",
    "    \"\"\"\n",
    "    Plot EEG data segment with cluster annotations for detailed analysis.\n",
    "    \n",
    "    Args:\n",
    "        start_sec, end_sec (float): Time range to visualize in seconds\n",
    "        eeg_data (array): EEG signal data\n",
    "        time_vector (array): Time points for EEG data\n",
    "        cluster_labels (array): Cluster assignments\n",
    "        cluster_times (array): Cluster window start times\n",
    "        window_size (float): Duration of each cluster window\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Interactive EEG segment plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract EEG segment\n",
    "    start_idx = int(start_sec * fs)\n",
    "    end_idx = int(end_sec * fs)\n",
    "    segment_data = eeg_data[start_idx:end_idx]\n",
    "    segment_time = time_vector[start_idx:end_idx]\n",
    "    \n",
    "    # Find overlapping cluster windows\n",
    "    cluster_mask = (cluster_times >= start_sec - window_size) & (cluster_times <= end_sec)\n",
    "    relevant_clusters = cluster_labels[cluster_mask]\n",
    "    relevant_times = cluster_times[cluster_mask]\n",
    "    \n",
    "    # Create dual-panel figure\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, \n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=['EEG Signal with Cluster Annotations', 'Cluster Assignment Timeline'],\n",
    "        vertical_spacing=0.12,\n",
    "        row_heights=[0.75, 0.25]\n",
    "    )\n",
    "    \n",
    "    # Plot EEG signal\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=segment_time,\n",
    "        y=segment_data,\n",
    "        mode='lines',\n",
    "        name='EEG Signal',\n",
    "        line=dict(width=1.2, color='#2E86C1'),\n",
    "        hovertemplate='Time: %{x:.1f}s<br>Amplitude: %{y:.1f}ŒºV<extra></extra>'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Color map for clusters\n",
    "    cluster_colors = {0: '#E74C3C', 1: '#F39C12', 2: '#27AE60', 3: '#8E44AD'}\n",
    "    \n",
    "    # Add cluster annotations as background regions\n",
    "    for time_start, cluster in zip(relevant_times, relevant_clusters):\n",
    "        color = cluster_colors.get(cluster, '#BDC3C7')\n",
    "        \n",
    "        # Background shading on EEG plot\n",
    "        fig.add_vrect(\n",
    "            x0=time_start,\n",
    "            x1=time_start + window_size,\n",
    "            fillcolor=color,\n",
    "            opacity=0.2,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Cluster timeline bar\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=time_start,\n",
    "            x1=time_start + window_size,\n",
    "            y0=cluster - 0.35,\n",
    "            y1=cluster + 0.35,\n",
    "            fillcolor=color,\n",
    "            line=dict(width=1, color=color),\n",
    "            opacity=0.8,\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Configure layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': f'EEG Segment Analysis: {start_sec}s - {end_sec}s ({(end_sec-start_sec)/60:.1f} min)',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 14}\n",
    "        },\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text='Time (seconds)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Amplitude (ŒºV)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Cluster', row=2, col=1, \n",
    "                     tickmode='linear', tick0=0, dtick=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Demonstrate with first 10 minutes of recording\n",
    "demo_start, demo_end = 0, 600  # 10 minutes\n",
    "print(f\"üîç Analyzing EEG segment: {demo_start}s - {demo_end}s\")\n",
    "segment_fig = plot_eeg_segment(demo_start, demo_end, eeg_data, time_vector, \n",
    "                              cluster_labels, cluster_times, window_size)\n",
    "segment_fig.show()\n",
    "print(\"‚úì Segment visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CLUSTER DISTRIBUTION ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "def analyze_cluster_distribution(cluster_labels, window_size):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of cluster distribution patterns.\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels (array): Cluster assignments for each window\n",
    "        window_size (float): Duration of each window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cluster statistics summary\n",
    "    \"\"\"\n",
    "    unique_clusters, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    total_windows = len(cluster_labels)\n",
    "    total_duration_hrs = total_windows * window_size / 3600\n",
    "    \n",
    "    print(\"üìä CLUSTER DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Recording Overview:\")\n",
    "    print(f\"  Total windows: {total_windows:,}\")\n",
    "    print(f\"  Total duration: {total_duration_hrs:.2f} hours\")\n",
    "    print(f\"  Window size: {window_size}s\")\n",
    "    print(f\"  Unique clusters: {len(unique_clusters)}\")\n",
    "    \n",
    "    print(f\"\\nCluster Breakdown:\")\n",
    "    cluster_stats = []\n",
    "    \n",
    "    for cluster, count in zip(unique_clusters, counts):\n",
    "        proportion = count / total_windows * 100\n",
    "        duration_hours = count * window_size / 3600\n",
    "        duration_minutes = duration_hours * 60\n",
    "        \n",
    "        print(f\"  Cluster {cluster}: {count:,} windows ({proportion:5.1f}%) \"\n",
    "              f\"‚Üí {duration_hours:5.2f}h ({duration_minutes:6.1f}min)\")\n",
    "        \n",
    "        cluster_stats.append({\n",
    "            'cluster': cluster,\n",
    "            'count': count,\n",
    "            'proportion_pct': proportion,\n",
    "            'duration_hours': duration_hours,\n",
    "            'duration_minutes': duration_minutes\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nInterpretation Notes:\")\n",
    "    print(f\"  ‚Ä¢ Higher proportion clusters may represent dominant sleep stages\")\n",
    "    print(f\"  ‚Ä¢ Consider circadian patterns and typical sleep architecture\")\n",
    "    print(f\"  ‚Ä¢ Cluster transitions indicate sleep stage stability\")\n",
    "    \n",
    "    return pd.DataFrame(cluster_stats)\n",
    "\n",
    "# Analyze cluster distribution\n",
    "cluster_dist_df = analyze_cluster_distribution(cluster_labels, window_size)\n",
    "print(\"\\n‚úì Cluster distribution analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CLUSTER DISTRIBUTION VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_cluster_distribution_plots(cluster_dist_df, cluster_labels, cluster_times):\n",
    "    \"\"\"Create comprehensive cluster distribution visualizations.\"\"\"\n",
    "    \n",
    "    # Create 2x2 subplot layout\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Cluster Window Counts', \n",
    "            'Sleep Stage Proportions (%)', \n",
    "            'Duration Distribution (Hours)', \n",
    "            'Temporal Evolution'\n",
    "        ],\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'pie'}],\n",
    "            [{'type': 'bar'}, {'type': 'scatter'}]\n",
    "        ],\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # 1. Bar chart of window counts\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cluster_dist_df['cluster'],\n",
    "        y=cluster_dist_df['count'],\n",
    "        name='Window Count',\n",
    "        marker_color='lightblue',\n",
    "        text=cluster_dist_df['count'],\n",
    "        textposition='outside',\n",
    "        hovertemplate='Cluster %{x}<br>Count: %{y}<extra></extra>'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Pie chart of proportions  \n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=[f'Cluster {c}' for c in cluster_dist_df['cluster']],\n",
    "        values=cluster_dist_df['proportion_pct'],\n",
    "        name='Proportion',\n",
    "        textinfo='label+percent',\n",
    "        hovertemplate='%{label}<br>%{percent}<br>%{value:.1f}%<extra></extra>'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Duration in hours\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cluster_dist_df['cluster'],\n",
    "        y=cluster_dist_df['duration_hours'],\n",
    "        name='Duration (Hours)',\n",
    "        marker_color='lightgreen',\n",
    "        text=[f'{h:.1f}h' for h in cluster_dist_df['duration_hours']],\n",
    "        textposition='outside',\n",
    "        hovertemplate='Cluster %{x}<br>Duration: %{y:.2f}h<extra></extra>'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # 4. Temporal evolution scatter plot (downsampled for performance)\n",
    "    max_points = 2000\n",
    "    if len(cluster_labels) > max_points:\n",
    "        step = len(cluster_labels) // max_points\n",
    "        times_plot = cluster_times[::step] / 3600  # Convert to hours\n",
    "        labels_plot = cluster_labels[::step]\n",
    "    else:\n",
    "        times_plot = cluster_times / 3600\n",
    "        labels_plot = cluster_labels\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=times_plot,\n",
    "        y=labels_plot,\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, opacity=0.6, color=labels_plot, colorscale='Viridis'),\n",
    "        name='Sleep Evolution',\n",
    "        hovertemplate='Time: %{x:.1f}h<br>Cluster: %{y}<extra></extra>'\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # Update layout and axes\n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        title={\n",
    "            'text': 'Comprehensive Cluster Distribution Analysis',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        },\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Configure axes labels\n",
    "    fig.update_xaxes(title_text='Cluster ID', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Number of Windows', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Cluster ID', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Duration (Hours)', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Recording Time (Hours)', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Cluster ID', row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display comprehensive distribution plots\n",
    "print(\"üé® Creating cluster distribution visualizations...\")\n",
    "distribution_fig = create_cluster_distribution_plots(cluster_dist_df, cluster_labels, cluster_times)\n",
    "distribution_fig.show()\n",
    "print(\"‚úì Distribution plots generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ed571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONTINUOUS DURATION ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "def analyze_continuous_durations(cluster_labels, window_size):\n",
    "    \"\"\"\n",
    "    Analyze the continuous duration of each cluster to understand sleep stage stability.\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels (array): Cluster assignments for each window\n",
    "        window_size (float): Duration of each window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (continuous_durations dict, duration_stats DataFrame)\n",
    "    \"\"\"\n",
    "    # Initialize storage for continuous segments\n",
    "    continuous_durations = {cluster: [] for cluster in np.unique(cluster_labels)}\n",
    "    \n",
    "    # Track current segment\n",
    "    current_cluster = cluster_labels[0]\n",
    "    current_duration = 1  # Number of consecutive windows\n",
    "    \n",
    "    print(\"üîç CONTINUOUS DURATION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Process each label to find continuous segments\n",
    "    for i in range(1, len(cluster_labels)):\n",
    "        if cluster_labels[i] == current_cluster:\n",
    "            # Continue current segment\n",
    "            current_duration += 1\n",
    "        else:\n",
    "            # End of continuous segment - record duration\n",
    "            duration_seconds = current_duration * window_size\n",
    "            continuous_durations[current_cluster].append(duration_seconds)\n",
    "            \n",
    "            # Start new segment\n",
    "            current_cluster = cluster_labels[i]\n",
    "            current_duration = 1\n",
    "    \n",
    "    # Don't forget the final segment\n",
    "    duration_seconds = current_duration * window_size\n",
    "    continuous_durations[current_cluster].append(duration_seconds)\n",
    "    \n",
    "    # Calculate comprehensive statistics\n",
    "    duration_stats = []\n",
    "    total_segments = sum(len(durations) for durations in continuous_durations.values())\n",
    "    \n",
    "    print(f\"Sleep Architecture Summary:\")\n",
    "    print(f\"  Total continuous segments: {total_segments}\")\n",
    "    print(f\"  Average transitions per hour: {total_segments / (len(cluster_labels) * window_size / 3600):.1f}\")\n",
    "    \n",
    "    print(f\"\\nCluster-Specific Duration Statistics:\")\n",
    "    for cluster in sorted(continuous_durations.keys()):\n",
    "        durations = continuous_durations[cluster]\n",
    "        \n",
    "        if durations:\n",
    "            # Calculate statistics in minutes for readability\n",
    "            durations_min = np.array(durations) / 60\n",
    "            \n",
    "            stats = {\n",
    "                'cluster': cluster,\n",
    "                'segment_count': len(durations),\n",
    "                'mean_duration_min': np.mean(durations_min),\n",
    "                'median_duration_min': np.median(durations_min),\n",
    "                'max_duration_min': np.max(durations_min),\n",
    "                'min_duration_min': np.min(durations_min),\n",
    "                'std_duration_min': np.std(durations_min),\n",
    "                'total_time_min': np.sum(durations_min)\n",
    "            }\n",
    "            \n",
    "            print(f\"  Cluster {cluster}:\")\n",
    "            print(f\"    Segments: {stats['segment_count']:3d} | \"\n",
    "                  f\"Mean: {stats['mean_duration_min']:5.1f}min | \"\n",
    "                  f\"Median: {stats['median_duration_min']:5.1f}min\")\n",
    "            print(f\"    Range: {stats['min_duration_min']:5.1f}min - {stats['max_duration_min']:5.1f}min | \"\n",
    "                  f\"Total: {stats['total_time_min']:6.1f}min\")\n",
    "            \n",
    "            duration_stats.append(stats)\n",
    "    \n",
    "    duration_stats_df = pd.DataFrame(duration_stats)\n",
    "    \n",
    "    print(f\"\\nüìä Sleep Stage Stability Analysis:\")\n",
    "    if len(duration_stats_df) > 0:\n",
    "        most_stable = duration_stats_df.loc[duration_stats_df['mean_duration_min'].idxmax()]\n",
    "        longest_segment = duration_stats_df.loc[duration_stats_df['max_duration_min'].idxmax()]\n",
    "        \n",
    "        print(f\"  Most stable cluster: {most_stable['cluster']} (avg {most_stable['mean_duration_min']:.1f}min)\")\n",
    "        print(f\"  Longest single segment: Cluster {longest_segment['cluster']} ({longest_segment['max_duration_min']:.1f}min)\")\n",
    "    \n",
    "    return continuous_durations, duration_stats_df\n",
    "\n",
    "# Analyze continuous durations\n",
    "continuous_durations, duration_stats_df = analyze_continuous_durations(cluster_labels, window_size)\n",
    "print(\"‚úì Continuous duration analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c63684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONTINUOUS DURATION VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_duration_analysis_plots(duration_stats_df, continuous_durations):\n",
    "    \"\"\"Create comprehensive visualization of continuous duration patterns.\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Average Duration by Cluster',\n",
    "            'Duration Distribution Histograms', \n",
    "            'Segment Count Analysis',\n",
    "            'Duration Boxplots'\n",
    "        ],\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'histogram'}],\n",
    "            [{'type': 'bar'}, {'type': 'box'}]\n",
    "        ],\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # 1. Bar chart of mean durations\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=duration_stats_df['cluster'],\n",
    "        y=duration_stats_df['mean_duration_min'],\n",
    "        name='Average Duration',\n",
    "        marker_color='lightcoral',\n",
    "        text=[f'{dur:.1f}min' for dur in duration_stats_df['mean_duration_min']],\n",
    "        textposition='outside',\n",
    "        hovertemplate='Cluster %{x}<br>Mean Duration: %{y:.1f}min<extra></extra>'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Overlapping histograms of duration distributions\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    for i, cluster in enumerate(sorted(continuous_durations.keys())):\n",
    "        durations_min = np.array(continuous_durations[cluster]) / 60\n",
    "        \n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=durations_min,\n",
    "            name=f'Cluster {cluster}',\n",
    "            opacity=0.7,\n",
    "            marker_color=colors[i % len(colors)],\n",
    "            nbinsx=20,\n",
    "            showlegend=True\n",
    "        ), row=1, col=2)\n",
    "    \n",
    "    # 3. Segment count analysis\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=duration_stats_df['cluster'],\n",
    "        y=duration_stats_df['segment_count'],\n",
    "        name='Segment Count',\n",
    "        marker_color='lightgreen',\n",
    "        text=duration_stats_df['segment_count'],\n",
    "        textposition='outside',\n",
    "        hovertemplate='Cluster %{x}<br>Segments: %{y}<extra></extra>'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # 4. Box plots showing duration distributions\n",
    "    for cluster in sorted(continuous_durations.keys()):\n",
    "        durations_min = np.array(continuous_durations[cluster]) / 60\n",
    "        \n",
    "        fig.add_trace(go.Box(\n",
    "            y=durations_min,\n",
    "            name=f'Cluster {cluster}',\n",
    "            boxpoints='outliers',\n",
    "            showlegend=False,\n",
    "            marker_color=colors[cluster % len(colors)]\n",
    "        ), row=2, col=2)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        title={\n",
    "            'text': 'Sleep Stage Continuity Analysis - Duration Patterns',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Configure axes\n",
    "    fig.update_xaxes(title_text='Cluster ID', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Mean Duration (minutes)', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Duration (minutes)', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Frequency', row=1, col=2)\n",
    "    fig.update_xaxes(title_text='Cluster ID', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Number of Segments', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Cluster ID', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Duration (minutes)', row=2, col=2)\n",
    "    \n",
    "    # Configure histogram to be overlaid\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display duration analysis plots\n",
    "print(\"üé® Creating duration analysis visualizations...\")\n",
    "duration_fig = create_duration_analysis_plots(duration_stats_df, continuous_durations)\n",
    "duration_fig.show()\n",
    "print(\"‚úì Duration analysis plots generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SPECTRAL ANALYSIS - MULTITAPER SPECTROGRAM\n",
    "# ==============================================================================\n",
    "\n",
    "def compute_multitaper_spectrogram(data, fs, window_length=30, overlap=0.75):\n",
    "    \"\"\"\n",
    "    Compute multitaper spectrogram for enhanced spectral resolution.\n",
    "    \n",
    "    Args:\n",
    "        data (array): EEG time series data\n",
    "        fs (float): Sampling frequency\n",
    "        window_length (float): Window length in seconds\n",
    "        overlap (float): Overlap ratio between windows\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (frequencies, times, power_spectral_density)\n",
    "    \"\"\"\n",
    "    from scipy.signal import spectrogram\n",
    "    \n",
    "    # Calculate spectrogram parameters\n",
    "    nperseg = int(window_length * fs)\n",
    "    noverlap = int(nperseg * overlap)\n",
    "    \n",
    "    print(f\"üî¨ Computing Multitaper Spectrogram:\")\n",
    "    print(f\"  Window length: {window_length}s ({nperseg} samples)\")\n",
    "    print(f\"  Overlap: {overlap*100}% ({noverlap} samples)\") \n",
    "    print(f\"  Frequency resolution: {fs/nperseg:.3f} Hz\")\n",
    "    \n",
    "    # Compute spectrogram\n",
    "    f, t, Sxx = spectrogram(\n",
    "        data, fs, \n",
    "        window='hann',  # Hann window for good spectral properties\n",
    "        nperseg=nperseg, \n",
    "        noverlap=noverlap,\n",
    "        scaling='density'\n",
    "    )\n",
    "    \n",
    "    print(f\"  Spectrogram shape: {Sxx.shape}\")\n",
    "    print(f\"  Frequency range: {f[0]:.1f} - {f[-1]:.1f} Hz\")\n",
    "    print(f\"  Time coverage: {t[-1]:.1f}s ({t[-1]/60:.1f}min)\")\n",
    "    \n",
    "    return f, t, Sxx\n",
    "\n",
    "# Analyze a representative segment (limit to first hour for computation efficiency)\n",
    "analysis_duration = min(3600, len(eeg_data)/fs)  # 1 hour or available data\n",
    "analysis_samples = int(analysis_duration * fs)\n",
    "eeg_segment = eeg_data[:analysis_samples]\n",
    "\n",
    "print(f\"üìä Analyzing {analysis_duration/60:.1f} minutes of EEG data for spectral characteristics...\")\n",
    "frequencies, spec_times, power_spectral_density = compute_multitaper_spectrogram(eeg_segment, fs)\n",
    "\n",
    "# Convert to decibels for visualization\n",
    "psd_db = 10 * np.log10(power_spectral_density + 1e-12)  # Add small constant to avoid log(0)\n",
    "\n",
    "print(\"‚úì Spectral analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMBINED HYPNOGRAM AND SPECTROGRAM VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_hypnogram_spectrogram_plot(cluster_labels, cluster_times, window_size, \n",
    "                                      frequencies, spec_times, psd_db, \n",
    "                                      display_duration=1800):\n",
    "    \"\"\"\n",
    "    Create integrated visualization combining sleep hypnogram with spectral analysis.\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels, cluster_times: Sleep cluster data\n",
    "        window_size: Cluster window duration\n",
    "        frequencies, spec_times, psd_db: Spectrogram data\n",
    "        display_duration: Time range to display in seconds\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Combined plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data to display range\n",
    "    time_mask = spec_times <= display_duration\n",
    "    spec_times_display = spec_times[time_mask]\n",
    "    psd_display = psd_db[:, time_mask]\n",
    "    \n",
    "    cluster_mask = cluster_times <= display_duration\n",
    "    cluster_times_display = cluster_times[cluster_mask]\n",
    "    cluster_labels_display = cluster_labels[cluster_mask]\n",
    "    \n",
    "    # Create subplot structure\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=[\n",
    "            f'Sleep Stage Hypnogram ({display_duration/60:.0f} min)',\n",
    "            'Multitaper Spectrogram (0-50 Hz)'\n",
    "        ],\n",
    "        vertical_spacing=0.12,\n",
    "        row_heights=[0.25, 0.75]\n",
    "    )\n",
    "    \n",
    "    # Define cluster visualization colors\n",
    "    cluster_colors = {\n",
    "        0: '#3498DB',  # Blue - Deep sleep\n",
    "        1: '#E67E22',  # Orange - Light sleep\n",
    "        2: '#27AE60',  # Green - REM sleep  \n",
    "        3: '#E74C3C',  # Red - Wake/Arousal\n",
    "    }\n",
    "    \n",
    "    # Add hypnogram as colored rectangles\n",
    "    for time_start, cluster in zip(cluster_times_display, cluster_labels_display):\n",
    "        color = cluster_colors.get(cluster, '#95A5A6')\n",
    "        \n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=time_start,\n",
    "            x1=time_start + window_size,\n",
    "            y0=cluster - 0.35,\n",
    "            y1=cluster + 0.35,\n",
    "            fillcolor=color,\n",
    "            line=dict(width=1, color=color),\n",
    "            opacity=0.8,\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Add spectrogram heatmap\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=spec_times_display,\n",
    "        y=frequencies,\n",
    "        z=psd_display,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(\n",
    "            title='Power Spectral Density (dB)',\n",
    "            x=1.02,\n",
    "            len=0.75,\n",
    "            y=0.4\n",
    "        ),\n",
    "        name='Spectrogram',\n",
    "        hovertemplate='Time: %{x:.1f}s<br>Frequency: %{y:.1f}Hz<br>Power: %{z:.1f}dB<extra></extra>'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Configure layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Integrated Sleep Analysis: Hypnogram with Spectral Dynamics',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        },\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Configure axes\n",
    "    fig.update_xaxes(title_text='Time (seconds)', row=2, col=1)\n",
    "    fig.update_yaxes(\n",
    "        title_text='Sleep Stage', \n",
    "        tickmode='linear', \n",
    "        tick0=0, \n",
    "        dtick=1,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='Frequency (Hz)', \n",
    "        range=[0, 50],  # Focus on sleep-relevant frequencies\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate combined visualization\n",
    "print(\"üé® Creating integrated hypnogram-spectrogram visualization...\")\n",
    "display_time = min(1800, len(eeg_data)/fs)  # 30 minutes or available data\n",
    "combined_plot = create_hypnogram_spectrogram_plot(\n",
    "    cluster_labels, cluster_times, window_size,\n",
    "    frequencies, spec_times, psd_db,\n",
    "    display_duration=display_time\n",
    ")\n",
    "combined_plot.show()\n",
    "print(\"‚úì Combined visualization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FREQUENCY BAND ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "def analyze_frequency_bands(frequencies, spec_times, power_spectral_density, \n",
    "                           cluster_labels, cluster_times, window_size):\n",
    "    \"\"\"\n",
    "    Analyze EEG frequency band power distribution across sleep clusters.\n",
    "    \n",
    "    Args:\n",
    "        frequencies: Frequency bins from spectrogram\n",
    "        spec_times: Time points from spectrogram  \n",
    "        power_spectral_density: Spectral power matrix\n",
    "        cluster_labels, cluster_times: Sleep cluster data\n",
    "        window_size: Cluster window duration\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Band power statistics by cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define physiologically relevant EEG frequency bands\n",
    "    frequency_bands = {\n",
    "        'Delta (0.5-4 Hz)': (0.5, 4.0),    # Deep sleep, slow-wave activity\n",
    "        'Theta (4-8 Hz)': (4.0, 8.0),      # Light sleep, drowsiness, REM\n",
    "        'Alpha (8-13 Hz)': (8.0, 13.0),    # Relaxed wakefulness, eyes closed\n",
    "        'Beta (13-30 Hz)': (13.0, 30.0),   # Active wakefulness, cognitive activity\n",
    "        'Gamma (30-50 Hz)': (30.0, 50.0)   # High-frequency activity, cognition\n",
    "    }\n",
    "    \n",
    "    print(\"üß† FREQUENCY BAND ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Analyzing {len(frequency_bands)} frequency bands across {len(np.unique(cluster_labels))} clusters\")\n",
    "    \n",
    "    # Pre-compute frequency band masks for efficiency\n",
    "    band_masks = {}\n",
    "    for band_name, (f_low, f_high) in frequency_bands.items():\n",
    "        mask = (frequencies >= f_low) & (frequencies <= f_high)\n",
    "        band_masks[band_name] = mask\n",
    "        n_bins = np.sum(mask)\n",
    "        print(f\"  {band_name}: {n_bins} frequency bins ({f_low}-{f_high} Hz)\")\n",
    "    \n",
    "    # Calculate band power for each time window\n",
    "    band_powers = {}\n",
    "    for band_name, freq_mask in band_masks.items():\n",
    "        # Average power across frequency bins within the band\n",
    "        band_powers[band_name] = np.mean(power_spectral_density[freq_mask, :], axis=0)\n",
    "    \n",
    "    # Align clusters with spectrogram time points\n",
    "    cluster_band_stats = []\n",
    "    analysis_limit = min(len(cluster_labels), 500)  # Limit for computational efficiency\n",
    "    \n",
    "    print(f\"\\nProcessing {analysis_limit} cluster windows...\")\n",
    "    \n",
    "    for i in range(0, analysis_limit, max(1, analysis_limit//100)):  # Sample for efficiency\n",
    "        cluster_time = cluster_times[i]\n",
    "        cluster_id = cluster_labels[i]\n",
    "        \n",
    "        # Find closest spectrogram time point\n",
    "        time_idx = np.argmin(np.abs(spec_times - cluster_time))\n",
    "        \n",
    "        # Extract band powers for this time point\n",
    "        for band_name in frequency_bands.keys():\n",
    "            power_value = band_powers[band_name][time_idx]\n",
    "            \n",
    "            cluster_band_stats.append({\n",
    "                'cluster': cluster_id,\n",
    "                'band': band_name,\n",
    "                'power': power_value,\n",
    "                'log_power': np.log10(power_value + 1e-12),  # Avoid log(0)\n",
    "                'time_point': cluster_time\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame and calculate aggregate statistics\n",
    "    band_df = pd.DataFrame(cluster_band_stats)\n",
    "    \n",
    "    # Calculate summary statistics by cluster and band\n",
    "    band_summary = band_df.groupby(['cluster', 'band']).agg({\n",
    "        'power': ['mean', 'std', 'median'],\n",
    "        'log_power': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    band_summary.columns = ['mean_power', 'std_power', 'median_power', 'mean_log_power', 'std_log_power']\n",
    "    band_summary = band_summary.reset_index()\n",
    "    \n",
    "    print(f\"\\nüìä Band Power Analysis Summary:\")\n",
    "    for cluster in sorted(band_summary['cluster'].unique()):\n",
    "        cluster_data = band_summary[band_summary['cluster'] == cluster]\n",
    "        dominant_band = cluster_data.loc[cluster_data['mean_power'].idxmax(), 'band']\n",
    "        max_power = cluster_data['mean_power'].max()\n",
    "        print(f\"  Cluster {cluster}: Dominant band = {dominant_band} (Power: {max_power:.2e})\")\n",
    "    \n",
    "    return band_summary, band_powers\n",
    "\n",
    "# Perform frequency band analysis\n",
    "print(\"üî¨ Starting frequency band analysis...\")\n",
    "band_stats_df, band_power_dict = analyze_frequency_bands(\n",
    "    frequencies, spec_times, power_spectral_density,\n",
    "    cluster_labels, cluster_times, window_size\n",
    ")\n",
    "\n",
    "print(\"‚úì Frequency band analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FREQUENCY BAND VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_frequency_band_plots(band_stats_df):\n",
    "    \"\"\"\n",
    "    Create comprehensive frequency band analysis visualizations.\n",
    "    \n",
    "    Args:\n",
    "        band_stats_df: DataFrame with band power statistics by cluster\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Multi-panel frequency analysis plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pivot data for easier visualization\n",
    "    power_pivot = band_stats_df.pivot(index='cluster', columns='band', values='mean_power')\n",
    "    log_power_pivot = band_stats_df.pivot(index='cluster', columns='band', values='mean_log_power')\n",
    "    \n",
    "    # Create comprehensive subplot layout\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Band Power by Cluster (Linear Scale)',\n",
    "            'Band Power Heatmap (Log Scale)', \n",
    "            'Relative Band Power Distribution (%)',\n",
    "            'Dominant Frequency Bands'\n",
    "        ],\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'heatmap'}],\n",
    "            [{'type': 'bar'}, {'type': 'bar'}]\n",
    "        ],\n",
    "        horizontal_spacing=0.12,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Color scheme for clusters\n",
    "    cluster_colors = ['#3498DB', '#E67E22', '#27AE60', '#E74C3C', '#9B59B6', '#1ABC9C']\n",
    "    \n",
    "    # 1. Grouped bar chart of absolute band powers\n",
    "    for i, cluster in enumerate(sorted(band_stats_df['cluster'].unique())):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=cluster_data['band'],\n",
    "            y=cluster_data['mean_power'],\n",
    "            name=f'Cluster {cluster}',\n",
    "            marker_color=cluster_colors[i % len(cluster_colors)],\n",
    "            opacity=0.8,\n",
    "            error_y=dict(type='data', array=cluster_data['std_power'], visible=True),\n",
    "            hovertemplate='Band: %{x}<br>Power: %{y:.2e}<br>Cluster: ' + str(cluster) + '<extra></extra>'\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # 2. Heatmap of log-scaled band powers\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=log_power_pivot.columns,\n",
    "        y=[f'Cluster {c}' for c in log_power_pivot.index],\n",
    "        z=log_power_pivot.values,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(\n",
    "            title='Log‚ÇÅ‚ÇÄ(Power)',\n",
    "            x=0.48,\n",
    "            y=0.8,\n",
    "            len=0.35\n",
    "        ),\n",
    "        hovertemplate='Band: %{x}<br>Cluster: %{y}<br>Log Power: %{z:.2f}<extra></extra>'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Relative band power (normalized to 100% per cluster)\n",
    "    for i, cluster in enumerate(sorted(band_stats_df['cluster'].unique())):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        total_power = cluster_data['mean_power'].sum()\n",
    "        relative_power = (cluster_data['mean_power'] / total_power) * 100\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=cluster_data['band'],\n",
    "            y=relative_power,\n",
    "            name=f'Cluster {cluster} (Relative)',\n",
    "            marker_color=cluster_colors[i % len(cluster_colors)],\n",
    "            opacity=0.8,\n",
    "            showlegend=False,\n",
    "            hovertemplate='Band: %{x}<br>Relative Power: %{y:.1f}%<br>Cluster: ' + str(cluster) + '<extra></extra>'\n",
    "        ), row=2, col=1)\n",
    "    \n",
    "    # 4. Dominant band analysis\n",
    "    dominant_bands = []\n",
    "    for cluster in sorted(band_stats_df['cluster'].unique()):\n",
    "        cluster_data = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "        dominant = cluster_data.loc[cluster_data['mean_power'].idxmax(), 'band']\n",
    "        dominant_power = cluster_data['mean_power'].max()\n",
    "        dominant_bands.append({'cluster': cluster, 'dominant_band': dominant, 'max_power': dominant_power})\n",
    "    \n",
    "    dominant_df = pd.DataFrame(dominant_bands)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[f'Cluster {c}' for c in dominant_df['cluster']],\n",
    "        y=dominant_df['max_power'],\n",
    "        text=dominant_df['dominant_band'],\n",
    "        textposition='outside',\n",
    "        marker_color='lightsteelblue',\n",
    "        name='Dominant Band Power',\n",
    "        showlegend=False,\n",
    "        hovertemplate='Cluster: %{x}<br>Dominant Band: %{text}<br>Power: %{y:.2e}<extra></extra>'\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # Configure layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title={\n",
    "            'text': 'Comprehensive EEG Frequency Band Analysis Across Sleep Clusters',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        },\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=1.02,\n",
    "            xanchor='center',\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Configure axes\n",
    "    fig.update_xaxes(title_text='Frequency Band', row=1, col=1, tickangle=45)\n",
    "    fig.update_yaxes(title_text='Mean Power', row=1, col=1, type='log')  # Log scale for better visualization\n",
    "    fig.update_xaxes(title_text='Frequency Band', row=2, col=1, tickangle=45)\n",
    "    fig.update_yaxes(title_text='Relative Power (%)', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Cluster', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Dominant Band Power', row=2, col=2, type='log')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display frequency band analysis plots\n",
    "print(\"üé® Creating frequency band visualizations...\")\n",
    "frequency_plots = create_frequency_band_plots(band_stats_df)\n",
    "frequency_plots.show()\n",
    "print(\"‚úì Frequency band analysis plots completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9266a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMPREHENSIVE ANALYSIS SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_analysis_summary(cluster_dist_df, duration_stats_df, band_stats_df, \n",
    "                             cluster_labels, eeg_data, fs, continuous_durations):\n",
    "    \"\"\"Generate comprehensive summary of BiLSTM clustering analysis.\"\"\"\n",
    "    \n",
    "    print(\"üìã COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Recording and Model Overview\n",
    "    total_duration_hrs = len(eeg_data) / fs / 3600\n",
    "    total_windows = len(cluster_labels)\n",
    "    transitions_count = np.sum(np.diff(cluster_labels) != 0)\n",
    "    stability_ratio = 1 - (transitions_count / len(cluster_labels))\n",
    "    \n",
    "    print(f\"\\nüîç RECORDING OVERVIEW:\")\n",
    "    print(f\"  Total duration: {total_duration_hrs:.2f} hours ({total_duration_hrs*60:.0f} minutes)\")\n",
    "    print(f\"  Total analysis windows: {total_windows:,}\")\n",
    "    print(f\"  Sampling frequency: {fs} Hz\")\n",
    "    print(f\"  Sleep stage transitions: {transitions_count:,}\")\n",
    "    print(f\"  Overall stability: {stability_ratio:.3f} (lower = more transitions)\")\n",
    "    \n",
    "    # 2. Cluster Distribution Summary\n",
    "    print(f\"\\nüìä CLUSTER DISTRIBUTION:\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in cluster_dist_df.iterrows():\n",
    "        print(f\"  Cluster {row['cluster']:1.0f}: {row['count']:4.0f} windows \"\n",
    "              f\"({row['proportion_pct']:5.1f}%) ‚Üí {row['duration_hours']:5.2f}h\")\n",
    "    \n",
    "    most_frequent_cluster = cluster_dist_df.loc[cluster_dist_df['count'].idxmax()]\n",
    "    least_frequent_cluster = cluster_dist_df.loc[cluster_dist_df['count'].idxmin()]\n",
    "    \n",
    "    print(f\"\\n  Most frequent: Cluster {most_frequent_cluster['cluster']} ({most_frequent_cluster['proportion_pct']:.1f}%)\")\n",
    "    print(f\"  Least frequent: Cluster {least_frequent_cluster['cluster']} ({least_frequent_cluster['proportion_pct']:.1f}%)\")\n",
    "    \n",
    "    # 3. Sleep Architecture Analysis\n",
    "    print(f\"\\nüèóÔ∏è  SLEEP ARCHITECTURE (Duration Analysis):\")\n",
    "    print(\"-\" * 40)\n",
    "    if len(duration_stats_df) > 0:\n",
    "        for _, row in duration_stats_df.iterrows():\n",
    "            print(f\"  Cluster {row['cluster']:1.0f}: {row['segment_count']:3.0f} segments | \"\n",
    "                  f\"Avg: {row['mean_duration_min']:5.1f}min | \"\n",
    "                  f\"Max: {row['max_duration_min']:5.1f}min\")\n",
    "        \n",
    "        most_stable = duration_stats_df.loc[duration_stats_df['mean_duration_min'].idxmax()]\n",
    "        longest_segment = duration_stats_df.loc[duration_stats_df['max_duration_min'].idxmax()]\n",
    "        \n",
    "        print(f\"\\n  Most stable cluster: {most_stable['cluster']} (avg {most_stable['mean_duration_min']:.1f}min per segment)\")\n",
    "        print(f\"  Longest single segment: Cluster {longest_segment['cluster']} ({longest_segment['max_duration_min']:.1f}min)\")\n",
    "    \n",
    "    # 4. Frequency Band Dominance\n",
    "    print(f\"\\nüß† FREQUENCY BAND ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    if len(band_stats_df) > 0:\n",
    "        for cluster in sorted(band_stats_df['cluster'].unique()):\n",
    "            cluster_bands = band_stats_df[band_stats_df['cluster'] == cluster]\n",
    "            dominant_band = cluster_bands.loc[cluster_bands['mean_power'].idxmax(), 'band']\n",
    "            max_power = cluster_bands['mean_power'].max()\n",
    "            \n",
    "            # Calculate relative band powers for interpretation\n",
    "            total_power = cluster_bands['mean_power'].sum()\n",
    "            dominant_percentage = (max_power / total_power) * 100\n",
    "            \n",
    "            print(f\"  Cluster {cluster}: {dominant_band} dominant ({dominant_percentage:.1f}% of total power)\")\n",
    "    \n",
    "    # 5. Clinical and Research Implications\n",
    "    print(f\"\\nüè• CLINICAL INTERPRETATION NOTES:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  ‚Ä¢ Delta dominance (0.5-4 Hz) ‚Üí Likely deep sleep (N3 stage)\")\n",
    "    print(\"  ‚Ä¢ Theta dominance (4-8 Hz) ‚Üí Likely light sleep (N1/N2) or REM\")\n",
    "    print(\"  ‚Ä¢ Alpha dominance (8-13 Hz) ‚Üí Likely relaxed wakefulness or sleep onset\")\n",
    "    print(\"  ‚Ä¢ Beta/Gamma dominance (>13 Hz) ‚Üí Likely active wakefulness or micro-arousals\")\n",
    "    \n",
    "    print(f\"\\nüí° RESEARCH INSIGHTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  ‚Ä¢ BiLSTM identified {len(cluster_dist_df)} distinct sleep clusters\")\n",
    "    print(f\"  ‚Ä¢ Sleep architecture shows {transitions_count} stage transitions\")\n",
    "    print(f\"  ‚Ä¢ Average sleep segment duration: {np.mean([np.mean(durations) for durations in continuous_durations.values()])/60:.1f} minutes\")\n",
    "    print(f\"  ‚Ä¢ Cluster stability suggests {'high' if stability_ratio > 0.8 else 'moderate' if stability_ratio > 0.6 else 'low'} sleep continuity\")\n",
    "    \n",
    "    return {\n",
    "        'total_duration_hrs': total_duration_hrs,\n",
    "        'total_windows': total_windows,\n",
    "        'transitions_count': transitions_count,\n",
    "        'stability_ratio': stability_ratio,\n",
    "        'most_frequent_cluster': most_frequent_cluster['cluster'],\n",
    "        'dominant_bands': {cluster: band_stats_df[band_stats_df['cluster'] == cluster].loc[\n",
    "            band_stats_df[band_stats_df['cluster'] == cluster]['mean_power'].idxmax(), 'band'] \n",
    "            for cluster in sorted(band_stats_df['cluster'].unique())} if len(band_stats_df) > 0 else {}\n",
    "    }\n",
    "\n",
    "# Generate comprehensive summary\n",
    "analysis_summary = generate_analysis_summary(\n",
    "    cluster_dist_df, duration_stats_df, band_stats_df, \n",
    "    cluster_labels, eeg_data, fs, continuous_durations\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis summary completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24401a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INTERACTIVE ANALYSIS TOOLS\n",
    "# ==============================================================================\n",
    "\n",
    "def interactive_segment_analysis(start_sec, end_sec, plot_spectrogram=True):\n",
    "    \"\"\"\n",
    "    Interactive function to analyze specific time segments in detail.\n",
    "    \n",
    "    Args:\n",
    "        start_sec, end_sec (float): Time range to analyze in seconds\n",
    "        plot_spectrogram (bool): Whether to generate spectrogram for the segment\n",
    "        \n",
    "    Usage:\n",
    "        interactive_segment_analysis(600, 1200)  # Analyze 10-20 minute segment\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç DETAILED SEGMENT ANALYSIS\")\n",
    "    print(f\"Time Range: {start_sec}s - {end_sec}s ({(end_sec-start_sec)/60:.1f} minutes)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find clusters in this segment\n",
    "    segment_mask = (cluster_times >= start_sec) & (cluster_times <= end_sec)\n",
    "    segment_clusters = cluster_labels[segment_mask]\n",
    "    segment_times = cluster_times[segment_mask]\n",
    "    \n",
    "    if len(segment_clusters) > 0:\n",
    "        unique, counts = np.unique(segment_clusters, return_counts=True)\n",
    "        cluster_distribution = dict(zip(unique, counts))\n",
    "        dominant_cluster = unique[np.argmax(counts)]\n",
    "        num_transitions = np.sum(np.diff(segment_clusters) != 0)\n",
    "        \n",
    "        print(f\"üìä Cluster Distribution: {cluster_distribution}\")\n",
    "        print(f\"üéØ Dominant cluster: {dominant_cluster} ({counts[np.argmax(counts)]} windows)\")\n",
    "        print(f\"üîÑ Transitions: {num_transitions}\")\n",
    "        print(f\"üìà Stability: {1 - (num_transitions / len(segment_clusters)):.3f}\")\n",
    "        \n",
    "        # Calculate segment duration statistics\n",
    "        total_segment_time = (end_sec - start_sec) / 60\n",
    "        windows_per_minute = len(segment_clusters) / total_segment_time\n",
    "        print(f\"‚è±Ô∏è  Analysis windows: {len(segment_clusters)} ({windows_per_minute:.1f} per minute)\")\n",
    "    else:\n",
    "        print(\"‚ùå No cluster data available for this time segment\")\n",
    "        return\n",
    "    \n",
    "    # Plot EEG segment with cluster annotations\n",
    "    print(f\"\\nüé® Generating EEG segment visualization...\")\n",
    "    segment_fig = plot_eeg_segment(start_sec, end_sec, eeg_data, time_vector,\n",
    "                                   cluster_labels, cluster_times, window_size)\n",
    "    segment_fig.show()\n",
    "    \n",
    "    # Optional spectrogram analysis for shorter segments\n",
    "    if plot_spectrogram and (end_sec - start_sec) <= 600:  # Max 10 minutes for performance\n",
    "        print(f\"üî¨ Computing segment spectrogram...\")\n",
    "        \n",
    "        start_idx = int(start_sec * fs)\n",
    "        end_idx = int(end_sec * fs)\n",
    "        segment_data = eeg_data[start_idx:end_idx]\n",
    "        \n",
    "        if len(segment_data) > fs * 10:  # Minimum 10 seconds of data\n",
    "            f_seg, t_seg, Sxx_seg = compute_multitaper_spectrogram(segment_data, fs, window_length=5)\n",
    "            Sxx_seg_db = 10 * np.log10(Sxx_seg + 1e-12)\n",
    "            \n",
    "            # Create spectrogram plot\n",
    "            spec_fig = go.Figure()\n",
    "            spec_fig.add_trace(go.Heatmap(\n",
    "                x=t_seg + start_sec,  # Adjust time to actual recording time\n",
    "                y=f_seg,\n",
    "                z=Sxx_seg_db,\n",
    "                colorscale='Viridis',\n",
    "                colorbar=dict(title='Power (dB)')\n",
    "            ))\n",
    "            \n",
    "            spec_fig.update_layout(\n",
    "                title=f'Segment Spectrogram: {start_sec}s - {end_sec}s',\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Frequency (Hz)',\n",
    "                height=400\n",
    "            )\n",
    "            spec_fig.update_yaxes(range=[0, 50])  # Focus on sleep-relevant frequencies\n",
    "            spec_fig.show()\n",
    "            \n",
    "            print(\"‚úÖ Spectrogram analysis completed\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Segment too short for reliable spectrogram analysis\")\n",
    "    \n",
    "    elif plot_spectrogram and (end_sec - start_sec) > 600:\n",
    "        print(\"‚ö†Ô∏è  Segment too long for spectrogram analysis (>10 min). Set plot_spectrogram=False for longer segments.\")\n",
    "    \n",
    "    print(\"‚úÖ Segment analysis completed\\n\")\n",
    "\n",
    "# Demonstration of interactive analysis\n",
    "print(\"üõ†Ô∏è  INTERACTIVE ANALYSIS TOOLS READY\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Available Functions:\")\n",
    "print(\"  ‚Ä¢ interactive_segment_analysis(start_sec, end_sec, plot_spectrogram=True)\")\n",
    "print(\"    - Analyze any time segment in detail\")\n",
    "print(\"    - Includes EEG visualization and optional spectrogram\")\n",
    "print(\"    - Example: interactive_segment_analysis(600, 900)\")\n",
    "print(\"\\nRecommended Analysis Segments:\")\n",
    "print(\"  ‚Ä¢ First hour: interactive_segment_analysis(0, 3600)\")\n",
    "print(\"  ‚Ä¢ Sleep onset: interactive_segment_analysis(0, 1800)  # First 30 min\")\n",
    "print(\"  ‚Ä¢ Mid-sleep: interactive_segment_analysis(14400, 16200)  # 4-4.5 hours in\")\n",
    "print(\"  ‚Ä¢ Wake period: interactive_segment_analysis(28800, 30600)  # 8-8.5 hours in\")\n",
    "\n",
    "print(\"\\nüí° ANALYSIS RECOMMENDATIONS:\")\n",
    "print(\"1. üî¨ Cluster Interpretation:\")\n",
    "print(\"   - Compare frequency band dominance with physiological sleep stages\")\n",
    "print(\"   - Delta dominance ‚Üí Deep sleep (N3)\")\n",
    "print(\"   - Theta dominance ‚Üí Light sleep (N1/N2) or REM\")\n",
    "print(\"   - Alpha/Beta dominance ‚Üí Wake or micro-arousals\")\n",
    "print(\"\\n2. üìä Model Validation:\")\n",
    "print(\"   - Check cluster consistency across different time periods\")\n",
    "print(\"   - Validate against expected sleep architecture patterns\")\n",
    "print(\"   - Consider individual sleep characteristics and disorders\")\n",
    "print(\"\\n3. üîç Further Investigation:\")\n",
    "print(\"   - Analyze cluster transition patterns and timing\")\n",
    "print(\"   - Investigate circadian rhythm effects on clustering\")\n",
    "print(\"   - Compare results with other sleep analysis methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d650494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CLUSTER TRANSITION ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "def analyze_cluster_transitions(cluster_labels):\n",
    "    \"\"\"\n",
    "    Analyze transitions between sleep clusters to understand sleep dynamics.\n",
    "    \n",
    "    Args:\n",
    "        cluster_labels (array): Sequence of cluster assignments\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (transition_matrix, transition_probabilities, unique_clusters)\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_clusters = sorted(np.unique(cluster_labels))\n",
    "    n_clusters = len(unique_clusters)\n",
    "    \n",
    "    print(\"üîÑ CLUSTER TRANSITION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Analyzing transitions between {n_clusters} clusters...\")\n",
    "    \n",
    "    # Initialize transition matrix\n",
    "    transition_matrix = np.zeros((n_clusters, n_clusters), dtype=int)\n",
    "    \n",
    "    # Count transitions between consecutive time windows\n",
    "    for i in range(len(cluster_labels) - 1):\n",
    "        from_cluster = int(cluster_labels[i])\n",
    "        to_cluster = int(cluster_labels[i + 1])\n",
    "        transition_matrix[from_cluster, to_cluster] += 1\n",
    "    \n",
    "    # Calculate transition probabilities (normalize by row sums)\n",
    "    row_sums = transition_matrix.sum(axis=1, keepdims=True)\n",
    "    transition_probs = np.divide(transition_matrix, row_sums, \n",
    "                                out=np.zeros_like(transition_matrix, dtype=float), \n",
    "                                where=row_sums!=0)\n",
    "    \n",
    "    # Display transition matrices\n",
    "    print(f\"\\nüìä Transition Matrix (Raw Counts):\")\n",
    "    trans_df = pd.DataFrame(\n",
    "        transition_matrix, \n",
    "        index=[f'From Cluster {c}' for c in unique_clusters], \n",
    "        columns=[f'To Cluster {c}' for c in unique_clusters]\n",
    "    )\n",
    "    print(trans_df.to_string())\n",
    "    \n",
    "    print(f\"\\nüìà Transition Probabilities:\")\n",
    "    trans_prob_df = pd.DataFrame(\n",
    "        transition_probs, \n",
    "        index=[f'From Cluster {c}' for c in unique_clusters], \n",
    "        columns=[f'To Cluster {c}' for c in unique_clusters]\n",
    "    )\n",
    "    print(trans_prob_df.round(3).to_string())\n",
    "    \n",
    "    # Calculate transition statistics\n",
    "    total_transitions = np.sum(transition_matrix)\n",
    "    self_transitions = np.sum(np.diag(transition_matrix))\n",
    "    stability_ratio = self_transitions / total_transitions if total_transitions > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìã Transition Statistics:\")\n",
    "    print(f\"  Total transitions: {total_transitions:,}\")\n",
    "    print(f\"  Self-transitions (no change): {self_transitions:,} ({stability_ratio:.1%})\")\n",
    "    print(f\"  Between-cluster transitions: {total_transitions - self_transitions:,}\")\n",
    "    print(f\"  Overall stability: {stability_ratio:.3f}\")\n",
    "    \n",
    "    # Identify most common transitions\n",
    "    print(f\"\\nüîù Most Common Transitions:\")\n",
    "    transition_list = []\n",
    "    for i, from_cluster in enumerate(unique_clusters):\n",
    "        for j, to_cluster in enumerate(unique_clusters):\n",
    "            if transition_matrix[i, j] > 0:\n",
    "                transition_list.append({\n",
    "                    'from': from_cluster,\n",
    "                    'to': to_cluster,\n",
    "                    'count': transition_matrix[i, j],\n",
    "                    'probability': transition_probs[i, j]\n",
    "                })\n",
    "    \n",
    "    # Sort by count and display top transitions\n",
    "    transition_list.sort(key=lambda x: x['count'], reverse=True)\n",
    "    for trans in transition_list[:8]:  # Show top 8 transitions\n",
    "        arrow = \"‚Üí\" if trans['from'] != trans['to'] else \"‚Üª\"\n",
    "        print(f\"  Cluster {trans['from']} {arrow} Cluster {trans['to']}: \"\n",
    "              f\"{trans['count']:,} times ({trans['probability']:.3f})\")\n",
    "    \n",
    "    return transition_matrix, transition_probs, unique_clusters\n",
    "\n",
    "# Perform transition analysis\n",
    "transition_matrix, transition_probabilities, cluster_ids = analyze_cluster_transitions(cluster_labels)\n",
    "print(\"‚úÖ Transition analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc44ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TRANSITION MATRIX VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "def create_transition_matrix_plots(transition_matrix, transition_probs, cluster_ids):\n",
    "    \"\"\"Create comprehensive visualization of cluster transition patterns.\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=['Transition Counts (Raw)', 'Transition Probabilities'],\n",
    "        specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}]],\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    cluster_labels = [f'Cluster {c}' for c in cluster_ids]\n",
    "    \n",
    "    # 1. Raw transition counts heatmap\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=cluster_labels,\n",
    "        y=cluster_labels,\n",
    "        z=transition_matrix,\n",
    "        colorscale='Blues',\n",
    "        text=transition_matrix.astype(int),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={'size': 12, 'color': 'white'},\n",
    "        colorbar=dict(\n",
    "            title='Transition Count',\n",
    "            x=0.46,\n",
    "            len=0.8\n",
    "        ),\n",
    "        hovertemplate='From: %{y}<br>To: %{x}<br>Count: %{z}<extra></extra>'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Transition probabilities heatmap\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        x=cluster_labels,\n",
    "        y=cluster_labels,\n",
    "        z=transition_probabilities,\n",
    "        colorscale='Reds',\n",
    "        text=np.round(transition_probabilities, 3),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={'size': 12, 'color': 'white'},\n",
    "        colorbar=dict(\n",
    "            title='Transition Probability',\n",
    "            x=1.02,\n",
    "            len=0.8\n",
    "        ),\n",
    "        hovertemplate='From: %{y}<br>To: %{x}<br>Probability: %{z:.3f}<extra></extra>'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Configure layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Sleep Cluster Transition Analysis - Markov Chain Dynamics',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16}\n",
    "        },\n",
    "        height=500,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # Configure axes\n",
    "    fig.update_xaxes(title_text='To Cluster', row=1, col=1, tickangle=45)\n",
    "    fig.update_yaxes(title_text='From Cluster', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='To Cluster', row=1, col=2, tickangle=45)\n",
    "    fig.update_yaxes(title_text='From Cluster', row=1, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display transition matrix visualization\n",
    "print(\"üé® Creating transition matrix visualizations...\")\n",
    "transition_fig = create_transition_matrix_plots(transition_matrix, transition_probabilities, cluster_ids)\n",
    "transition_fig.show()\n",
    "\n",
    "# Additional transition insights\n",
    "print(\"\\nüß† TRANSITION PATTERN INSIGHTS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate self-transition (stability) for each cluster\n",
    "self_stability = np.diag(transition_probabilities)\n",
    "most_stable_cluster = cluster_ids[np.argmax(self_stability)]\n",
    "least_stable_cluster = cluster_ids[np.argmin(self_stability)]\n",
    "\n",
    "print(f\"üìä Cluster Stability (Self-Transition Probabilities):\")\n",
    "for i, cluster in enumerate(cluster_ids):\n",
    "    stability = self_stability[i]\n",
    "    stability_desc = \"High\" if stability > 0.8 else \"Moderate\" if stability > 0.6 else \"Low\"\n",
    "    print(f\"  Cluster {cluster}: {stability:.3f} ({stability_desc} stability)\")\n",
    "\n",
    "print(f\"\\nüéØ Key Findings:\")\n",
    "print(f\"  Most stable cluster: {most_stable_cluster} (probability: {self_stability[most_stable_cluster]:.3f})\")\n",
    "print(f\"  Most dynamic cluster: {least_stable_cluster} (probability: {self_stability[least_stable_cluster]:.3f})\")\n",
    "\n",
    "# Identify most common between-cluster transitions\n",
    "between_cluster_transitions = []\n",
    "for i, from_cluster in enumerate(cluster_ids):\n",
    "    for j, to_cluster in enumerate(cluster_ids):\n",
    "        if i != j and transition_probabilities[i, j] > 0.05:  # Threshold for significant transitions\n",
    "            between_cluster_transitions.append({\n",
    "                'from': from_cluster,\n",
    "                'to': to_cluster,\n",
    "                'probability': transition_probabilities[i, j],\n",
    "                'count': transition_matrix[i, j]\n",
    "            })\n",
    "\n",
    "if between_cluster_transitions:\n",
    "    between_cluster_transitions.sort(key=lambda x: x['probability'], reverse=True)\n",
    "    print(f\"\\nüîÑ Significant Between-Cluster Transitions (>5% probability):\")\n",
    "    for trans in between_cluster_transitions[:5]:  # Top 5\n",
    "        print(f\"  Cluster {trans['from']} ‚Üí Cluster {trans['to']}: \"\n",
    "              f\"{trans['probability']:.3f} ({trans['count']} transitions)\")\n",
    "else:\n",
    "    print(f\"\\nüîí No significant between-cluster transitions detected (all <5% probability)\")\n",
    "    \n",
    "print(\"‚úÖ Transition visualization and analysis completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
